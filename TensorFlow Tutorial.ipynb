{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-size:30px;\"><b>Tutorial de TensorFlow</b></p>\n",
    "<p style=\"text-align:center;\">Pedro Cheira | 53436 | MAEBD</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify;\">Este documento serve de tutorial da framework TensorFlow e visa introduzir, brevemente, algumas capacidades da mesma. Foi elaborado no âmbito da unidade curricular de Aprendizagem com Dados Não Estruturados, do Mestrado em Análise e Engenharia de Big Data, da Faculdade de Ciências e Tecnologia da Universidade Nova de Lisboa.</p>\n",
    "<p style=\"text-align:justify;\">Descrevem-se abordagens a dois problemas de classificação:</p>\n",
    "<ul style=\"text-align:justify;\">\n",
    "<li>O primeiro consiste em reconhecer dígitos manuscritos representados numa determinada imagem. Para tal, é utilizado o popular dataset MNIST (Modified National Institute of Standards and Technology database).</li> \n",
    "<li>O segundo resume-se a descobrir a qual de 10 grupos pertence uma determinada imagem, utilizando-se o dataset CIFAR-10 (Canadian Institute for Advanced Research).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>TensorFlow</h2>\n",
    "\n",
    "<p style=\"text-align:justify;\">O TensorFlow é uma biblioteca de software de código aberto para computação numérica que usa gráficos de fluxo de dados. Os nodes no gráfico representam operações matemáticas, e as arestas representam as matrizes ou tensores de dados multidimensionais que se comunicam com os nodes. A arquitetura flexível permite a implementação de aplicações de computação num ou mais CPUs ou GPUs num computador, servidor ou dispositivo móvel usando uma única API. O TensorFlow foi desenvolvido por investigadores e engenheiros da Google Brain Team no departamento de investigação de machine learning da Google, com a finalidade de realizar investigação sobre redes neurais profundas (deep learning) e aprendizagem automática. No entanto, devido à característica abrangente do sistema, também pode ser aplicado a vários outros domínios.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>MNIST - Softmax Regression</h2>\n",
    "\n",
    "<p style=\"text-align:justify;\">O dataset MNIST (Modified National Institute of Standards and Technology database) contém imagens de dígitos manuscritos divididas em 3 conjuntos: treino (55000 imagens), teste (10000 imagens) e validação (5000 imagens). Cada imagem tem 28 por 28 pixels, que deram origem a um array (numpy) de 784 features. Há 10 labels de classes (algarismos de 0 a 9) já na forma one-hot encoding.</p>\n",
    "\n",
    "<img src=\"https://media.data.world/1ECoxJH9QVCIn3km6L5e_Screen%20Shot%202017-06-27%20at%204.58.43%20PM.png\" alt=\"MNIST\" width=\"250\" height=\"300\">\n",
    "<p style=\"text-align:center;\">Exemplos de imagens do dataset MNIST</p>\n",
    "\n",
    "<p style=\"text-align:justify;\">Como se pretende lidar com classificação de múltiplas classes, utiliza-se <b>Softmax Regression</b>.\n",
    "Softmax Regression (ou multinomial logistic regression) é uma generalização da logistic regression para lidar com várias classes. Para tal, transforma o vetor $z$, de dimensão K, de valores reais arbitrários, no vetor $\\sigma(z)$, da mesma dimensão, de valores reais, onde cada entrada pertence ao intervalo entre 0 e 1, e a soma de todas as entradas dá 1. Assim, torna-se possível expressar a probabilidade de um exemplo pertencer a determinada classe. A função é dada por:</p>\n",
    "\n",
    "$$\\sigma:\\mathbb{R}^K \\to \\left\\{\\sigma \\in \\mathbb{R}^K| \\sigma_i > 0, \\sum_{i = 1}^K \\sigma_i  = 1 \\right\\}$$\n",
    "$$\\sigma(\\mathbf{z})_j = \\frac{e^{z_j}}{\\sum_{k=1}^K e^{z_k}}$$\n",
    "<p style=\"text-align:center;\">para j = 1, ... , K.</p>\n",
    "\n",
    "<p>No caso da classificação de dígitos as labels possíveis são os algarismos de 0 a 9.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\"><b>Importar dependências</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\"><b>Download dos dados</b></p>\n",
    "<p style=\"text-align:justify;\">O TensorFlow permite efetuar o download e leitura dos dados do MNIST de forma automática, bastando apenas usar o código abaixo. Os dados serão descarregados e gravados na pasta \"MNIST_data\" (criada automáticamente), no local onde o código está a ser executado e, posteriormente, carregados para o programa. É importante realçar o facto de os dados poderem ser carregados já em one-hot encoding (através do parâmetro \"one_hot\").</p>\n",
    "<p style=\"text-align:justify;\">O Output consiste em mensagens de sucesso.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\"><b>Preparar as directorias para o TensorBoard</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"logs\"\n",
    "logdir = \"{}/model-{}/\".format(root_logdir, now)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\"><b>Dataset</b></p>\n",
    "<p style=\"text-align:justify;\">O dataset tem “m” features e “n” observações. Existem “k” labels representativas de cada uma das 10 classes. Assim, considerando um dataset de 100 imagens de dígitos manuscritos de tamanho 28x28 pixels, tem-se: n = 100, m = 28x28 = 784 e k = 10.</p>\n",
    "<p style=\"text-align:justify;\">No código abaixo é possível analisar alguns aspetos do dataset, tais como as dimensões da matriz de features e da matriz target, que contém as labels de cada observação. É também possível constatar que a primeira observação corresponde ao algarismo \"7\", tanto através do plot como através do primeiro vetor one-hot encoded, em que a oitava posição (correspondente a \"7\") é a única a 1.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature matrix: (55000, 784)\n",
      "Shape of target matrix: (55000, 10)\n",
      "One-hot encoding for 1st observation:\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 100 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Shape of feature matrix:\", mnist.train.images.shape)\n",
    "print(\"Shape of target matrix:\", mnist.train.labels.shape)\n",
    "print(\"One-hot encoding for 1st observation:\\n\", mnist.train.labels[0])\n",
    " \n",
    "# visualize data by plotting images\n",
    "fig,ax = plt.subplots(10,10)\n",
    "k = 0\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        ax[i][j].imshow(mnist.train.images[k].reshape(28,28), aspect='auto')\n",
    "        k += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\"><b>Variáveis</b></p>\n",
    "<p style=\"text-align:justify;\">Aqui guardam-se os já conhecidos números de features e de labels em variáveis. Também se define a taxa de aprendizegem, $\\alpha$, como 0.05. Define-se o número de épocas e o tamanho dos batches (subsets do conjunto de treino). É utilizado Minibatch Stochastic Gradient Descent.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of features\n",
    "num_features = 784\n",
    "# number of target labels\n",
    "num_labels = 10\n",
    "# learning rate (alpha)\n",
    "learning_rate = 0.05\n",
    "# batch size\n",
    "batch_size = 128\n",
    "# number of epochs\n",
    "num_steps = 5001\n",
    " \n",
    "# input data\n",
    "train_dataset = mnist.train.images\n",
    "train_labels = mnist.train.labels\n",
    "test_dataset = mnist.test.images\n",
    "test_labels = mnist.test.labels\n",
    "valid_dataset = mnist.validation.images\n",
    "valid_labels = mnist.validation.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\"><b>Grafo de computação</b></p>\n",
    "<p style=\"text-align:justify;\">O TensorFlow usa um grafo dataflow para representar a computação pretendida, em termos de dependências entre operações indivíduais. Isto leva a que se considere este modelo como um modelo de programação de baixo nível no qual se define, primeiro, o grafo dataflow e depois se cria uma sessão TensorFlow, para executar partes do grafo ao longo de um conjunto de máquinas locais e remotas.</p>\n",
    "<p style=\"text-align:justify;\">Um grafo TensorFlow contém dois tipos de informação relevante:</p>\n",
    "<ul>\n",
    "    <li><b>Estrutura do grafo</b> - Os vértices e arestas do grafo, que indicam como as operações individuais são compostas em conjunto, mas não como devem ser usadas.</li>\n",
    "    <li><b>Coleções do grafo</b> - O TensorFlow fornece um mecanismo geral para guardar coleções de metadados num <code>tf.Graph</code>. A função <code>tf.add_to_collection</code> permite associar uma lista de objetos a uma chave (<code>tf.GraphKeys</code> define algumas das chaves standard), e a função <code>tf.get_collection</code> permite ver todos os objetos associados a uma chave.</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"text-align:justify;\">No código abaixo podemos ver que o grafo é guardado na variável graph, através da operação <code>tf.Graph()</code>. De seguida, ao invocar a função <code>as_default()</code> é devolvido um context manager que torna este grafo no grafo default.</p>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a tensorflow graph\n",
    "graph = tf.Graph()\n",
    " \n",
    "with graph.as_default():\n",
    "    \"\"\"\n",
    "    defining all the nodes\n",
    "    \"\"\"\n",
    " \n",
    "    # Inputs\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, num_features), name=\"Train_Dataset\")\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels), name=\"Train_Labels\")\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    " \n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([num_features, num_labels]), name=\"Weights\")\n",
    "    biases = tf.Variable(tf.zeros([num_labels]), name=\"Bias\")\n",
    " \n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                        labels=tf_train_labels, logits=logits))\n",
    " \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    " \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify;\">Alguns pontos importantes a reter:</p>\n",
    "\n",
    "<ul>\n",
    "    <li>Para os dados de treino, utiliza-se <code>tf.placeholder</code>. Um placeholder é apenas uma variável à qual vamos associar informação mais tarde. Permitem criar operações e construir o grafo de computação, sem precisar dos dados no momento de criação. Na terminologia do TensorFlow diz-se que o placeholder vai ser \"alimentado\" em tempo de execução.</li>\n",
    "    <li>Para a matriz de pesos e os valores de bias utiliza-se a classe <code>tf.Variable</code>. Estas variáveis do TensorFlow constituem a melhor forma de representar o estado partilhado e persistente, manipulado pelo nosso programa. Internamente, guardam um tensor persistente. Operações específicas permitem ler e modificar os valores deste tensor. Estas modificações são visíveis ao longo de multiplas <code>tf.Sessions</code>, por isso multiplos workers podem ver os mesmos valores para uma <code>tf.Variable</code>. Também poderia ter sido utilizado <code>tf.get_variable</code>.</li>\n",
    "    <li>A matriz de pesos é inicializada usando valores aleatórios que seguem uma distribuição normal (truncada). É utilizado o método <code>tf.truncated_normal</code>. Os valores de bias são inicializados a zero com o método <code>tf.zeros</code>.</li>\n",
    "    <li>São efetuadas as típicas operações de multiplicação dos inputs pela matriz de pesos seguida da adição dos valores de bias ao resultado da multiplicação. Para a multiplicação (de matrizes) é utilizado <code>tf.matmul</code>, uma das operações de cálculo matricial já definidas no TensorFlow. O resultado é guardado numa variável denominada por <code>logits</code> e corresponde ao vetor das previsões (não normalizadas) que o modelo de classificação gerou e que, geralmente, é depois passado para uma função de normalização. Neste caso, como o modelo resolve um problema de classificação multi-classe, <code>logits</code> será o input da função softmax. A função softmax gera um vetor de probabilidades (normalizadas) com um valor para cada classe possível.</li>\n",
    "    <li>De seguida, calcula-se a função softmax e a função de custo (neste caso, a cross-entropy). Por serem funções muito utilizadas, o TensorFlow possui uma operação que engloba ambas: <code>tf.nn.softmax_cross_entropy_with_logits</code>. Além disso, esta operação pode ser otimizada. Encontra-se a média da cross-entropy, considerando todos os exemplos de treino, utilizando a função <code>tf.reduce_mean</code>.</li>\n",
    "    <li>Minimiza-se o custo usando o gradient descent. Para tal, utiliza-se o optimizer <code>tf.train.GradientDescentOptimizer</code>, incluído na coleção de optimizers do TensorFlow, em <code>tf.train</code>. Utiliza-se o método <code>minimize</code> do optimizer.</li>\n",
    "    <li><code>train_prediction</code>, <code>valid_prediction</code> e <code>test_prediction</code> não fazem parte do treino, mas são necessárias para ir reportando valores de precisão, durante o treino.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\"><b>Execução do grafo de computação</b></p>\n",
    "<p style=\"text-align:justify;\">Após termos construído o grafo de computação, é tempo de executá-lo através de uma sessão. O TensorFlow usa a classe <code>tf.Session</code> para representar a ligação entre o programa cliente - tipicamente, um programa Python - e o runtime C++. Um objeto <code>tf.Session</code> fornece acesso a equipamentos na máquina local e a equipamentos remotos, utilizando o runtime distribuído do TensorFlow. Também guarda informação sobre o <code>tf.Graph</code>, para executar eficientemente a mesma computação, multiplas vezes.</p>\n",
    "<p style=\"text-align:justify;\">Uma sessão é tipicamente utilizada como um context manager (dentro de um bloco \"with\") que termina automaticamente a sessão, quando se sai do bloco.</p>\n",
    "<p style=\"text-align:justify;\">O método <code>tf.Session.run</code> é o principal mecanismo para executar uma <code>tf.Operation</code> ou avaliar um <code>tf.Tensor</code>. É possível passar um ou mais objetos <code>tf.Operation</code> ou <code>tf.Tensor</code> para <code>tf.Session.run</code> e, assim, o TensorFlow executa as operações necessárias para calcular o resultado. <code>tf.Session.run</code> requer que se especifique uma lista de \"fetches\", que determina os valores a retornar e podem ser <code>tf.Operation</code>, <code>tf.Tensor</code> ou um tipo tensor-like tal como <code>tf.Variable</code>. Esses \"fetches\" determinam qual o sub-grafo do <code>tf.Graph</code> a executar para produzir o resultado.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 12.63520336151123\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 9.0%\n",
      "Minibatch loss at step 500: 1.2474206686019897\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 66.1%\n",
      "Minibatch loss at step 1000: 1.0424119234085083\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 75.9%\n",
      "Minibatch loss at step 1500: 1.3145450353622437\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 2000: 0.5827685594558716\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2500: 0.5758383274078369\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 83.3%\n",
      "Minibatch loss at step 3000: 0.6070429682731628\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 84.0%\n",
      "Minibatch loss at step 3500: 0.8440330624580383\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 4000: 0.8456128835678101\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 4500: 0.6035041809082031\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 5000: 1.2652534246444702\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 86.5%\n",
      "\n",
      "Test accuracy: 86.1%\n"
     ]
    }
   ],
   "source": [
    "# utility function to calculate accuracy\n",
    "def accuracy(predictions, labels):\n",
    "    correctly_predicted = np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "    accu = (100.0 * correctly_predicted) / predictions.shape[0]\n",
    "    return accu\n",
    " \n",
    "with tf.Session(graph=graph) as session:\n",
    "    # initialize weights and biases\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    \n",
    "    # initialize file writer to log data and visualize it with TensorBoard\n",
    "    file_writer = tf.summary.FileWriter(logdir, session.graph)\n",
    " \n",
    "    for step in range(num_steps):\n",
    "        # pick a randomized offset\n",
    "        offset = np.random.randint(0, train_labels.shape[0] - batch_size - 1)\n",
    " \n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    " \n",
    "        # Prepare the feed dict\n",
    "        feed_dict = {tf_train_dataset : batch_data,\n",
    "                     tf_train_labels : batch_labels}\n",
    " \n",
    "        # run one step of computation\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction],\n",
    "                                        feed_dict=feed_dict)\n",
    " \n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step {0}: {1}\".format(step, l))\n",
    "            value_train_loss = tf.Summary.Value(tag='Train_loss',simple_value=l)\n",
    "            summary = tf.Summary(value=[value_train_loss])\n",
    "            file_writer.add_summary(summary, step)\n",
    "            \n",
    "            train_accuracy = accuracy(predictions, batch_labels)\n",
    "            print(\"Minibatch accuracy: {:.1f}%\".format(train_accuracy))\n",
    "            \n",
    "            validation_accuracy = accuracy(valid_prediction.eval(), valid_labels)\n",
    "            print(\"Validation accuracy: {:.1f}%\".format(validation_accuracy))\n",
    "            \n",
    "            # log data\n",
    "            value_train = tf.Summary.Value(tag='Train_accuracy',simple_value=train_accuracy)\n",
    "            value_validation = tf.Summary.Value(tag='Validation_accuracy',simple_value=validation_accuracy)\n",
    "\n",
    "            summary = tf.Summary(value=[value_train,value_validation])\n",
    "            file_writer.add_summary(summary, step)\n",
    " \n",
    "    print(\"\\nTest accuracy: {:.1f}%\".format(\n",
    "        accuracy(test_prediction.eval(), test_labels)))\n",
    "    file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify;\">Alguns pontos importantes a reter:</p>\n",
    "\n",
    "<ul>\n",
    "    <li style=\"text-align:justify;\">Apenas após executar <code>tf.global_variables_initializer()</code>, numa sessão, é que as variáveis irão conter os valores com os quais foram declaradas (por exemplo: <code>tf.Variable(tf.zeros(...))</code>, <code>tf.Variable(tf.random_normal(...))</code>,...).</li>\n",
    "    <li style=\"text-align:justify;\">Em cada iteração, um minibatch é selecionado, ao escolher um valor de offset aleatório, usando a instrução <code>np.random.randint</code>.</li>\n",
    "    <li style=\"text-align:justify;\">Observa-se que <code>tf.Session.run</code> também pode receber um dicionário de \"feeds\", correspondente a mapeamentos de objetos <code>tf.Tensor</code> (tipicamente tensores <code>tf.placeholder</code>) para valores (tipicamente escalares e listas do Python ou arrays do NumPy) que irão ser substituídos para esses tensores na execução. Neste caso, para \"alimentar\" os placeholders <code>tf_train_dataset</code> e <code>tf_train_label</code>, criou-se o dicionário <code>feed_dict</code>.</li>\n",
    "    <li style=\"text-align:justify;\">A instrução <code>session.run()</code> devolve os novos valores de custo e previsões após completar o passo de optimização.</li>\n",
    "    <li style=\"text-align:justify;\">Os resultados de custo e precisão de treino e validação vão sendo mostrados a cada 500 passos (dos 5001). No final do treino, testa-se o modelo, com o conjunto de teste.</li>\n",
    "    <li style=\"text-align:justify;\">Os resultados de precisão são obtidos através da função <code>t.eval()</code>. Esta função é equivalente a <code>tf.get_default_session().run(t)</code>, sendo que, neste caso, a default session corresponde à variável <code>session</code>. Utilizar <code>eval()</code> apenas permite o \"fetch\" do valor de um tensor em cada passo.</li>\n",
    "    <li style=\"text-align:justify;\">É recomendável que se experimente variar os valores dos parâmetros, como o learning rate, tamanho do batch, número de épocas, entre outros, para alcançar melhores resultados. Utilizar outro optimizer também seria o ideal, como por exemplo o <code>tf.train.AdamOptimizer</code>.</li>\n",
    "    <li style=\"text-align:justify;\">A precisão do modelo poderia ser melhorada utilizando uma rede neuronal com uma ou mais camadas ocultas.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\"><b>TensorBoard</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![alt text](mnist_tensorboard_graph.png \"Grafo de computação\")\n",
    "<p style=\"text-align:center;\">Grafo de computação</p>\n",
    "![alt text](mnist_tensorboard_scalars_train.png \"Precisão e Custo - Treino\")\n",
    "<p style=\"text-align:center;\">Gráficos de precisão e custo - Treino</p>\n",
    "![alt text](mnist_tensorboard_scalars_val.png \"Precisão - Validação\")\n",
    "<p style=\"text-align:center;\">Gráfico de precisão - Validação</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>CIFAR-10 - Redes neuronais de convolução</h2>\n",
    "\n",
    "<p style=\"text-align:justify;\">O dataset CIFAR-10 (Canadian Institute For Advanced Research) é uma coleção de imagens geralmente usadas para treinar algoritmos de machine learning ou visão computacional. É um dos datasets mais utilizados para investigação em machine learning. Contém 60000 imagens a cor de 32x32 pixels, agrupadas em 10 classes distintas: aviões, carros, aves, gatos, veados, cães, sapos, cavalos, barcos e camiões. Existem 6000 imagens em cada classe.</p>\n",
    "\n",
    "\n",
    "<p style=\"text-align:justify;\">Normalmente, algoritmos computacionais para reconhecer objetos em fotografias aprendem por exemplo. CIFAR-10 é um conjunto de imagens que pode ser utilizado para ensinar um computador a reconhecer objetos. Já que as imagens deste dataset são de baixa resolução (32x32), permite aos investigadores experimentar diversos algoritmos, de forma rápida, para observar qual funciona. Vários tipos de redes neuronais de convolução tendem a ser a melhor solução para reconhecer imagens no CIFAR-10.</p>\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/944/1*6XQqOifwnmplS22zCRRVaw.png\" alt=\"CIFAR-10\" width=\"500\" height=\"600\">\n",
    "<p style=\"text-align:center;\">Exemplos de imagens do dataset CIFAR-10</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\"><b>Custom Estimators e Layers</b></p>\n",
    "<p style=\"text-align:justify;\">O principal objetivo deste tutorial consiste em resolver o problema de classificação do CIFAR-10, com redes neuronais de convolução, utilizando a API de Custom Estimators e a classe Layers do TensorFlow.</p>\n",
    "<p style=\"text-align:justify;\">Será criado um Estimator (classe do TensorFlow para treino, avaliação e inferência de modelos de alto-nível) para o modelo. É possível utilizar os pre-made Estimators que o TensorFlow já fornece ou então criar o nosso próprio custom Estimator (será este o caso).</p>\n",
    "<p style=\"text-align:justify;\">O módulo de layers do TensorFlow oferece uma API de alto-nível que torna fácil construir uma rede neuronal. Fornece métodos que facilitam a criação de camadas densas (fully connected) e camadas de convolução, adicionando funções de ativação e aplicando regularização através de dropout.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\"><b>Redes Neuronais de Convolução</b></p>\n",
    "\n",
    "<p style=\"text-align:justify;\">Atualmente, Redes Neuronais de Convolução (CNNs) constituem a arquitetura de modelo state-of-the-art para classificação de imagem. As CNNs aplicam vários filtros à informação dos pixeis (raw) de uma imagem para extrair e aprender features de um nível mais alto, que o modelo pode depois utilizar para classificação:</p>\n",
    "\n",
    "<ul>\n",
    "\n",
    "<li style=\"text-align:justify;\"><b>Camadas de Convolução</b>, que aplicam um número específico de filtros de convolução à imagem. Para cada sub-região, a camada executa um conjunto de operações matemáticas para produzir um único valor no mapa de features de output. Depois, tipicamente, estas camadas aplicam a função de ativação ReLU ao output para introduzir não-linearidade no modelo.</li>\n",
    "\n",
    "<li style=\"text-align:justify;\"><b>Camadas de Pooling</b>, que reduzem a resolução da informação da imagem extraída pelas camadas de convolução, para reduzir a dimensionalidade do mapa de features e assim diminuir o tempo de processamento. Um algoritmo frequentemente utilizado é o max pooling, que extrai sub-regiões do mapa de features (p.ex: blocos de 2x2 pixels), mantém o seu valor máximo e descarta todos os outros valores.</li>\n",
    "\n",
    "<li style=\"text-align:justify;\"><b>Camadas Densas (fully connected)</b>, que executam classificação nas features extraídas pelas camadas de convolução e \"downsampled\" pelas camadas de pooling. Numa camada densa, todos os nós da camada estão ligados a todos os nós da camada seguinte.</li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "<p style=\"text-align:justify;\">Normalmente, uma CNN é composta por uma pilha de módulos de convolução que executam a extração de features. Cada módulo consiste numa camada de convolução seguida de uma camada de pooling. O último módulo é seguido de uma ou mais camadas densas que efetuam a classificação. A camada densa final numa CNN contém um só nó para cada classe alvo no modelo (todas as possíveis classes que o modelo pode prever), com uma função de ativação softmax para gerar um valor entre 0 e 1 para cada nó (a soma de todos estes valores softmax é igual a 1). Pode-se interpretar os valores softmax para uma determinada imagem como medidas relativas acerca de quão provável é essa imagem pertencer a uma classe alvo.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\"><b>Arquitetura da Rede</b></p>\n",
    "\n",
    "<p style=\"text-align:justify;\">Será criado um modelo para classificar as imagens do dataset CIFAR-10 com a seguinte arquitetura CNN:</p>\n",
    "\n",
    "<ol>\n",
    "\n",
    "<li style=\"text-align:justify;\"><b>Camada de Convolução 1</b>: Aplica 64 filtros 5x5 (extraí 5x5 sub-regiões de pixels), com função de ativação ReLU.</li>\n",
    "\n",
    "<li style=\"text-align:justify;\"><b>Camada de Pooling 1</b>: Executa max pooling com filtro 2x2 e stride de 2 (regiões pooled não se sobrepõem).</li>\n",
    "\n",
    "<li style=\"text-align:justify;\"><b>Local Response Normalization 1</b></li>\n",
    "\n",
    "<li style=\"text-align:justify;\"><b>Camada de Convolução 2</b>: Aplica 64 filtros 5x5, com função de ativação ReLU.</li>\n",
    "\n",
    "<li style=\"text-align:justify;\"><b>Local Response Normalization 2</b></li>\n",
    "\n",
    "<li style=\"text-align:justify;\"><b>Camada de Pooling 2</b>: Executa max pooling com filtro 2x2 e stride de 2.</li>\n",
    "\n",
    "<li style=\"text-align:justify;\"><b>Camada Densa (fully connected) 1</b>: 1024 neurónios, com taxa de regularização dropout de 0.4 (qualquer elemento possui probabilidade de 0.4 de ser ignorado, durante o treino).</li>\n",
    "\n",
    "<li style=\"text-align:justify;\"><b>Camada Densa (fully connected) 2</b>: 512 neurónios, com taxa de regularização dropout de 0.4 (qualquer elemento possui probabilidade de 0.4 de ser ignorado, durante o treino).</li>\n",
    "\n",
    "<li style=\"text-align:justify;\"><b>Camada Densa 3 (Camada de Logits)</b>: 10 neurónios, um para cada classe alvo de imagens.</li>\n",
    "\n",
    "</ol>\n",
    "\n",
    "<p style=\"text-align:justify;\">O módulo <code>tf.layers</code> contém métodos para criar cada um dos três tipos de camadas descritas anteriormente:</p>\n",
    "\n",
    "<ul>\n",
    "\n",
    "<li style=\"text-align:justify;\"><code>conv2d()</code>: Constrói uma camada de convolução de duas dimensões. Recebe como argumentos o número de filtros, tamanho do kernel do filtro, padding e função de ativação.</li>\n",
    "\n",
    "<li style=\"text-align:justify;\"><code>max_pooling2d()</code>: Constrói uma camada de pooling de duas dimensões, utilizando o algoritmo max-pooling. Recebe como argumentos o tamanho do filtro de pooling e stride.</li>\n",
    "\n",
    "<li style=\"text-align:justify;\"><code>dense()</code>: Constrói uma camada densa. Recebe o número de neurónios e a função de ativação como argumentos.</li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "<p style=\"text-align:justify;\">Cada um destes métodos aceita um tensor como input e retorna um tensor transformado como output. Isto torna fácil ligar uma camada a outra: basta receber o output de uma camada e fornecê-lo como input a outra.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cifar10_data\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 32, 32, 3])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "  \n",
    "    # Norm 1\n",
    "    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm1')\n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=norm1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  \n",
    "    # Norm 2\n",
    "    norm2 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm2')\n",
    "  \n",
    "    # Pooling Layer #2  \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=norm2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dense Layer 1\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 8 * 8 * 64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "  \n",
    "    # Dense Layer 2\n",
    "    dense2 = tf.layers.dense(inputs=dropout, units=512, activation=tf.nn.relu)\n",
    "    dropout2 = tf.layers.dropout(\n",
    "      inputs=dense2, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout2, units=10)\n",
    "\n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        # Write to TensorBoard\n",
    "        tf.summary.scalar(\"loss_train\", loss)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    accuracy = tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])\n",
    "\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": accuracy}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\"><b>Download dos dados e criação e execução do Estimator</b></p>\n",
    "\n",
    "<p style=\"text-align:justify;\">No código abaixo começa-se por se efetuar o download dos conjuntos de treino e teste do CIFAR-10. O script Python cifar10_data que trata do download é importado. O código não será mostrado no tutorial, contudo, o ficheiro está na pasta enviada.</p>\n",
    "\n",
    "<p style=\"text-align:justify;\">De seguida, cria-se o Estimator através de <code>tf.estimator.Estimator</code>. O parâmetro model_fn corresponde à função do modelo para usar para treino, avaliação e previsão; portanto, é passada a função <code>cnn_model_fn</code>. O argumento model_dir especifica a directoria onde a informação sobre o modelo (checkpoints) será gravada (neste caso, será em \"/tmp/cifar10_convnet_model\").</p>\n",
    "\n",
    "<p style=\"text-align:justify;\">Como as CNNs podem demorar muito tempo a treinar, é benéfico configurar algum tipo de logging para se ir acompanhando o progresso durante o treino. É possível utilizar <code>tf.train.SessionRunHook</code>, do TensorFlow, para criar um <code>tf.train.LoggingTensorHook</code> que vai efetuando o log dos valores de probabilidade da camada softmax da CNN. Para tal, guarda-se um dicionário dos tensors dos quais se pretende fazer log, em tensors_to_log. Cada chave é uma label à escolha que será impressa no output do log e o valor correspondente é o nome de um tensor no grafo do TensorFlow. Aqui, as probabilidades podem ser encontrados em softmax_tensor, o nome que foi dado à operação de softmax, anteriormente, quando se geraram as probabilidades em cnn_model_fn. De seguida, cria-se o LoggingTensorHook, passando tensors_to_log para o argumento \"tensors\". Define-se every_n_iter = 100, que especifica que o log das probabilidades deve ser feito a cada 100 passos de treino.</p>\n",
    "\n",
    "<p style=\"text-align:justify;\">Agora é o momento de treinar o modelo, o que pode ser feito ao criar train_input_fn e chamar a função <code>train()</code> no cifar10_classifier. Na chamada <code>tf.estimator.inputs.numpy_input_fn</code>, passam-se os dados de treino para o argumento x (dicionário) e as labels de treino para y. Define-se um batch size de 100 (o que significa que o modelo vai efetuar o treino com minibatches de 100 exemplos, em cada passo). Define-se num_epochs=None, o que significa que o modelo vai treinar até se alcançar o número especificado de passos. Define-se shuffle=True para baralhar os dados de treino. O número de passos é definido como steps=1000 (o que significa que o modelo vai treinar durante 1000 passos). É também passado o logging_hook para o argumento hooks, para se ir fazendo logging durante o treino.</p>\n",
    "\n",
    "<p style=\"text-align:justify;\">Assim que o treino estiver completo, pretende-se avaliar o modelo para determinar a sua precisão no conjunto de teste do CIFAR-10. Invoca-se o método <code>evaluate()</code> que avalia as métricas especificadas no argumento eval_metric_ops no model_fn. Para criar eval_input_fn, define-se num_epochs=1, para que o modelo avalie as métricas tendo em conta uma época de dados. Define-se shuffle=False para se iterar sobre os dados de forma sequencial.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_1\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_2\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_3\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_4\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_5\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/test_batch\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/cifar10_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025AA3BEDCC0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/cifar10_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.12478982 0.09453356 0.10214605 0.11478541 0.08536987 0.10892936\n",
      "  0.10386928 0.07385141 0.09347181 0.09825351]\n",
      " [0.09872072 0.10344662 0.11159948 0.11243124 0.08901703 0.09906881\n",
      "  0.10199565 0.09553163 0.08372208 0.10446677]\n",
      " [0.14809854 0.09969892 0.10719782 0.12740883 0.09619211 0.08361748\n",
      "  0.11110742 0.06652088 0.07407782 0.08608019]\n",
      " [0.12126567 0.11912755 0.09087562 0.10458526 0.08624963 0.09582748\n",
      "  0.11858331 0.08718276 0.0889691  0.08733369]\n",
      " [0.09693987 0.09733263 0.12286937 0.11831158 0.09196049 0.08749796\n",
      "  0.13381965 0.0825815  0.08819056 0.08049644]\n",
      " [0.10459953 0.09833925 0.11827195 0.13213626 0.09288753 0.09678193\n",
      "  0.109434   0.08014607 0.08146003 0.08594345]\n",
      " [0.12530687 0.09531888 0.12707078 0.09792588 0.11117085 0.08466511\n",
      "  0.1208148  0.10214366 0.0643406  0.07124265]\n",
      " [0.14660053 0.08211473 0.12039955 0.10918929 0.09400804 0.0985461\n",
      "  0.11961189 0.07939835 0.0672349  0.0828966 ]\n",
      " [0.11615539 0.09939314 0.10855702 0.10874997 0.09196796 0.08571672\n",
      "  0.10878212 0.09681267 0.0913335  0.09253144]\n",
      " [0.10490059 0.10800184 0.10213665 0.11851979 0.10109417 0.09331295\n",
      "  0.10187274 0.08081004 0.0852854  0.10406586]\n",
      " [0.11467683 0.0776106  0.11814585 0.11775383 0.09078547 0.11463785\n",
      "  0.10949896 0.08922978 0.08168157 0.08597931]\n",
      " [0.11307064 0.10355032 0.10010628 0.11249255 0.09664302 0.09559004\n",
      "  0.11113147 0.10295033 0.08981718 0.07464808]\n",
      " [0.131169   0.10629687 0.12056039 0.10477789 0.08049095 0.09321366\n",
      "  0.11018397 0.0743036  0.08591963 0.0930841 ]\n",
      " [0.11891995 0.09059276 0.104844   0.11593287 0.08157858 0.0873484\n",
      "  0.11389019 0.10038774 0.08276483 0.1037406 ]\n",
      " [0.13044468 0.11769759 0.11159532 0.12772131 0.1002194  0.09897467\n",
      "  0.09285327 0.07642593 0.08109436 0.06297345]\n",
      " [0.13589956 0.0872687  0.09281541 0.12457953 0.09153473 0.09478756\n",
      "  0.09602967 0.10151002 0.1048074  0.07076735]\n",
      " [0.11844733 0.09495137 0.13078424 0.16519915 0.08476024 0.07578003\n",
      "  0.110197   0.068227   0.08029892 0.07135463]\n",
      " [0.13481109 0.09294798 0.09494799 0.11343809 0.09373992 0.09507514\n",
      "  0.10347531 0.08807854 0.09819854 0.08528747]\n",
      " [0.11514679 0.08883803 0.10723852 0.11841834 0.09999694 0.09568539\n",
      "  0.12347182 0.08164328 0.08500607 0.0845548 ]\n",
      " [0.1158313  0.07724731 0.13145544 0.10658392 0.10557095 0.11435672\n",
      "  0.10312565 0.08116173 0.07440749 0.09025952]\n",
      " [0.12264837 0.0832774  0.09453595 0.13394602 0.09629338 0.09548442\n",
      "  0.13021018 0.08228049 0.08021399 0.08110987]\n",
      " [0.12004065 0.07635198 0.09327449 0.10902509 0.10424037 0.10474746\n",
      "  0.13706316 0.09011649 0.08346105 0.08167921]\n",
      " [0.12485737 0.09333345 0.08832024 0.12100529 0.08534332 0.10338206\n",
      "  0.12107859 0.08977023 0.08984958 0.08305983]\n",
      " [0.1339739  0.08957937 0.08165718 0.120355   0.09719154 0.11467344\n",
      "  0.09375157 0.09932363 0.09504866 0.07444575]\n",
      " [0.12673353 0.0846139  0.11349174 0.12071743 0.09400718 0.08782656\n",
      "  0.13667619 0.07640345 0.08252591 0.07700413]\n",
      " [0.09197062 0.10026655 0.0880333  0.12515752 0.10100153 0.10473907\n",
      "  0.09501962 0.11302835 0.09344217 0.08734136]\n",
      " [0.09827883 0.10980562 0.1017653  0.14818998 0.07891548 0.08611051\n",
      "  0.10628887 0.0845596  0.09741132 0.0886744 ]\n",
      " [0.11973315 0.09205251 0.12435117 0.11269048 0.08451582 0.08371085\n",
      "  0.08965411 0.1011706  0.08989659 0.10222469]\n",
      " [0.12799907 0.11849685 0.09992728 0.11028665 0.0963831  0.09551689\n",
      "  0.10418379 0.07997532 0.09177211 0.07545892]\n",
      " [0.12276128 0.07804977 0.13085325 0.10592365 0.11543805 0.1062846\n",
      "  0.13246185 0.08217827 0.07322536 0.05282389]\n",
      " [0.1434299  0.09022381 0.10243853 0.13936755 0.07977314 0.10821294\n",
      "  0.09913415 0.08523997 0.07097884 0.08120126]\n",
      " [0.12293427 0.12276869 0.09081022 0.11521928 0.09018987 0.09978351\n",
      "  0.10267708 0.09316286 0.08649149 0.07596266]\n",
      " [0.13165547 0.07794775 0.09545267 0.11290432 0.09692196 0.08614192\n",
      "  0.14484824 0.0868986  0.08721975 0.08000941]\n",
      " [0.10728782 0.15024653 0.09382803 0.19994609 0.07943033 0.05829277\n",
      "  0.13922781 0.06565829 0.04324788 0.06283436]\n",
      " [0.11270794 0.09711438 0.13651241 0.09932744 0.12051308 0.07949161\n",
      "  0.11466905 0.08911886 0.07589898 0.07464613]\n",
      " [0.12846175 0.12341661 0.0891627  0.10375722 0.08636492 0.08840239\n",
      "  0.11553444 0.08031719 0.11000077 0.07458196]\n",
      " [0.13667533 0.1059863  0.08036055 0.13494323 0.0676716  0.0685501\n",
      "  0.12962073 0.08238497 0.10807182 0.08573548]\n",
      " [0.16153376 0.08545172 0.11073535 0.11028621 0.08699846 0.0749291\n",
      "  0.13021094 0.06850608 0.09501311 0.07633528]\n",
      " [0.0990529  0.09811451 0.11759134 0.09407703 0.08580948 0.09406733\n",
      "  0.11221772 0.10915738 0.09474686 0.09516547]\n",
      " [0.11299036 0.08796897 0.12210353 0.09089113 0.11170586 0.09915636\n",
      "  0.10461067 0.1000099  0.08757205 0.08299119]\n",
      " [0.10650782 0.0949972  0.11660727 0.11947822 0.09047087 0.09909507\n",
      "  0.11111486 0.0889502  0.08081122 0.09196723]\n",
      " [0.11656111 0.09299166 0.11485463 0.11174412 0.09265818 0.09312661\n",
      "  0.1077541  0.08423973 0.0940907  0.09197914]\n",
      " [0.12867557 0.09952441 0.09301192 0.10602445 0.10459369 0.09717228\n",
      "  0.09666441 0.10181912 0.09281413 0.07970003]\n",
      " [0.10673092 0.12529504 0.12780425 0.15507397 0.07687526 0.11547104\n",
      "  0.0844384  0.08305258 0.06125041 0.06400806]\n",
      " [0.12092363 0.10668194 0.09492247 0.1103673  0.0759061  0.09147722\n",
      "  0.13054912 0.08719537 0.08911372 0.09286309]\n",
      " [0.13396734 0.11645894 0.09350608 0.10325842 0.0778239  0.11140691\n",
      "  0.1087579  0.08401129 0.07155189 0.09925736]\n",
      " [0.12627023 0.08528847 0.11862905 0.11165562 0.08090251 0.11664882\n",
      "  0.10153532 0.07665196 0.10066462 0.08175348]\n",
      " [0.08453643 0.09357312 0.11817638 0.13301113 0.08936197 0.11006236\n",
      "  0.10843346 0.07977533 0.07955844 0.10351145]\n",
      " [0.18598539 0.09107222 0.09953204 0.11456073 0.09322843 0.07539723\n",
      "  0.12300216 0.06666268 0.08723669 0.06332249]\n",
      " [0.13358714 0.09787689 0.09585759 0.1356089  0.08495425 0.08633669\n",
      "  0.12447755 0.07297891 0.07983287 0.08848919]\n",
      " [0.12913893 0.11214078 0.11303112 0.1476438  0.06963908 0.08690821\n",
      "  0.12703793 0.06426144 0.06272165 0.0874771 ]\n",
      " [0.1744024  0.09901305 0.07049974 0.11481948 0.08084277 0.10312977\n",
      "  0.12073625 0.07141164 0.08857662 0.07656828]\n",
      " [0.11035804 0.08406612 0.1183091  0.09907658 0.10104828 0.09298515\n",
      "  0.1099521  0.10500872 0.09286673 0.0863291 ]\n",
      " [0.13462844 0.07636625 0.08723594 0.10293322 0.09055611 0.1003343\n",
      "  0.13131021 0.08593448 0.09838421 0.09231687]\n",
      " [0.10316478 0.09463793 0.10328554 0.10741778 0.09913221 0.09930024\n",
      "  0.11307976 0.0973121  0.09373122 0.08893853]\n",
      " [0.11819664 0.08843663 0.11341269 0.11363516 0.10549871 0.09362351\n",
      "  0.11541272 0.0937871  0.08117227 0.0768246 ]\n",
      " [0.1357581  0.09699783 0.1109446  0.1249821  0.10255913 0.08958536\n",
      "  0.09271447 0.08325242 0.07919349 0.08401254]\n",
      " [0.1127385  0.10785663 0.09461669 0.11213349 0.08605959 0.09023017\n",
      "  0.10534286 0.08919172 0.09480085 0.10702951]\n",
      " [0.11955389 0.09453325 0.1054825  0.12989196 0.08271951 0.09320548\n",
      "  0.1135224  0.08645419 0.08014785 0.09448889]\n",
      " [0.11022715 0.09154583 0.08728866 0.13837148 0.08866474 0.11809955\n",
      "  0.1043216  0.06936468 0.1020691  0.09004718]\n",
      " [0.12297355 0.1186951  0.10865308 0.10527191 0.08346394 0.10464001\n",
      "  0.11889391 0.07733531 0.08929018 0.07078294]\n",
      " [0.11515183 0.10604288 0.09897303 0.12177737 0.10023331 0.08480494\n",
      "  0.09786355 0.08385637 0.10610341 0.08519321]\n",
      " [0.12894037 0.11550181 0.09196285 0.11410151 0.08869589 0.09274997\n",
      "  0.1150967  0.09384762 0.08399677 0.07510648]\n",
      " [0.13146448 0.08917426 0.10665339 0.10477769 0.08732641 0.0868412\n",
      "  0.10077898 0.10112572 0.10358334 0.08827455]\n",
      " [0.1515114  0.08414029 0.09272419 0.11906303 0.09284307 0.101441\n",
      "  0.10720142 0.08764148 0.07340954 0.09002464]\n",
      " [0.11645937 0.10413381 0.10171167 0.11778416 0.09037289 0.0919594\n",
      "  0.12116174 0.09323141 0.07694988 0.08623567]\n",
      " [0.12522845 0.10072593 0.10133385 0.10141554 0.08251496 0.09975188\n",
      "  0.12730947 0.10296021 0.08601196 0.07274772]\n",
      " [0.11139616 0.08473244 0.11167927 0.15932575 0.078286   0.11862733\n",
      "  0.0933094  0.08727005 0.06712662 0.0882469 ]\n",
      " [0.11187291 0.09258921 0.11499961 0.10665573 0.11724687 0.09438649\n",
      "  0.09775548 0.10070919 0.07854199 0.08524252]\n",
      " [0.10683571 0.08363432 0.10473841 0.11555298 0.10205135 0.07976134\n",
      "  0.12438852 0.10242414 0.09406652 0.08654669]\n",
      " [0.10828155 0.09526803 0.09773409 0.10848892 0.08949156 0.0998761\n",
      "  0.11248267 0.0777582  0.11032376 0.1002951 ]\n",
      " [0.12450194 0.07266026 0.1142812  0.11366377 0.09533858 0.11023766\n",
      "  0.12196825 0.0899303  0.06732931 0.09008869]\n",
      " [0.13299713 0.0773611  0.09056787 0.11425108 0.0868403  0.09900097\n",
      "  0.15209644 0.06406788 0.10770005 0.0751173 ]\n",
      " [0.11361012 0.12054839 0.16001548 0.11925603 0.08253291 0.08334396\n",
      "  0.09888881 0.08706737 0.06211022 0.07262672]\n",
      " [0.11552399 0.09010235 0.08854964 0.12079845 0.122154   0.12373112\n",
      "  0.10899988 0.0861885  0.06577746 0.07817454]\n",
      " [0.13577855 0.10454769 0.09979534 0.10700863 0.09183975 0.1066094\n",
      "  0.10533509 0.07993829 0.07556319 0.093584  ]\n",
      " [0.14749572 0.1180996  0.12009304 0.11809777 0.07577503 0.0866373\n",
      "  0.10633333 0.0812723  0.07135382 0.07484201]\n",
      " [0.16332561 0.08108277 0.07421469 0.12007511 0.08468646 0.09334467\n",
      "  0.1308338  0.09044826 0.07922668 0.08276205]\n",
      " [0.11848087 0.07150914 0.12292875 0.10739662 0.09872983 0.12114663\n",
      "  0.12612021 0.08897113 0.07536667 0.06935024]\n",
      " [0.1515012  0.1314618  0.08202735 0.11541445 0.1032292  0.07779218\n",
      "  0.09740368 0.07775959 0.09163547 0.07177518]\n",
      " [0.10901118 0.09538954 0.10957845 0.12027977 0.09526341 0.09612505\n",
      "  0.10727125 0.09262269 0.08266    0.09179859]\n",
      " [0.10912802 0.09582119 0.10034125 0.10572156 0.09434546 0.1017649\n",
      "  0.10223495 0.10331219 0.09814648 0.08918409]\n",
      " [0.13899523 0.13072383 0.09030501 0.09918275 0.08406927 0.11489767\n",
      "  0.11529937 0.07467382 0.07810686 0.07374633]\n",
      " [0.14077127 0.0882517  0.1152076  0.08778341 0.08312805 0.10436916\n",
      "  0.13543825 0.09730681 0.07345517 0.07428859]\n",
      " [0.11471815 0.11931665 0.10632409 0.1346533  0.07381868 0.09150512\n",
      "  0.11966494 0.07625052 0.08276448 0.0809841 ]\n",
      " [0.10807613 0.10429697 0.1331569  0.13844788 0.09428543 0.09046733\n",
      "  0.10498089 0.0652182  0.08845109 0.07261919]\n",
      " [0.11176727 0.0823119  0.10102048 0.1275473  0.08701141 0.10463543\n",
      "  0.12064848 0.0891526  0.08179541 0.09410974]\n",
      " [0.12671381 0.09425148 0.10127918 0.10949366 0.11173276 0.10626464\n",
      "  0.10747703 0.07012913 0.08103105 0.09162729]\n",
      " [0.097477   0.09095712 0.10353845 0.10857356 0.09693425 0.09786218\n",
      "  0.10831044 0.10310429 0.09883729 0.09440546]\n",
      " [0.112451   0.12957841 0.1393787  0.09747579 0.06846672 0.08307274\n",
      "  0.12097648 0.08422628 0.09113716 0.07323677]\n",
      " [0.16410907 0.08596    0.10579239 0.12196321 0.07856733 0.08169516\n",
      "  0.10625841 0.08208415 0.08694468 0.08662567]\n",
      " [0.13598154 0.09073593 0.09312716 0.15773001 0.08555477 0.06920943\n",
      "  0.1108133  0.09765485 0.0744414  0.08475163]\n",
      " [0.13280684 0.11241493 0.11638161 0.09758407 0.09509978 0.0955299\n",
      "  0.11650421 0.08526529 0.07129934 0.07711416]\n",
      " [0.12529707 0.09867558 0.10831016 0.1314825  0.07842292 0.07588916\n",
      "  0.11308162 0.07339428 0.1069107  0.08853596]\n",
      " [0.14609344 0.10886908 0.0986544  0.11938294 0.06878612 0.1134844\n",
      "  0.0839824  0.09345846 0.08206249 0.08522626]\n",
      " [0.11507776 0.09674428 0.10439155 0.11592266 0.07996493 0.08011992\n",
      "  0.11213856 0.08061774 0.10426781 0.11075479]\n",
      " [0.13372044 0.09714223 0.09701509 0.10381757 0.08108864 0.08907892\n",
      "  0.15416645 0.05441197 0.09392896 0.09562975]\n",
      " [0.1384603  0.09200674 0.11761599 0.16080399 0.06888126 0.09178622\n",
      "  0.11048382 0.08200496 0.07618868 0.06176814]\n",
      " [0.13135795 0.10636135 0.08672365 0.125388   0.09515332 0.08027471\n",
      "  0.10545681 0.09280653 0.08870509 0.08777253]\n",
      " [0.13378732 0.08840944 0.1253704  0.12516223 0.06918551 0.10492966\n",
      "  0.14422995 0.06279854 0.0576662  0.08846071]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.3104017, step = 1\n",
      "INFO:tensorflow:global_step/sec: 2.99378\n",
      "INFO:tensorflow:probabilities = [[0.12179022 0.05696849 0.08405156 0.12417798 0.05823662 0.15515766\n",
      "  0.05502829 0.04896527 0.17542183 0.12020219]\n",
      " [0.06402117 0.01672421 0.18160942 0.25051853 0.1615546  0.20946614\n",
      "  0.03997101 0.05270808 0.01568012 0.00774684]\n",
      " [0.05289187 0.00312123 0.15141039 0.04246603 0.5355987  0.03190714\n",
      "  0.11187497 0.06220208 0.00414019 0.00438746]\n",
      " [0.00438485 0.00258498 0.12220469 0.08589025 0.37195262 0.04863474\n",
      "  0.31555507 0.04667694 0.00109281 0.00102305]\n",
      " [0.03954758 0.02099438 0.10646966 0.14763373 0.13816002 0.07978015\n",
      "  0.3625199  0.07952599 0.0064044  0.0189642 ]\n",
      " [0.29718173 0.07767607 0.06180236 0.03620509 0.0479196  0.01977314\n",
      "  0.01608026 0.07308667 0.23122618 0.13904889]\n",
      " [0.05090672 0.02347205 0.12189018 0.08648676 0.21276231 0.1254963\n",
      "  0.21199195 0.14647058 0.0101086  0.01041448]\n",
      " [0.13344991 0.4225094  0.00811756 0.02987848 0.0024957  0.00696988\n",
      "  0.0246794  0.02018385 0.03301296 0.3187029 ]\n",
      " [0.27582937 0.11813561 0.02574398 0.00668305 0.01586615 0.00116494\n",
      "  0.0031706  0.06211238 0.0455831  0.4457108 ]\n",
      " [0.0165763  0.00109395 0.16659878 0.01894155 0.5901785  0.01906932\n",
      "  0.14089075 0.04476447 0.00106986 0.00081652]\n",
      " [0.08346945 0.526346   0.01812142 0.02019295 0.00222325 0.0071844\n",
      "  0.00530032 0.00200427 0.13432668 0.20083135]\n",
      " [0.55714834 0.05422779 0.01140848 0.0035125  0.00331834 0.00048427\n",
      "  0.00035198 0.00080545 0.34351364 0.02522922]\n",
      " [0.5914676  0.21273245 0.02204128 0.02523341 0.00597384 0.00845478\n",
      "  0.00329565 0.00621375 0.09877763 0.0258096 ]\n",
      " [0.07773916 0.00755519 0.2785141  0.19936717 0.17817324 0.09634233\n",
      "  0.0863325  0.03176293 0.03704104 0.00717229]\n",
      " [0.0872102  0.11919125 0.06294784 0.23400392 0.05178514 0.12319551\n",
      "  0.08910267 0.05413992 0.10557722 0.07284635]\n",
      " [0.09212673 0.60151935 0.03921431 0.00838672 0.0071448  0.00658025\n",
      "  0.00216736 0.00226393 0.16469009 0.07590646]\n",
      " [0.06312317 0.04980965 0.0778109  0.16389777 0.09339786 0.1841122\n",
      "  0.22801805 0.06011011 0.04932037 0.03039992]\n",
      " [0.1616838  0.03467161 0.00333223 0.00045017 0.00049804 0.00017075\n",
      "  0.00001985 0.00004101 0.7943386  0.0047939 ]\n",
      " [0.7754374  0.00272708 0.0300086  0.00760421 0.01567341 0.00702729\n",
      "  0.00066302 0.03455408 0.099656   0.02664884]\n",
      " [0.18624584 0.01149109 0.0829671  0.0428331  0.13692386 0.03862363\n",
      "  0.16211157 0.2777039  0.01268084 0.04841911]\n",
      " [0.2021665  0.01214112 0.23276958 0.11471011 0.13741603 0.06890902\n",
      "  0.03542945 0.07020169 0.08538873 0.04086775]\n",
      " [0.10208016 0.00819907 0.18928368 0.06676468 0.26782537 0.10621549\n",
      "  0.07066474 0.1478946  0.02795746 0.01311471]\n",
      " [0.02798389 0.0072224  0.17823513 0.28507653 0.18084913 0.18267265\n",
      "  0.07899834 0.03841383 0.01509912 0.0054491 ]\n",
      " [0.01595366 0.6808214  0.00127334 0.00286356 0.00012529 0.00015067\n",
      "  0.00120897 0.00011863 0.04481243 0.25267196]\n",
      " [0.54783195 0.00393997 0.1321253  0.06310163 0.05375739 0.05277842\n",
      "  0.0035583  0.0164361  0.11952608 0.00694491]\n",
      " [0.00207586 0.00094598 0.05873674 0.18535234 0.25839394 0.34513825\n",
      "  0.1326786  0.01552288 0.00056251 0.00059293]\n",
      " [0.35206985 0.10948277 0.00979332 0.00430925 0.00235107 0.00143358\n",
      "  0.00051765 0.00073671 0.471018   0.0482879 ]\n",
      " [0.03749484 0.674339   0.03255568 0.04193813 0.02193633 0.05185265\n",
      "  0.01705176 0.0427059  0.01570714 0.06441858]\n",
      " [0.01447477 0.00737574 0.14587353 0.16584848 0.13661486 0.17124406\n",
      "  0.33596838 0.0175298  0.00254677 0.00252365]\n",
      " [0.00308383 0.00722715 0.07412422 0.39008203 0.13062435 0.10654535\n",
      "  0.2178851  0.06694913 0.00185028 0.00162854]\n",
      " [0.20560926 0.02542971 0.09814624 0.03676801 0.08622707 0.03038028\n",
      "  0.02353477 0.33914113 0.03142915 0.12333439]\n",
      " [0.05031966 0.02874015 0.13424033 0.13516387 0.19510691 0.06678648\n",
      "  0.2372397  0.11660274 0.017544   0.01825613]\n",
      " [0.00158828 0.00044507 0.02954908 0.2978117  0.01344811 0.57398504\n",
      "  0.06892844 0.01358642 0.00047104 0.00018682]\n",
      " [0.04269477 0.01179787 0.2161988  0.16016938 0.2976481  0.10660582\n",
      "  0.09111374 0.04024937 0.02563074 0.00789152]\n",
      " [0.05027936 0.01589116 0.20023328 0.10101306 0.17899056 0.14074261\n",
      "  0.28102964 0.01073779 0.01884231 0.00224024]\n",
      " [0.01058848 0.00532796 0.08122878 0.29314503 0.19874252 0.25570047\n",
      "  0.11554576 0.03321026 0.00381302 0.00269765]\n",
      " [0.04836458 0.6979168  0.00672819 0.00706828 0.00304941 0.00521337\n",
      "  0.00320219 0.00817086 0.07372535 0.146561  ]\n",
      " [0.3280139  0.0542208  0.11330331 0.0579549  0.0937099  0.05461434\n",
      "  0.0191468  0.03890846 0.18506092 0.05506668]\n",
      " [0.02174926 0.7165419  0.00367467 0.00308618 0.00055863 0.00240167\n",
      "  0.00343828 0.00021376 0.16187817 0.08645754]\n",
      " [0.04173581 0.00945251 0.11945793 0.09495748 0.3821317  0.09171324\n",
      "  0.1367737  0.1062834  0.00838674 0.00910746]\n",
      " [0.06094322 0.27755505 0.05991639 0.09255071 0.02494781 0.05372919\n",
      "  0.04058128 0.00987328 0.24214585 0.1377572 ]\n",
      " [0.01541268 0.00617861 0.10434815 0.1798362  0.16107182 0.3863673\n",
      "  0.11649007 0.02703193 0.0021742  0.00108897]\n",
      " [0.03358886 0.00352399 0.2620886  0.20007089 0.19848624 0.19915238\n",
      "  0.03490419 0.05045328 0.01113944 0.00659208]\n",
      " [0.20583919 0.07325543 0.21671104 0.08158115 0.06440789 0.0968727\n",
      "  0.04019013 0.0276548  0.13469009 0.05879761]\n",
      " [0.21092756 0.07771957 0.00430545 0.00387726 0.00123632 0.00014661\n",
      "  0.00008975 0.00024241 0.65898854 0.04246646]\n",
      " [0.11781361 0.3465063  0.00472431 0.00560199 0.00392589 0.00097999\n",
      "  0.00221175 0.00091878 0.3729851  0.14433232]\n",
      " [0.00218442 0.87379783 0.00024629 0.00125134 0.00010996 0.00015421\n",
      "  0.00039879 0.00009258 0.01150282 0.11026184]\n",
      " [0.51862866 0.00998198 0.04730047 0.02481485 0.03467509 0.01185132\n",
      "  0.00378473 0.01025013 0.31500667 0.02370619]\n",
      " [0.1628243  0.5048641  0.02630385 0.0311294  0.01112057 0.02379387\n",
      "  0.03257222 0.03474011 0.04763684 0.12501468]\n",
      " [0.02107388 0.02386432 0.07874711 0.2228612  0.21347316 0.11292985\n",
      "  0.21403141 0.09888701 0.00364718 0.010485  ]\n",
      " [0.15536046 0.04815008 0.12925065 0.1319323  0.04154322 0.09739614\n",
      "  0.03424405 0.05279845 0.15343179 0.15589279]\n",
      " [0.39303482 0.00150056 0.00889936 0.00496172 0.00181352 0.00096722\n",
      "  0.00020398 0.00008648 0.58126664 0.00726571]\n",
      " [0.0257713  0.04037398 0.20182936 0.11824151 0.09977899 0.13289015\n",
      "  0.32583106 0.03015453 0.01392877 0.01120032]\n",
      " [0.02396655 0.0176832  0.1378756  0.1493497  0.24693005 0.18554527\n",
      "  0.14311486 0.08238713 0.00571518 0.00743241]\n",
      " [0.03470015 0.00250498 0.18115996 0.04761777 0.50623685 0.06637777\n",
      "  0.05827746 0.09330923 0.00593854 0.00387733]\n",
      " [0.05992415 0.00510815 0.13692798 0.07024127 0.44350603 0.08465841\n",
      "  0.09627175 0.0887152  0.01049777 0.00414926]\n",
      " [0.04281905 0.00055565 0.11473668 0.05975011 0.10194906 0.03266747\n",
      "  0.00562474 0.64076567 0.00012428 0.00100731]\n",
      " [0.09748453 0.00109018 0.25521863 0.08618686 0.4053494  0.07693253\n",
      "  0.0446309  0.02780458 0.00454517 0.00075711]\n",
      " [0.03872977 0.01544876 0.11633549 0.16105802 0.15542258 0.11126959\n",
      "  0.31920427 0.05076641 0.01602063 0.01574448]\n",
      " [0.15247326 0.00200596 0.40552747 0.15507689 0.10361305 0.05309295\n",
      "  0.0093654  0.10298891 0.00938329 0.00647275]\n",
      " [0.0050102  0.00055891 0.16605611 0.06694012 0.60504496 0.0556479\n",
      "  0.03516093 0.06450509 0.0008093  0.00026651]\n",
      " [0.22962046 0.02212552 0.06224008 0.05323567 0.03746341 0.01839968\n",
      "  0.01629707 0.0071708  0.51925284 0.03419447]\n",
      " [0.04093907 0.01295384 0.23007122 0.1405452  0.19995627 0.18440369\n",
      "  0.08627163 0.08170912 0.01083884 0.01231117]\n",
      " [0.09177529 0.01255667 0.26978692 0.19481146 0.19767442 0.09686768\n",
      "  0.04103244 0.05210578 0.02749706 0.01589233]\n",
      " [0.04430646 0.01180938 0.09374034 0.18509535 0.11128931 0.16979724\n",
      "  0.14528394 0.20950615 0.01014058 0.01903136]\n",
      " [0.0182074  0.01040178 0.16337806 0.08500718 0.21062753 0.07803556\n",
      "  0.25707304 0.16393201 0.00518497 0.00815247]\n",
      " [0.4982364  0.02725082 0.15181616 0.04898968 0.06049649 0.01708024\n",
      "  0.0143635  0.0310554  0.11502673 0.0356846 ]\n",
      " [0.20563889 0.01035284 0.2182917  0.15188216 0.0891685  0.12401024\n",
      "  0.02644659 0.04155482 0.08853169 0.04412258]\n",
      " [0.03430291 0.00605774 0.0720092  0.2473794  0.0652074  0.13184518\n",
      "  0.03875684 0.3910779  0.00397568 0.00938779]\n",
      " [0.02798267 0.00624725 0.09910028 0.15496571 0.29114303 0.22882852\n",
      "  0.10875394 0.06923032 0.00781242 0.00593587]\n",
      " [0.06745461 0.11525618 0.11790994 0.08547501 0.09440097 0.10309962\n",
      "  0.12497681 0.20641823 0.02847714 0.05653148]\n",
      " [0.02517187 0.00229034 0.12242685 0.35830233 0.12572831 0.22249547\n",
      "  0.05104639 0.08484506 0.00521652 0.00247681]\n",
      " [0.72704804 0.00787313 0.01232526 0.00102668 0.00352147 0.00085078\n",
      "  0.00020127 0.00101491 0.23485473 0.01128373]\n",
      " [0.00450009 0.007351   0.01866437 0.25609058 0.04956367 0.23174053\n",
      "  0.339835   0.08624075 0.00133779 0.00467613]\n",
      " [0.00176602 0.8656672  0.00091589 0.00237593 0.00009266 0.000231\n",
      "  0.00360799 0.00075553 0.00365471 0.12093315]\n",
      " [0.00843927 0.00133698 0.17596886 0.06449265 0.26492536 0.20655853\n",
      "  0.17103104 0.10463113 0.00104892 0.00156726]\n",
      " [0.16651008 0.00553272 0.22253366 0.10876295 0.24655463 0.10636841\n",
      "  0.04507724 0.05587709 0.03330909 0.00947411]\n",
      " [0.00410665 0.00039872 0.16989858 0.04317282 0.37892902 0.02891456\n",
      "  0.36181572 0.01219014 0.00034083 0.00023291]\n",
      " [0.9585601  0.00028714 0.00954878 0.00217584 0.00768786 0.00340519\n",
      "  0.00004269 0.00104088 0.01655826 0.00069318]\n",
      " [0.06933939 0.37334314 0.01183134 0.01764961 0.00927225 0.01323025\n",
      "  0.01673651 0.07359423 0.02698034 0.38802293]\n",
      " [0.10925569 0.00749845 0.16282307 0.10464114 0.1507879  0.01751729\n",
      "  0.05011978 0.28202084 0.02129121 0.09404455]\n",
      " [0.05066257 0.03549222 0.16277088 0.15284984 0.11705044 0.08352291\n",
      "  0.26709348 0.07832653 0.02060222 0.03162897]\n",
      " [0.11731263 0.00445965 0.28574032 0.27131388 0.09052579 0.15178484\n",
      "  0.02276175 0.01555507 0.03317262 0.00737355]\n",
      " [0.02709169 0.00605971 0.16551605 0.15366116 0.08902556 0.48654595\n",
      "  0.02190346 0.04128288 0.00654479 0.00236866]\n",
      " [0.13575956 0.24973224 0.01323029 0.02925786 0.00820834 0.00545846\n",
      "  0.00621408 0.01529333 0.23645526 0.3003905 ]\n",
      " [0.23670757 0.00528425 0.00933475 0.00254679 0.0053967  0.00041868\n",
      "  0.00024695 0.00031575 0.73328656 0.00646209]\n",
      " [0.12033201 0.00825749 0.02215984 0.03009628 0.01376456 0.00541093\n",
      "  0.0097491  0.45673734 0.01196407 0.3215283 ]\n",
      " [0.01575351 0.19034511 0.02250597 0.09123768 0.01914716 0.03017938\n",
      "  0.0114394  0.5138255  0.00475693 0.10080942]\n",
      " [0.04550977 0.1218605  0.05040713 0.1157257  0.05880418 0.06660872\n",
      "  0.284919   0.02605349 0.15886186 0.07124963]\n",
      " [0.01081761 0.00112644 0.21946308 0.21865618 0.24378665 0.23813939\n",
      "  0.05498483 0.01096922 0.00172932 0.00032722]\n",
      " [0.12409522 0.22738574 0.01203466 0.02310386 0.00476835 0.00685006\n",
      "  0.00306154 0.03077622 0.02012061 0.54780376]\n",
      " [0.01631292 0.00281917 0.1209702  0.26793224 0.07074329 0.38829577\n",
      "  0.10410901 0.01484683 0.01302764 0.00094286]\n",
      " [0.5512562  0.00899755 0.0271532  0.00421059 0.00762297 0.00139904\n",
      "  0.00084083 0.00196312 0.3900282  0.0065283 ]\n",
      " [0.06308839 0.05055878 0.09323536 0.20588946 0.09508727 0.11144128\n",
      "  0.15698344 0.15527599 0.01492357 0.05351639]\n",
      " [0.12887008 0.00254513 0.10086582 0.01698666 0.08985806 0.07323527\n",
      "  0.00738903 0.5695111  0.00255589 0.00818294]\n",
      " [0.01250136 0.4957552  0.00090647 0.00292611 0.00059949 0.00111823\n",
      "  0.00229342 0.00248822 0.02132422 0.4600873 ]\n",
      " [0.03334197 0.4142332  0.00034356 0.00027467 0.0000277  0.00008912\n",
      "  0.00003941 0.00014737 0.08433706 0.46716598]\n",
      " [0.28297263 0.04399342 0.09570225 0.0805131  0.10217306 0.05132997\n",
      "  0.1502965  0.03687605 0.11521749 0.04092541]\n",
      " [0.03719566 0.01115971 0.15727262 0.2212593  0.10746671 0.26410118\n",
      "  0.06745453 0.10795046 0.0153552  0.01078461]\n",
      " [0.01630328 0.5788244  0.00846815 0.01779147 0.00996563 0.00734669\n",
      "  0.0217755  0.01118735 0.11189961 0.21643785]] (33.404 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.8025825, step = 101 (33.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96705\n",
      "INFO:tensorflow:probabilities = [[0.6232017  0.00283466 0.18188946 0.05604915 0.03623825 0.0626795\n",
      "  0.00224066 0.01406804 0.01479223 0.00600632]\n",
      " [0.02471839 0.02277649 0.03016636 0.0072662  0.02330721 0.01498212\n",
      "  0.02102048 0.6901216  0.00024889 0.16539234]\n",
      " [0.24934809 0.09408917 0.09348771 0.01538542 0.04188256 0.0152744\n",
      "  0.01063575 0.00882575 0.4247617  0.04630939]\n",
      " [0.00666633 0.09923291 0.00569863 0.01582403 0.00213834 0.00306586\n",
      "  0.01858668 0.00060651 0.02619393 0.82198673]\n",
      " [0.04700891 0.03320882 0.21775961 0.08864462 0.16663404 0.11991491\n",
      "  0.1821579  0.04991441 0.05512164 0.03963514]\n",
      " [0.0395961  0.02009777 0.1385262  0.2852514  0.06294202 0.1208389\n",
      "  0.20381998 0.018509   0.06465489 0.04576372]\n",
      " [0.00530745 0.0004264  0.05431103 0.04790601 0.03806955 0.66093177\n",
      "  0.00332129 0.1871811  0.00077134 0.00177406]\n",
      " [0.00287513 0.29864442 0.00038556 0.0024257  0.00026086 0.00039653\n",
      "  0.01390807 0.00096487 0.00504406 0.6750948 ]\n",
      " [0.00612085 0.00198555 0.01885451 0.00309636 0.01367462 0.01084554\n",
      "  0.00181671 0.9276153  0.00019492 0.01579561]\n",
      " [0.06711975 0.7225046  0.00432086 0.00146107 0.00162776 0.00291847\n",
      "  0.00453596 0.00269937 0.09854186 0.09427015]\n",
      " [0.17558733 0.09303547 0.01681786 0.00942454 0.00872748 0.01035696\n",
      "  0.00772411 0.01113266 0.17109908 0.49609458]\n",
      " [0.01210877 0.0160789  0.13897425 0.30074167 0.11571185 0.19439386\n",
      "  0.09528542 0.07744598 0.01563827 0.03362099]\n",
      " [0.02566635 0.04588274 0.06493772 0.04397333 0.10546972 0.05181617\n",
      "  0.18022846 0.35659766 0.00528768 0.12014015]\n",
      " [0.01807594 0.00547406 0.10693035 0.09780631 0.15102574 0.18989147\n",
      "  0.13531363 0.27752623 0.00182738 0.01612892]\n",
      " [0.0126414  0.00245283 0.1532797  0.01907795 0.33201006 0.01208545\n",
      "  0.4319457  0.03002013 0.00274708 0.00373962]\n",
      " [0.0297909  0.01500439 0.14527616 0.1004804  0.16052273 0.09537897\n",
      "  0.3862623  0.02236209 0.01995674 0.0249653 ]\n",
      " [0.03980409 0.223615   0.01363664 0.01119549 0.01085284 0.00724949\n",
      "  0.01459943 0.00778682 0.05604859 0.6152116 ]\n",
      " [0.04649696 0.03326783 0.13216372 0.1256956  0.14348377 0.11475545\n",
      "  0.26856992 0.04076821 0.05015985 0.04463881]\n",
      " [0.03702262 0.0058871  0.33600175 0.12937345 0.09003016 0.1210997\n",
      "  0.09792592 0.04681437 0.09079533 0.04504956]\n",
      " [0.07549877 0.0098289  0.20741045 0.12213115 0.13570838 0.31648263\n",
      "  0.00671194 0.08069212 0.03261382 0.01292189]\n",
      " [0.01979846 0.29110736 0.00223505 0.00237267 0.00076663 0.00149596\n",
      "  0.00136802 0.00108779 0.05461762 0.6251505 ]\n",
      " [0.13057563 0.05182339 0.09441786 0.01814114 0.14270186 0.01879384\n",
      "  0.04248269 0.01070342 0.39902937 0.09133074]\n",
      " [0.00055741 0.00009255 0.01980657 0.1582044  0.02186264 0.7737739\n",
      "  0.00454636 0.02073227 0.00030301 0.00012094]\n",
      " [0.02777243 0.00502007 0.27988368 0.07712191 0.27638417 0.08462274\n",
      "  0.07901827 0.14684647 0.01431184 0.0090184 ]\n",
      " [0.09997235 0.00190454 0.3523163  0.03837481 0.32470047 0.06695116\n",
      "  0.00691783 0.09707936 0.01037775 0.0014055 ]\n",
      " [0.00474384 0.00128793 0.07732841 0.31647918 0.06238583 0.37701285\n",
      "  0.13176702 0.02306652 0.00232319 0.00360514]\n",
      " [0.04523595 0.6073482  0.00626746 0.01272224 0.00562324 0.00459547\n",
      "  0.01617316 0.00637357 0.05474641 0.24091431]\n",
      " [0.07249656 0.0206255  0.10406248 0.03222814 0.2798421  0.02315296\n",
      "  0.14641047 0.22613938 0.01083021 0.08421221]\n",
      " [0.00223793 0.00073906 0.05137761 0.17166564 0.0228293  0.6645067\n",
      "  0.00396887 0.07851356 0.00052904 0.00363241]\n",
      " [0.04468312 0.03510387 0.07551133 0.14001153 0.06843054 0.18217485\n",
      "  0.13331468 0.1561919  0.0184807  0.14609747]\n",
      " [0.26321137 0.01221583 0.1838565  0.06151767 0.13136603 0.05871592\n",
      "  0.01768629 0.09504585 0.13456851 0.04181608]\n",
      " [0.06579576 0.0299134  0.12846804 0.01280718 0.11471722 0.00834689\n",
      "  0.5548979  0.00693537 0.05392191 0.02419634]\n",
      " [0.03275714 0.08234128 0.00986952 0.01539475 0.00343539 0.00874471\n",
      "  0.00729493 0.01101636 0.06526468 0.76388127]\n",
      " [0.01467825 0.00631585 0.11618394 0.10857585 0.06085494 0.0666739\n",
      "  0.59236217 0.02038273 0.00474903 0.00922339]\n",
      " [0.0166099  0.00397599 0.08416491 0.21940868 0.06849116 0.40162358\n",
      "  0.11419537 0.07492323 0.00753433 0.00907286]\n",
      " [0.05197124 0.00107891 0.00092439 0.00006048 0.00016955 0.00002835\n",
      "  0.00007372 0.00000717 0.94404125 0.00164501]\n",
      " [0.00746762 0.8307983  0.00038064 0.00127925 0.00021825 0.00033542\n",
      "  0.00057031 0.00010862 0.02415471 0.13468684]\n",
      " [0.06431227 0.01625966 0.00376812 0.00035757 0.00113832 0.00014149\n",
      "  0.0006433  0.00009497 0.85686386 0.05642044]\n",
      " [0.04473515 0.0461294  0.08696713 0.03877456 0.04852363 0.01861153\n",
      "  0.5132704  0.01574417 0.02523889 0.16200516]\n",
      " [0.28159612 0.07643984 0.12286648 0.02215178 0.05874039 0.01169019\n",
      "  0.04212252 0.01398573 0.27879378 0.09161326]\n",
      " [0.08183771 0.27808994 0.09171446 0.053933   0.06310531 0.091075\n",
      "  0.0152186  0.14834681 0.02990158 0.14677754]\n",
      " [0.12543263 0.00891744 0.11534914 0.09513483 0.05643509 0.10826275\n",
      "  0.01559374 0.02388476 0.43626866 0.01472087]\n",
      " [0.00935783 0.00135513 0.1127711  0.04574863 0.06965039 0.40688547\n",
      "  0.00610874 0.3439362  0.00132327 0.00286325]\n",
      " [0.5598042  0.14669167 0.01193206 0.00027358 0.00066272 0.00017435\n",
      "  0.00014322 0.00022889 0.20875089 0.07133824]\n",
      " [0.00143717 0.0001297  0.4381891  0.0121461  0.4376733  0.01781518\n",
      "  0.05156353 0.03991449 0.00084212 0.00028926]\n",
      " [0.39767754 0.00048206 0.00742301 0.00022302 0.00218327 0.00003969\n",
      "  0.00008456 0.00002859 0.5913024  0.00055587]\n",
      " [0.01209516 0.0054177  0.18407783 0.08296075 0.15095505 0.13417597\n",
      "  0.32004508 0.08925688 0.00344273 0.01757287]\n",
      " [0.13851357 0.00038082 0.00417016 0.00039516 0.00308265 0.00013861\n",
      "  0.00017976 0.0000962  0.8516878  0.00135521]\n",
      " [0.00789377 0.00092307 0.02949753 0.02531827 0.04813815 0.04666071\n",
      "  0.00384955 0.80840653 0.00026271 0.02904973]\n",
      " [0.11395735 0.12411778 0.10534906 0.04214273 0.06377844 0.02909977\n",
      "  0.15833308 0.01475908 0.2048632  0.14359951]\n",
      " [0.02260564 0.00845495 0.12042326 0.10530462 0.09969133 0.49677086\n",
      "  0.01046128 0.11695481 0.00990467 0.00942851]\n",
      " [0.00761564 0.00368738 0.10188182 0.2558905  0.06545952 0.41987497\n",
      "  0.09057246 0.04083887 0.00431015 0.00986862]\n",
      " [0.23993412 0.00150856 0.122601   0.04531481 0.06419504 0.02256539\n",
      "  0.01658087 0.00371112 0.48057655 0.00301244]\n",
      " [0.07130302 0.37361875 0.00343694 0.00075079 0.00037716 0.00097913\n",
      "  0.00111551 0.00220948 0.05306462 0.49314457]\n",
      " [0.01170491 0.00445823 0.2997476  0.14938797 0.07283514 0.1375261\n",
      "  0.27538332 0.02257141 0.0153402  0.01104513]\n",
      " [0.00743219 0.00106663 0.13085471 0.20136912 0.04477185 0.40863895\n",
      "  0.03763035 0.158948   0.00077134 0.00851688]\n",
      " [0.00420551 0.00108765 0.0844646  0.18537243 0.03397932 0.5622353\n",
      "  0.01627399 0.10787906 0.00190422 0.00259788]\n",
      " [0.00244537 0.00141525 0.02366954 0.02989727 0.02601324 0.02894565\n",
      "  0.01732947 0.86267847 0.00007406 0.00753161]\n",
      " [0.06084297 0.06596643 0.11073441 0.05284243 0.18352573 0.05672001\n",
      "  0.18553288 0.18790497 0.00806282 0.08786716]\n",
      " [0.00002822 0.00000835 0.05570471 0.24164304 0.00513178 0.69142884\n",
      "  0.00483443 0.00111397 0.00009409 0.0000125 ]\n",
      " [0.03770914 0.04952522 0.03313046 0.08729093 0.0197516  0.18710269\n",
      "  0.027541   0.3083715  0.00212991 0.2474476 ]\n",
      " [0.02073187 0.01168492 0.08370937 0.2514275  0.04355056 0.29440925\n",
      "  0.07741097 0.10563689 0.07366042 0.03777826]\n",
      " [0.00018352 0.00007702 0.02347687 0.18475455 0.01171617 0.738149\n",
      "  0.00532687 0.03591883 0.00009859 0.00029856]\n",
      " [0.04730801 0.75117874 0.01126002 0.01915779 0.00392198 0.00880591\n",
      "  0.00337829 0.00395836 0.04791319 0.10311765]\n",
      " [0.01019631 0.00558454 0.13012582 0.32462236 0.03807556 0.11245432\n",
      "  0.33775702 0.01438821 0.00893655 0.01785937]\n",
      " [0.04308793 0.02128828 0.16439903 0.0744303  0.27342764 0.19173172\n",
      "  0.03874867 0.1669082  0.01819475 0.00778346]\n",
      " [0.6429408  0.0062472  0.06210899 0.00182656 0.04342726 0.00402595\n",
      "  0.00150621 0.00716105 0.21300286 0.0177531 ]\n",
      " [0.03338475 0.01107892 0.08807423 0.01667939 0.01787992 0.20408583\n",
      "  0.00107417 0.6009212  0.00104736 0.02577424]\n",
      " [0.01276632 0.00219746 0.07198188 0.12341476 0.08082008 0.5895513\n",
      "  0.00339695 0.10900592 0.00335734 0.00350805]\n",
      " [0.00328783 0.00018486 0.20484738 0.34771082 0.10064235 0.27246514\n",
      "  0.04155306 0.02196143 0.00635312 0.0009941 ]\n",
      " [0.02645935 0.00366625 0.1762609  0.193355   0.04513843 0.36959684\n",
      "  0.0045681  0.16156234 0.01083066 0.00856213]\n",
      " [0.30639797 0.09256044 0.0350213  0.00360699 0.00434952 0.00421238\n",
      "  0.00277905 0.00150807 0.5183223  0.03124191]\n",
      " [0.00959592 0.70744485 0.00051633 0.00034836 0.00017437 0.00033387\n",
      "  0.00032911 0.00091491 0.00921789 0.2711244 ]\n",
      " [0.00604024 0.00095076 0.01199517 0.00630487 0.05737129 0.01218253\n",
      "  0.00335277 0.8880341  0.00047085 0.0132974 ]\n",
      " [0.01520639 0.43164834 0.00526346 0.00622952 0.0014918  0.00548505\n",
      "  0.00941618 0.00393436 0.01346791 0.50785697]\n",
      " [0.09022651 0.02332818 0.36175877 0.10315859 0.15529293 0.15166473\n",
      "  0.02410186 0.04264907 0.02174684 0.02607256]\n",
      " [0.11602112 0.01231108 0.27647227 0.13959427 0.1036879  0.07962403\n",
      "  0.09498525 0.03305228 0.10148288 0.04276894]\n",
      " [0.0038994  0.00016409 0.5452126  0.03143298 0.24825099 0.02992427\n",
      "  0.12339574 0.0162444  0.00087653 0.00059897]\n",
      " [0.01246665 0.00326168 0.33970448 0.01803092 0.2970807  0.03125901\n",
      "  0.24985637 0.04232794 0.00187333 0.00413888]\n",
      " [0.00420773 0.00155742 0.05465038 0.28904825 0.0237213  0.42399958\n",
      "  0.03734322 0.15603104 0.00241942 0.0070217 ]\n",
      " [0.22819139 0.01175361 0.0343122  0.02284971 0.01497835 0.01236138\n",
      "  0.08580969 0.00323387 0.5585356  0.02797414]\n",
      " [0.01154936 0.00246617 0.27714512 0.0312561  0.3728996  0.02637705\n",
      "  0.23587437 0.03117026 0.00680184 0.00446019]\n",
      " [0.04395625 0.02223761 0.00460073 0.00044334 0.00057503 0.00035254\n",
      "  0.00029544 0.00014264 0.8871247  0.04027171]\n",
      " [0.003211   0.00017817 0.23375429 0.02133637 0.57297516 0.03884812\n",
      "  0.06888434 0.06013485 0.00037272 0.00030497]\n",
      " [0.0448101  0.10111353 0.05381295 0.0661658  0.03364569 0.07712084\n",
      "  0.02807245 0.13837688 0.02378327 0.43309852]\n",
      " [0.03756825 0.00606581 0.27233678 0.01807092 0.22143994 0.02779959\n",
      "  0.37728298 0.01240321 0.00658556 0.02044689]\n",
      " [0.01531236 0.01248924 0.00146594 0.00043282 0.00075034 0.00017514\n",
      "  0.00013526 0.00020646 0.94622743 0.02280503]\n",
      " [0.0021587  0.00113963 0.05547638 0.13110533 0.01062762 0.76955616\n",
      "  0.00451332 0.01395665 0.00551877 0.00594726]\n",
      " [0.10012756 0.07035472 0.13875799 0.03833573 0.1533426  0.02981697\n",
      "  0.34319234 0.05729469 0.02444434 0.04433298]\n",
      " [0.02786154 0.00227813 0.26121786 0.0298733  0.38857108 0.05806812\n",
      "  0.04996646 0.17164603 0.00363093 0.0068865 ]\n",
      " [0.07341778 0.24195464 0.02771673 0.0558351  0.0159939  0.01298683\n",
      "  0.06149344 0.00713239 0.19191603 0.31155312]\n",
      " [0.20112868 0.32422    0.0201331  0.0026135  0.00700546 0.00816431\n",
      "  0.00072346 0.00320682 0.2804324  0.15237217]\n",
      " [0.02072133 0.01396161 0.12189208 0.17011504 0.10813044 0.20918405\n",
      "  0.02891755 0.28147238 0.0069789  0.03862654]\n",
      " [0.15439846 0.10813713 0.06224263 0.04758655 0.03666867 0.04192837\n",
      "  0.15703097 0.05691187 0.07597356 0.25912178]\n",
      " [0.11741512 0.01428647 0.19495456 0.04716551 0.3249178  0.03890459\n",
      "  0.1671418  0.03413559 0.04576268 0.01531587]\n",
      " [0.00569254 0.00265094 0.09540333 0.04791379 0.07366488 0.04270972\n",
      "  0.71190834 0.01139572 0.00288605 0.00577468]\n",
      " [0.09631255 0.10882305 0.02408314 0.01763389 0.01268721 0.01610784\n",
      "  0.03627645 0.0116229  0.33812183 0.33833113]\n",
      " [0.00391028 0.00124959 0.10399824 0.02299342 0.61810523 0.03318777\n",
      "  0.08907627 0.12529033 0.00077505 0.0014138 ]\n",
      " [0.05901871 0.0367708  0.05730591 0.04648573 0.08822083 0.0551157\n",
      "  0.13436358 0.42524323 0.01189019 0.08558529]\n",
      " [0.13923888 0.2184254  0.02048258 0.01308804 0.00405235 0.007428\n",
      "  0.00923339 0.00476304 0.25560442 0.32768384]] (33.702 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.3719695, step = 201 (33.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95722\n",
      "INFO:tensorflow:probabilities = [[0.21751027 0.01519134 0.08211792 0.01558491 0.24340641 0.01180811\n",
      "  0.0049099  0.37422636 0.01214083 0.02310386]\n",
      " [0.09263454 0.03521423 0.11139542 0.09935266 0.14096308 0.06947144\n",
      "  0.28974885 0.08090463 0.0580316  0.02228361]\n",
      " [0.00070504 0.0004314  0.03173288 0.5097067  0.02728754 0.26763877\n",
      "  0.14567065 0.01406777 0.00060888 0.00215037]\n",
      " [0.00761732 0.0020699  0.29691523 0.18234484 0.1576421  0.15808558\n",
      "  0.02980223 0.158598   0.0039009  0.00302385]\n",
      " [0.3905378  0.00734631 0.0587751  0.01690208 0.02160673 0.00626615\n",
      "  0.01724848 0.00202989 0.45672312 0.02256426]\n",
      " [0.00246961 0.00455544 0.05559535 0.1162445  0.03940745 0.04230581\n",
      "  0.7281747  0.00552451 0.00138293 0.00433977]\n",
      " [0.00272949 0.00069034 0.09428578 0.20217519 0.04163748 0.1441067\n",
      "  0.508855   0.0040957  0.00063526 0.00078905]\n",
      " [0.3124542  0.00937186 0.13827772 0.14443696 0.15882793 0.0654961\n",
      "  0.01188872 0.12626787 0.01735216 0.01562639]\n",
      " [0.02605649 0.02199239 0.00273767 0.00358782 0.0028877  0.0008758\n",
      "  0.00124825 0.00224134 0.30313024 0.63524234]\n",
      " [0.23779365 0.5698144  0.02001206 0.00695477 0.0255277  0.00660836\n",
      "  0.00556    0.01216736 0.06955918 0.04600243]\n",
      " [0.0233554  0.27534774 0.00541267 0.00889532 0.00729552 0.00736883\n",
      "  0.00217196 0.04384236 0.00803309 0.6182772 ]\n",
      " [0.04251594 0.00318635 0.20618267 0.17298035 0.2250546  0.16956533\n",
      "  0.10208777 0.06699039 0.00983546 0.00160109]\n",
      " [0.00075098 0.46774477 0.000115   0.00006689 0.00004217 0.00014642\n",
      "  0.00011743 0.00055072 0.00037344 0.53009224]\n",
      " [0.02951072 0.00381712 0.07309331 0.10739132 0.25371262 0.03376305\n",
      "  0.296794   0.18066259 0.00912141 0.01213385]\n",
      " [0.47702405 0.0177981  0.03703243 0.0098559  0.03507838 0.00708457\n",
      "  0.00217695 0.01000254 0.33445308 0.06949395]\n",
      " [0.08352118 0.00011729 0.07722888 0.00267191 0.4894046  0.00111798\n",
      "  0.00020119 0.345012   0.00011538 0.00060958]\n",
      " [0.00670715 0.00880699 0.03292625 0.38725847 0.02347114 0.21063602\n",
      "  0.24233654 0.03137613 0.01664979 0.03983151]\n",
      " [0.00433549 0.00369502 0.02462395 0.02225458 0.03803669 0.01274125\n",
      "  0.87598306 0.00633516 0.0026274  0.00936733]\n",
      " [0.00659803 0.00023491 0.17346111 0.4574659  0.10632649 0.16356643\n",
      "  0.00932319 0.08077559 0.00053845 0.00170985]\n",
      " [0.03029153 0.01811545 0.25546375 0.17387258 0.14419474 0.08139516\n",
      "  0.2523874  0.02973071 0.00423921 0.01030945]\n",
      " [0.00078987 0.00024731 0.0499554  0.43596128 0.03815462 0.33598998\n",
      "  0.02165197 0.114181   0.00107821 0.00199032]\n",
      " [0.16823494 0.00047264 0.00790812 0.00023006 0.0353666  0.00048011\n",
      "  0.0000345  0.78010726 0.00067905 0.00648673]\n",
      " [0.01089532 0.00262936 0.09526899 0.11178243 0.09956074 0.18107776\n",
      "  0.00536313 0.4879993  0.00234502 0.00307794]\n",
      " [0.01603671 0.17969666 0.00240238 0.00117511 0.00163099 0.00177367\n",
      "  0.00030342 0.00198221 0.00488749 0.7901113 ]\n",
      " [0.38174868 0.00927375 0.22095066 0.02715096 0.09664308 0.02067622\n",
      "  0.01866698 0.02088891 0.17034012 0.03366061]\n",
      " [0.00849467 0.0004932  0.16326652 0.18328005 0.03727505 0.48125586\n",
      "  0.0073501  0.11381916 0.00222425 0.00254116]\n",
      " [0.15889925 0.05541985 0.04315419 0.07262814 0.07043567 0.02668879\n",
      "  0.18210378 0.04839233 0.14816557 0.19411242]\n",
      " [0.01197841 0.00132547 0.48306364 0.15664305 0.09245771 0.17821735\n",
      "  0.03978537 0.02869848 0.00519053 0.00264001]\n",
      " [0.01371121 0.00462716 0.12339455 0.11169375 0.33966237 0.08099078\n",
      "  0.22384916 0.09053011 0.00551739 0.00602339]\n",
      " [0.00535203 0.00082677 0.19475585 0.2250111  0.20094219 0.12376492\n",
      "  0.17213315 0.07545705 0.00066453 0.00109235]\n",
      " [0.07509405 0.01330846 0.19753772 0.03153891 0.39731345 0.02989285\n",
      "  0.04181127 0.1916182  0.00720452 0.01468055]\n",
      " [0.08583119 0.03612578 0.06628475 0.0831369  0.08474161 0.08105353\n",
      "  0.08230619 0.17267443 0.05438111 0.2534645 ]\n",
      " [0.0008954  0.00097347 0.01538581 0.3276004  0.01698202 0.08775845\n",
      "  0.52467334 0.02075604 0.0013872  0.00358781]\n",
      " [0.06051114 0.00355633 0.20627593 0.09006444 0.38143378 0.0374198\n",
      "  0.08676651 0.12487702 0.00581677 0.00327827]\n",
      " [0.04875858 0.01132555 0.0474363  0.4233147  0.11612181 0.08421069\n",
      "  0.15406057 0.0895141  0.01467768 0.01058008]\n",
      " [0.1744034  0.00276212 0.24349344 0.17631827 0.1129686  0.1607318\n",
      "  0.02026778 0.00778808 0.09897275 0.0022938 ]\n",
      " [0.06076578 0.06832425 0.10931447 0.20021391 0.1227404  0.10222727\n",
      "  0.09602049 0.16182    0.02234433 0.05622915]\n",
      " [0.04036972 0.00186871 0.2829816  0.14531969 0.20376672 0.12719736\n",
      "  0.09502424 0.08648718 0.00843742 0.00854732]\n",
      " [0.0209415  0.00540156 0.03891978 0.02227682 0.07187748 0.09911322\n",
      "  0.00734421 0.71305233 0.00430757 0.01676545]\n",
      " [0.07200389 0.04347937 0.1085885  0.1625056  0.20009449 0.07943867\n",
      "  0.14762422 0.1128476  0.02417219 0.04924548]\n",
      " [0.0190908  0.00860139 0.09816814 0.07647333 0.27238473 0.04409873\n",
      "  0.16713655 0.3054747  0.00288189 0.00568967]\n",
      " [0.043492   0.13046741 0.01164521 0.00480714 0.00915057 0.00446818\n",
      "  0.0014144  0.01557213 0.01188091 0.76710206]\n",
      " [0.00707252 0.0177299  0.13439451 0.40094784 0.08061013 0.09892645\n",
      "  0.10903653 0.13227355 0.0032307  0.01577791]\n",
      " [0.27169192 0.02299694 0.17099607 0.05290604 0.10407456 0.04110339\n",
      "  0.00538735 0.01775343 0.30562434 0.0074659 ]\n",
      " [0.5441849  0.01183842 0.10726275 0.02045999 0.1703123  0.0124457\n",
      "  0.02076939 0.01088325 0.09650458 0.00533867]\n",
      " [0.00691966 0.00153798 0.09293295 0.03488274 0.20344327 0.02789664\n",
      "  0.6054574  0.02119538 0.00185694 0.00387699]\n",
      " [0.57475555 0.00648783 0.0220921  0.00356583 0.00427884 0.00032374\n",
      "  0.00180827 0.00126555 0.31221458 0.0732077 ]\n",
      " [0.00328785 0.0013698  0.11154058 0.3814144  0.06213398 0.23217006\n",
      "  0.17682746 0.02840194 0.00155823 0.00129583]\n",
      " [0.01855902 0.00209741 0.18449068 0.25675252 0.06584627 0.41617158\n",
      "  0.01587602 0.03246898 0.00505772 0.00267993]\n",
      " [0.02388613 0.01920883 0.03999679 0.09854914 0.02948078 0.06794949\n",
      "  0.06242497 0.34853792 0.01389858 0.29606727]\n",
      " [0.02299203 0.0228069  0.07142031 0.21052088 0.07106933 0.4155187\n",
      "  0.05533742 0.09179329 0.02198161 0.01655961]\n",
      " [0.10036428 0.08610806 0.01411962 0.05246753 0.01321037 0.01952575\n",
      "  0.2892532  0.0040415  0.2034133  0.21749641]\n",
      " [0.777911   0.00191123 0.10257941 0.0027813  0.08018222 0.00177885\n",
      "  0.0007156  0.00493395 0.02549303 0.00171336]\n",
      " [0.01241441 0.02048283 0.04006404 0.35763603 0.0266034  0.11984358\n",
      "  0.08976777 0.11232246 0.00996276 0.21090262]\n",
      " [0.01212005 0.00163759 0.2391815  0.18096471 0.23145793 0.12012033\n",
      "  0.11591915 0.08833515 0.00750757 0.00275597]\n",
      " [0.00091434 0.00165145 0.04136257 0.40009066 0.05841484 0.38772938\n",
      "  0.06495497 0.03792441 0.00375362 0.00320375]\n",
      " [0.22826353 0.01948296 0.07098465 0.0214545  0.08902993 0.01888889\n",
      "  0.03237296 0.32907888 0.05698118 0.13346237]\n",
      " [0.8060292  0.00324136 0.0451174  0.00056014 0.05652056 0.00138835\n",
      "  0.00088185 0.04254348 0.01578745 0.02793014]\n",
      " [0.0055039  0.00293284 0.05027563 0.35781145 0.0275872  0.19960043\n",
      "  0.16167928 0.07768071 0.00512567 0.11180285]\n",
      " [0.23684065 0.01329181 0.0343916  0.0241727  0.02281156 0.01144565\n",
      "  0.0092226  0.00891426 0.6081277  0.03078152]\n",
      " [0.03341565 0.02231396 0.12674804 0.20923701 0.06463902 0.24993844\n",
      "  0.02257973 0.08900592 0.13544561 0.04667658]\n",
      " [0.26926485 0.01574838 0.07437757 0.02212889 0.07592755 0.01155032\n",
      "  0.02342838 0.0109994  0.44736323 0.04921139]\n",
      " [0.41753793 0.00903332 0.05528663 0.01619995 0.02990117 0.00563437\n",
      "  0.00122573 0.00308529 0.46002862 0.00206693]\n",
      " [0.00229496 0.0396187  0.00040804 0.01048816 0.00054459 0.00235162\n",
      "  0.00196653 0.03211477 0.00075381 0.9094588 ]\n",
      " [0.00056018 0.00143981 0.00237524 0.01644935 0.0110853  0.00378023\n",
      "  0.9600498  0.00093672 0.000114   0.00320927]\n",
      " [0.00418219 0.00292418 0.10645134 0.2718628  0.08052795 0.19207503\n",
      "  0.30634105 0.02697722 0.00481653 0.00384161]\n",
      " [0.00165679 0.0154916  0.0087009  0.09464234 0.01022808 0.01326329\n",
      "  0.8400547  0.00387541 0.00075647 0.01133039]\n",
      " [0.06828258 0.01701251 0.10553412 0.08794332 0.07845566 0.21298538\n",
      "  0.05638568 0.22530115 0.05593896 0.09216063]\n",
      " [0.02013639 0.01013526 0.14184712 0.2118544  0.0960626  0.19791517\n",
      "  0.17927569 0.09170014 0.02227656 0.02879667]\n",
      " [0.02890948 0.0252781  0.07527848 0.38075358 0.03921092 0.08500133\n",
      "  0.14971767 0.07128613 0.01482378 0.12974048]\n",
      " [0.5509489  0.00322777 0.09754565 0.00688774 0.06906319 0.00196321\n",
      "  0.02267268 0.00360645 0.23735899 0.00672547]\n",
      " [0.01954829 0.135897   0.01142438 0.01376215 0.00616696 0.00611333\n",
      "  0.0025842  0.00729155 0.08364221 0.71356994]\n",
      " [0.05288704 0.03087144 0.01275565 0.0160131  0.01231979 0.01505927\n",
      "  0.00345191 0.00300941 0.83449364 0.01913878]\n",
      " [0.01123763 0.00331204 0.06730212 0.05774609 0.2701818  0.06090895\n",
      "  0.14390884 0.37686032 0.00249053 0.00605166]\n",
      " [0.04340795 0.71393055 0.00782609 0.00085452 0.00358044 0.00087161\n",
      "  0.00011863 0.00154431 0.03459274 0.1932732 ]\n",
      " [0.02197948 0.01328531 0.217552   0.15537179 0.28121886 0.08489142\n",
      "  0.121529   0.07600654 0.01728916 0.01087646]\n",
      " [0.3998552  0.2714593  0.00205607 0.00016216 0.00241762 0.0000842\n",
      "  0.00006737 0.00070771 0.18461123 0.13857913]\n",
      " [0.00678648 0.00778327 0.06108647 0.3685875  0.0237053  0.27651933\n",
      "  0.09642898 0.07293669 0.00200185 0.08416414]\n",
      " [0.07441755 0.00446804 0.18506308 0.124048   0.31076255 0.05546313\n",
      "  0.17291282 0.04403915 0.02556136 0.00326439]\n",
      " [0.05555454 0.12138475 0.00719823 0.01108321 0.00539576 0.00483861\n",
      "  0.00844869 0.00850083 0.04039948 0.7371959 ]\n",
      " [0.01288223 0.00326574 0.08311661 0.14605857 0.14641362 0.13608247\n",
      "  0.02195049 0.44407737 0.00228585 0.00386704]\n",
      " [0.05830064 0.02274458 0.20162648 0.14582434 0.12332653 0.10507089\n",
      "  0.04168351 0.23851001 0.01259223 0.05032079]\n",
      " [0.01066886 0.00159608 0.04732293 0.03882442 0.02311848 0.03892788\n",
      "  0.00130977 0.80387336 0.00172176 0.0326364 ]\n",
      " [0.00760986 0.00421635 0.05124002 0.04233398 0.12448509 0.07660709\n",
      "  0.6164639  0.07000885 0.0017185  0.00531636]\n",
      " [0.02377976 0.03515018 0.04346768 0.12365855 0.03969562 0.0938997\n",
      "  0.07596111 0.274887   0.0047972  0.28470325]\n",
      " [0.41562584 0.1010533  0.05052555 0.0183375  0.05915325 0.01354155\n",
      "  0.00120301 0.02068278 0.28268796 0.0371894 ]\n",
      " [0.00006283 0.00006837 0.00038682 0.000168   0.00279869 0.00099543\n",
      "  0.00010508 0.995252   0.00000176 0.00016096]\n",
      " [0.00962992 0.07496607 0.00111932 0.00134527 0.00082675 0.00142837\n",
      "  0.00095928 0.0066406  0.03705531 0.8660291 ]\n",
      " [0.00578491 0.00020356 0.07862864 0.00787622 0.37070495 0.00415983\n",
      "  0.50103134 0.03126753 0.00011209 0.00023089]\n",
      " [0.0077214  0.34544212 0.00688727 0.01251392 0.00282871 0.01490681\n",
      "  0.01692148 0.02934448 0.00957807 0.5538558 ]\n",
      " [0.00669649 0.00121726 0.05365562 0.02227137 0.32350206 0.04456142\n",
      "  0.06839872 0.4786572  0.00041133 0.00062857]\n",
      " [0.00134881 0.00118745 0.00467556 0.01964958 0.00853022 0.00459876\n",
      "  0.95447755 0.00404622 0.00015454 0.00133138]\n",
      " [0.06127609 0.5551234  0.04284466 0.02679844 0.0095345  0.02115647\n",
      "  0.00481424 0.02096005 0.01850141 0.23899086]\n",
      " [0.2624354  0.07447857 0.02317607 0.04090793 0.07619836 0.01119683\n",
      "  0.0885691  0.01067746 0.22407718 0.18828304]\n",
      " [0.31038538 0.01770852 0.11288928 0.02546943 0.14847566 0.0205881\n",
      "  0.01481308 0.24317649 0.01924309 0.08725095]\n",
      " [0.05614731 0.68746394 0.00687108 0.00972085 0.02415309 0.00610846\n",
      "  0.0017393  0.01335408 0.03784874 0.15659314]\n",
      " [0.03579124 0.0000798  0.11456468 0.00944512 0.43174666 0.01185295\n",
      "  0.00254797 0.3934692  0.00014247 0.00035985]\n",
      " [0.00048622 0.00007727 0.02516608 0.34359455 0.00772243 0.6000118\n",
      "  0.00309374 0.01943819 0.00033043 0.00007921]\n",
      " [0.03195169 0.05428734 0.11042562 0.18338266 0.09041405 0.14319651\n",
      "  0.15307406 0.03081333 0.10793148 0.09452325]\n",
      " [0.854259   0.00972947 0.00162921 0.00009716 0.00211125 0.00005134\n",
      "  0.0001068  0.00003646 0.129649   0.00233042]] (33.817 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.4246713, step = 301 (33.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.9553\n",
      "INFO:tensorflow:probabilities = [[0.00817342 0.00126529 0.16684878 0.11675697 0.4645081  0.10411653\n",
      "  0.11579512 0.01610912 0.0052339  0.0011928 ]\n",
      " [0.10759515 0.0971316  0.12076904 0.21417873 0.04183505 0.17209855\n",
      "  0.04976878 0.06451186 0.02342736 0.10868387]\n",
      " [0.02367801 0.00483758 0.1283986  0.1951317  0.1667362  0.24605343\n",
      "  0.16240253 0.0462321  0.01083698 0.01569273]\n",
      " [0.00269109 0.95847744 0.00053163 0.00331646 0.00043055 0.00047337\n",
      "  0.00041143 0.00037555 0.00341809 0.02987443]\n",
      " [0.05424179 0.0058932  0.00636509 0.0046935  0.00131345 0.0008568\n",
      "  0.00044303 0.00029223 0.91958296 0.00631788]\n",
      " [0.06991545 0.00150813 0.4100762  0.10084772 0.15357131 0.19337492\n",
      "  0.03564504 0.02884403 0.00239488 0.00382245]\n",
      " [0.03796306 0.00800064 0.13672787 0.20300163 0.1339906  0.28041357\n",
      "  0.03434528 0.078683   0.07452902 0.01234532]\n",
      " [0.15920289 0.0112973  0.07139979 0.04351757 0.01814487 0.0269823\n",
      "  0.00765027 0.03182265 0.5548107  0.07517164]\n",
      " [0.15452455 0.02771319 0.13784441 0.04870985 0.17763764 0.14055686\n",
      "  0.01762244 0.25226045 0.00881628 0.03431433]\n",
      " [0.08894645 0.03012139 0.04427169 0.08228011 0.03391782 0.11005038\n",
      "  0.02813343 0.36708033 0.01590946 0.19928889]\n",
      " [0.05451612 0.02381445 0.06874913 0.15944287 0.07292527 0.04732148\n",
      "  0.16034088 0.01412835 0.35923645 0.03952499]\n",
      " [0.00198556 0.00126083 0.03107288 0.6116551  0.02751063 0.26087666\n",
      "  0.05103606 0.01174476 0.00094367 0.00191385]\n",
      " [0.05708833 0.01580073 0.09174051 0.19061072 0.0437265  0.09342431\n",
      "  0.38097256 0.01549807 0.0810004  0.03013794]\n",
      " [0.01290822 0.00651142 0.12180553 0.32214987 0.09166635 0.22098167\n",
      "  0.15307948 0.04012886 0.01356133 0.01720724]\n",
      " [0.29889882 0.3433031  0.0978763  0.03964679 0.04045097 0.0279044\n",
      "  0.02264866 0.01235765 0.03604667 0.08086656]\n",
      " [0.02331201 0.02457156 0.13760197 0.07479164 0.02833066 0.36337554\n",
      "  0.00352299 0.3142631  0.00701631 0.02321418]\n",
      " [0.00592633 0.00021951 0.18910772 0.13919954 0.183245   0.40718034\n",
      "  0.05016061 0.02212647 0.00177379 0.00106066]\n",
      " [0.02905557 0.01068405 0.15767637 0.29313397 0.06779825 0.1275\n",
      "  0.23514412 0.01330533 0.02691225 0.03879004]\n",
      " [0.04340021 0.00346823 0.08987932 0.34615076 0.09741851 0.22210498\n",
      "  0.14490741 0.03733923 0.00666583 0.00866542]\n",
      " [0.01613927 0.739687   0.00121094 0.00410095 0.00075315 0.00061744\n",
      "  0.00257957 0.00038118 0.02735991 0.20717065]\n",
      " [0.00571029 0.00285654 0.09805884 0.27508986 0.07542854 0.41237304\n",
      "  0.03357461 0.08409887 0.00976507 0.00304438]\n",
      " [0.00757831 0.00581728 0.05901137 0.2129384  0.03927295 0.5286285\n",
      "  0.02603844 0.09618965 0.00440922 0.02011593]\n",
      " [0.04111662 0.01083931 0.15216547 0.16149749 0.2550711  0.15223077\n",
      "  0.15457444 0.05064235 0.01230387 0.00955854]\n",
      " [0.00864977 0.8707894  0.00085303 0.00270396 0.00009489 0.00034849\n",
      "  0.00015498 0.00008038 0.07940977 0.03691539]\n",
      " [0.02285088 0.00813215 0.05653484 0.34418193 0.03804906 0.19438255\n",
      "  0.20579343 0.06286164 0.02857647 0.03863701]\n",
      " [0.20670947 0.14134789 0.0441214  0.02279463 0.01788099 0.01023863\n",
      "  0.01116432 0.03799455 0.09809706 0.40965104]\n",
      " [0.03617021 0.43689838 0.00738281 0.0335617  0.00368159 0.00445854\n",
      "  0.00944524 0.00407693 0.16370244 0.30062225]\n",
      " [0.05629444 0.00685962 0.00253007 0.00335156 0.00052181 0.00016716\n",
      "  0.00064031 0.00006568 0.9222789  0.00729038]\n",
      " [0.00145123 0.8952402  0.00176166 0.03030735 0.00023302 0.00688014\n",
      "  0.00262049 0.00041195 0.00682805 0.05426604]\n",
      " [0.0446079  0.00741207 0.11732482 0.23571782 0.13510402 0.16485523\n",
      "  0.1236612  0.06955171 0.06562084 0.03614436]\n",
      " [0.01534554 0.01046643 0.07293588 0.21577209 0.05112157 0.3462773\n",
      "  0.04732128 0.16275498 0.01668433 0.0613206 ]\n",
      " [0.09694055 0.00578772 0.33647543 0.15967473 0.08352654 0.12351339\n",
      "  0.11579261 0.0260177  0.03867027 0.01360102]\n",
      " [0.02707556 0.01498478 0.12369658 0.06041498 0.4460897  0.10091948\n",
      "  0.14895253 0.06267969 0.0078108  0.0073759 ]\n",
      " [0.21602911 0.02855278 0.00130443 0.00071032 0.00152045 0.00019951\n",
      "  0.00018384 0.00026445 0.72482365 0.02641156]\n",
      " [0.01203717 0.00504083 0.02537067 0.31453392 0.03832965 0.21650818\n",
      "  0.25309741 0.06573728 0.01118318 0.05816171]\n",
      " [0.03421267 0.12862864 0.04642775 0.16669618 0.03230518 0.14638215\n",
      "  0.18236107 0.06594078 0.03990081 0.1571448 ]\n",
      " [0.02651796 0.00163489 0.04000726 0.03008738 0.02908803 0.1275543\n",
      "  0.00364037 0.7245691  0.0005587  0.01634201]\n",
      " [0.11535621 0.19572066 0.02113952 0.0620749  0.00866794 0.01221562\n",
      "  0.01561022 0.00585559 0.23434606 0.32901323]\n",
      " [0.00633327 0.00184882 0.05692497 0.318199   0.04002476 0.5385946\n",
      "  0.01517926 0.01503047 0.00586483 0.00199997]\n",
      " [0.48152447 0.01465118 0.2623988  0.0503964  0.05909539 0.02071657\n",
      "  0.03740993 0.00703253 0.0599406  0.0068342 ]\n",
      " [0.1159177  0.03377174 0.08324876 0.08703129 0.02755193 0.0285097\n",
      "  0.12070301 0.00731953 0.39994678 0.09599958]\n",
      " [0.03742803 0.00760633 0.19516328 0.22494455 0.13891856 0.1655719\n",
      "  0.18735133 0.01721942 0.01299093 0.01280563]\n",
      " [0.00588344 0.01149755 0.06951549 0.26382956 0.07054257 0.23842064\n",
      "  0.30377275 0.0229821  0.00623068 0.00732524]\n",
      " [0.04767694 0.00764543 0.00522889 0.00133496 0.0009896  0.00023147\n",
      "  0.00051449 0.00017889 0.9212212  0.01497804]\n",
      " [0.00460467 0.00600071 0.05557493 0.22731777 0.06629168 0.29826555\n",
      "  0.28410095 0.04367502 0.00352467 0.01064402]\n",
      " [0.03109444 0.00345768 0.2566536  0.18889529 0.23152862 0.13372372\n",
      "  0.10604692 0.02141722 0.02071014 0.00647232]\n",
      " [0.02233168 0.47282895 0.01342106 0.02045292 0.00647103 0.00787299\n",
      "  0.01107698 0.00567103 0.1552276  0.28464574]\n",
      " [0.00725142 0.00311094 0.01819518 0.02922926 0.11891061 0.08431032\n",
      "  0.00862194 0.7238728  0.00174557 0.00475198]\n",
      " [0.05958417 0.00908261 0.17570706 0.12744474 0.07918873 0.30475965\n",
      "  0.019203   0.14768648 0.04630268 0.03104096]\n",
      " [0.00539554 0.46178752 0.00132397 0.00638947 0.00060551 0.001579\n",
      "  0.00603916 0.00062118 0.00352627 0.51273245]\n",
      " [0.02216366 0.0831396  0.0604363  0.17123258 0.02923671 0.15624604\n",
      "  0.17060667 0.06827341 0.01307478 0.22559015]\n",
      " [0.02601798 0.02114186 0.18627141 0.21355791 0.13849068 0.16354597\n",
      "  0.15901168 0.04105361 0.02405122 0.02685773]\n",
      " [0.1403951  0.00490244 0.31595236 0.11839451 0.19701211 0.12211139\n",
      "  0.04480138 0.03761058 0.00980585 0.00901427]\n",
      " [0.02374263 0.00585983 0.09410951 0.21571165 0.07710969 0.40541652\n",
      "  0.04533979 0.10784623 0.01057747 0.01428678]\n",
      " [0.01685959 0.0032498  0.06901358 0.31587005 0.0351478  0.4588182\n",
      "  0.02160696 0.06465768 0.00441404 0.01036222]\n",
      " [0.01537394 0.40186062 0.00224588 0.00842709 0.00076356 0.00102838\n",
      "  0.00163348 0.00163653 0.232874   0.33415648]\n",
      " [0.09416144 0.00137318 0.22890598 0.13516097 0.04040042 0.04876784\n",
      "  0.04332216 0.01260552 0.38564146 0.00966106]\n",
      " [0.7251439  0.00055369 0.21457997 0.00952286 0.01897339 0.00391147\n",
      "  0.00113177 0.00123631 0.02450612 0.00044057]\n",
      " [0.321453   0.02408871 0.09907333 0.03247898 0.05892763 0.0160154\n",
      "  0.00793578 0.01071026 0.4042027  0.02511417]\n",
      " [0.09640479 0.00080996 0.16040485 0.02401769 0.01057431 0.00442236\n",
      "  0.00738361 0.00033489 0.69367874 0.00196879]\n",
      " [0.15164393 0.03942436 0.09984823 0.14438754 0.16687931 0.10239199\n",
      "  0.11821655 0.05289748 0.06668664 0.05762394]\n",
      " [0.01070753 0.00734314 0.04913867 0.15992436 0.09653331 0.2386048\n",
      "  0.3374248  0.06698717 0.00871565 0.02462065]\n",
      " [0.22375424 0.05001485 0.0715739  0.04334688 0.04620502 0.07165077\n",
      "  0.00872563 0.20123634 0.01856266 0.2649297 ]\n",
      " [0.02366921 0.00356676 0.26395777 0.09751337 0.34732312 0.15590912\n",
      "  0.06059846 0.03677376 0.00817381 0.00251464]\n",
      " [0.02319628 0.07133324 0.01960083 0.0281823  0.00870922 0.01317561\n",
      "  0.00998059 0.03430434 0.02856518 0.7629524 ]\n",
      " [0.01207517 0.3155821  0.0005693  0.00223241 0.00028749 0.0007242\n",
      "  0.0008091  0.00037708 0.01235255 0.65499055]\n",
      " [0.00531984 0.00250074 0.03534839 0.07239392 0.0798467  0.19403414\n",
      "  0.0227685  0.581657   0.00062544 0.00550527]\n",
      " [0.03154084 0.14577645 0.03275614 0.14927314 0.04437876 0.10719224\n",
      "  0.15994722 0.04008339 0.09715641 0.19189541]\n",
      " [0.00536421 0.8402172  0.00133135 0.00233143 0.00043405 0.00056938\n",
      "  0.0002278  0.00044424 0.01338731 0.13569307]\n",
      " [0.01134589 0.00195576 0.31066966 0.10295071 0.27779856 0.18934107\n",
      "  0.04175406 0.05334895 0.00606574 0.0047696 ]\n",
      " [0.14310648 0.05923338 0.0902652  0.13105251 0.03354904 0.07081018\n",
      "  0.0165011  0.05070317 0.3195284  0.08525053]\n",
      " [0.00862091 0.00115324 0.00162095 0.00155106 0.00047141 0.00017323\n",
      "  0.00008767 0.00001665 0.98607004 0.00023487]\n",
      " [0.04661153 0.01885418 0.08391931 0.27420932 0.0935318  0.21220316\n",
      "  0.10099403 0.08185496 0.05154597 0.0362757 ]\n",
      " [0.29231152 0.00623173 0.30574858 0.16959403 0.05263847 0.08713084\n",
      "  0.04847397 0.00442704 0.02839854 0.00504528]\n",
      " [0.2342716  0.00513793 0.22856736 0.0228895  0.12659758 0.01754411\n",
      "  0.01963722 0.01619818 0.3172401  0.01191638]\n",
      " [0.00648678 0.00242814 0.3091091  0.11511453 0.3715907  0.10150892\n",
      "  0.0373604  0.05450579 0.00096749 0.00092817]\n",
      " [0.10344941 0.00183294 0.28605494 0.08909258 0.26109096 0.12130421\n",
      "  0.05964365 0.05152136 0.02235733 0.00365266]\n",
      " [0.14836518 0.01566267 0.10382903 0.07001659 0.05664816 0.05105405\n",
      "  0.02290708 0.01483342 0.5073287  0.00935518]\n",
      " [0.03005244 0.05558184 0.1684443  0.18567836 0.08494038 0.15598568\n",
      "  0.1649714  0.02854244 0.0629871  0.06281617]\n",
      " [0.01021331 0.00163983 0.0194667  0.02755558 0.03712349 0.06034052\n",
      "  0.00440707 0.8371711  0.00008863 0.00199379]\n",
      " [0.00099012 0.00039151 0.01740703 0.533029   0.03976599 0.25980082\n",
      "  0.14330235 0.00266034 0.00180402 0.00084876]\n",
      " [0.01559068 0.00278642 0.08385897 0.16873603 0.20266828 0.13880722\n",
      "  0.32512382 0.04463027 0.00948059 0.00831763]\n",
      " [0.03598321 0.01682903 0.09563593 0.2697295  0.03301262 0.3585448\n",
      "  0.03368663 0.10533348 0.02054716 0.03069765]\n",
      " [0.08681171 0.00202804 0.16456485 0.05091507 0.45445207 0.08221447\n",
      "  0.05477218 0.08876396 0.01097755 0.00450006]\n",
      " [0.06276513 0.22917026 0.07457656 0.14580499 0.04878322 0.07962155\n",
      "  0.03957791 0.06947918 0.10519786 0.14502332]\n",
      " [0.2044071  0.17343502 0.04900273 0.0497301  0.04381064 0.02723871\n",
      "  0.03113425 0.03285214 0.22218236 0.16620693]\n",
      " [0.07977    0.05516366 0.37932706 0.1523115  0.02330818 0.07670886\n",
      "  0.01562939 0.05793332 0.02264229 0.13720559]\n",
      " [0.01701074 0.00229929 0.18136504 0.3921426  0.0887071  0.16982497\n",
      "  0.08112337 0.00658179 0.05747195 0.0034731 ]\n",
      " [0.04949236 0.00340057 0.31637996 0.11157543 0.11582587 0.28743464\n",
      "  0.03171434 0.05832248 0.0226819  0.00317249]\n",
      " [0.00204514 0.86074173 0.00021371 0.00134503 0.00006108 0.00021135\n",
      "  0.00027267 0.00056338 0.00198433 0.1325617 ]\n",
      " [0.10833418 0.48830563 0.06217252 0.02526546 0.03117733 0.0302006\n",
      "  0.01671083 0.05034042 0.0335593  0.15393373]\n",
      " [0.00047957 0.9762056  0.00005526 0.00319026 0.00000941 0.0001413\n",
      "  0.00031812 0.00000946 0.00104812 0.0185429 ]\n",
      " [0.07761165 0.00045674 0.64373684 0.06732479 0.11577871 0.04778415\n",
      "  0.01272735 0.00452114 0.02875757 0.00130113]\n",
      " [0.57617694 0.00051322 0.2264517  0.00624528 0.0100301  0.00074356\n",
      "  0.00281872 0.00018535 0.17664948 0.00018563]\n",
      " [0.02473637 0.00177054 0.2878683  0.02882596 0.46375468 0.03279301\n",
      "  0.11197539 0.04137874 0.00386806 0.00302893]\n",
      " [0.00346113 0.00344101 0.01528242 0.4698566  0.01590944 0.2850958\n",
      "  0.1627136  0.02292766 0.00643885 0.01487361]\n",
      " [0.00425882 0.00003792 0.58076596 0.10736604 0.06668894 0.216903\n",
      "  0.00031355 0.0234533  0.0000885  0.00012401]\n",
      " [0.10151313 0.00713659 0.14256705 0.0041315  0.6972924  0.01456474\n",
      "  0.0086532  0.02217561 0.00152587 0.0004399 ]\n",
      " [0.1179933  0.0026745  0.21990119 0.06356549 0.20494103 0.22655234\n",
      "  0.01154291 0.1332985  0.01361385 0.00591681]\n",
      " [0.00579279 0.74542123 0.00072829 0.00109477 0.00006414 0.00054271\n",
      "  0.00060647 0.00016801 0.00011903 0.24546255]] (33.851 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.3699675, step = 401 (33.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.81545\n",
      "INFO:tensorflow:probabilities = [[0.385727   0.02214791 0.01327033 0.00290795 0.0052447  0.00018132\n",
      "  0.00067787 0.00030499 0.5611694  0.00836859]\n",
      " [0.00767386 0.01161329 0.02921221 0.1562321  0.06251903 0.20678332\n",
      "  0.130665   0.35162577 0.00400859 0.03966675]\n",
      " [0.147155   0.0979571  0.00451233 0.00394758 0.00097335 0.00089479\n",
      "  0.00195595 0.00038344 0.5520282  0.19019233]\n",
      " [0.06603402 0.22558692 0.26070982 0.07807992 0.02615059 0.11058855\n",
      "  0.01501966 0.08267741 0.00455263 0.13060048]\n",
      " [0.13575648 0.22092764 0.03283459 0.05646279 0.04270595 0.03730385\n",
      "  0.01387176 0.07872598 0.12766774 0.25374326]\n",
      " [0.00721157 0.6163399  0.00193286 0.00121454 0.00280943 0.00380208\n",
      "  0.01657264 0.00341881 0.00422019 0.34247795]\n",
      " [0.00052253 0.00020541 0.00700185 0.3856563  0.00751872 0.5670943\n",
      "  0.00770074 0.02239803 0.00089803 0.00100404]\n",
      " [0.15874404 0.00004954 0.6938507  0.04070891 0.05126586 0.02036222\n",
      "  0.00008995 0.02642363 0.00757032 0.00093465]\n",
      " [0.8830605  0.01151384 0.00771456 0.0005406  0.00528642 0.00030274\n",
      "  0.00024856 0.00089332 0.03661055 0.05382904]\n",
      " [0.03744953 0.19340254 0.06472597 0.08586553 0.05048016 0.05856245\n",
      "  0.22635928 0.03332649 0.18706223 0.06276582]\n",
      " [0.61430186 0.00291977 0.2569639  0.03184381 0.02906096 0.03579362\n",
      "  0.00047341 0.02281485 0.00484168 0.00098608]\n",
      " [0.05318857 0.01213716 0.15334359 0.23467958 0.11125594 0.27308553\n",
      "  0.04974328 0.0751806  0.02252567 0.01486011]\n",
      " [0.00608743 0.00751497 0.07625066 0.28961113 0.10421747 0.2889561\n",
      "  0.07263453 0.14694926 0.00255737 0.00522105]\n",
      " [0.46585488 0.07954325 0.00556577 0.00342265 0.00259228 0.00113482\n",
      "  0.00266973 0.0005721  0.27010798 0.16853645]\n",
      " [0.00247852 0.00163927 0.03363399 0.05020675 0.05687007 0.0547119\n",
      "  0.01981946 0.76805884 0.00032797 0.01225324]\n",
      " [0.02084317 0.00392273 0.09865288 0.16803998 0.32545742 0.16581543\n",
      "  0.01917209 0.19104782 0.00436578 0.00268264]\n",
      " [0.00110641 0.00114415 0.0568551  0.32783183 0.02698781 0.14759505\n",
      "  0.4125286  0.01884473 0.00153102 0.00557529]\n",
      " [0.40227044 0.10124692 0.04845566 0.02702066 0.03517914 0.00770733\n",
      "  0.01606697 0.01022946 0.2381025  0.11372095]\n",
      " [0.00262224 0.00193781 0.00541923 0.00457392 0.01587478 0.01797878\n",
      "  0.00057434 0.94817513 0.00028595 0.00255774]\n",
      " [0.7341651  0.00294629 0.14385627 0.01203447 0.02544557 0.00518334\n",
      "  0.00242188 0.00549033 0.06430676 0.0041502 ]\n",
      " [0.00250998 0.00288622 0.0051525  0.69632256 0.010223   0.11555703\n",
      "  0.09601845 0.03774169 0.00125362 0.03233497]\n",
      " [0.73302406 0.00003304 0.25094897 0.00583951 0.00340386 0.00632018\n",
      "  0.00004886 0.00019384 0.00012582 0.000062  ]\n",
      " [0.1722438  0.05443057 0.0091634  0.00327602 0.00527275 0.0010906\n",
      "  0.00126108 0.007802   0.02074179 0.7247179 ]\n",
      " [0.0498654  0.1598472  0.02444078 0.1210493  0.01000251 0.04023254\n",
      "  0.01101731 0.01792798 0.3428843  0.22273266]\n",
      " [0.03807541 0.47254023 0.00614873 0.00864062 0.00503923 0.00344768\n",
      "  0.00401269 0.00371056 0.04353893 0.41484585]\n",
      " [0.13941465 0.01409882 0.13112873 0.05758224 0.13748953 0.06691033\n",
      "  0.00414219 0.31805363 0.08716317 0.04401669]\n",
      " [0.00134034 0.0077572  0.05395292 0.30615595 0.01211642 0.44318834\n",
      "  0.03624947 0.12186793 0.00063799 0.01673347]\n",
      " [0.04985718 0.0039024  0.12244501 0.21800056 0.2385785  0.10435373\n",
      "  0.06965338 0.16773032 0.0123129  0.01316608]\n",
      " [0.00622523 0.00301519 0.12553611 0.1402629  0.17391422 0.26710957\n",
      "  0.04903416 0.22833304 0.00194966 0.00461989]\n",
      " [0.35249403 0.03550329 0.02976092 0.04884366 0.08103533 0.02708379\n",
      "  0.10105073 0.10642357 0.06494994 0.15285473]\n",
      " [0.00463707 0.00221177 0.04596574 0.5112308  0.03539231 0.34654593\n",
      "  0.01013221 0.04110514 0.00073804 0.00204097]\n",
      " [0.04583777 0.0744785  0.05082214 0.05045437 0.03770896 0.03295441\n",
      "  0.00616606 0.12982348 0.00678682 0.5649675 ]\n",
      " [0.63091224 0.04936996 0.01699413 0.00464334 0.01269574 0.00107281\n",
      "  0.00240493 0.00160581 0.2595701  0.02073088]\n",
      " [0.01074807 0.00733476 0.16211765 0.38926578 0.13827334 0.12789927\n",
      "  0.11386637 0.03963775 0.00324656 0.00761058]\n",
      " [0.09514406 0.00298088 0.00046915 0.00016584 0.00034977 0.00001321\n",
      "  0.00006364 0.00003218 0.8958602  0.00492113]\n",
      " [0.0197958  0.3792417  0.0201243  0.06361421 0.00681486 0.04609639\n",
      "  0.04842833 0.01637382 0.05088654 0.348624  ]\n",
      " [0.071307   0.00097239 0.00233982 0.00219578 0.00077694 0.00009492\n",
      "  0.00066272 0.00011535 0.9199942  0.0015409 ]\n",
      " [0.00267194 0.00112896 0.03561253 0.1423179  0.0331384  0.1783071\n",
      "  0.00093906 0.60310394 0.00065475 0.00212538]\n",
      " [0.13847966 0.12370449 0.01400961 0.02344905 0.01432564 0.00628166\n",
      "  0.00456824 0.00568613 0.51162887 0.15786655]\n",
      " [0.0326094  0.10824244 0.02179297 0.03644824 0.01734716 0.05207179\n",
      "  0.01563986 0.07800775 0.01458022 0.62326026]\n",
      " [0.0114637  0.0038319  0.07137442 0.14846571 0.07820892 0.33736506\n",
      "  0.00852916 0.32314995 0.00251974 0.01509144]\n",
      " [0.01083779 0.23460528 0.02588921 0.04410053 0.00835792 0.0535449\n",
      "  0.0097244  0.17788242 0.00350918 0.43154836]\n",
      " [0.37277094 0.53114486 0.00123142 0.00006454 0.00028593 0.00005333\n",
      "  0.00001098 0.00009174 0.03065422 0.06369205]\n",
      " [0.00694139 0.0364096  0.01305618 0.06613245 0.01588063 0.05610584\n",
      "  0.7463206  0.00973017 0.00461017 0.04481288]\n",
      " [0.00771778 0.16731787 0.00112872 0.00663584 0.0011948  0.00093183\n",
      "  0.00134749 0.00316954 0.00083355 0.8097226 ]\n",
      " [0.01574287 0.00115385 0.52046895 0.07721686 0.23207517 0.0542287\n",
      "  0.05944608 0.03743504 0.00102448 0.00120804]\n",
      " [0.0110072  0.09135435 0.04663371 0.29462865 0.03488688 0.15129276\n",
      "  0.17468803 0.11245476 0.00366558 0.07938807]\n",
      " [0.26126897 0.0805235  0.0442097  0.03603308 0.03234446 0.01421985\n",
      "  0.01111722 0.01067203 0.4490112  0.06059998]\n",
      " [0.00347909 0.00079988 0.02606627 0.67706305 0.00313939 0.23548935\n",
      "  0.00525956 0.03125939 0.00079055 0.0166536 ]\n",
      " [0.00271934 0.00303113 0.03085576 0.02386644 0.1519134  0.04179822\n",
      "  0.06694875 0.6757713  0.00045778 0.00263788]\n",
      " [0.03889329 0.13852099 0.02166308 0.01255315 0.01815505 0.02122952\n",
      "  0.00258192 0.08781347 0.02210522 0.63648427]\n",
      " [0.00672814 0.00331642 0.09458765 0.16471997 0.08490998 0.21146266\n",
      "  0.01229339 0.40837964 0.00099627 0.01260592]\n",
      " [0.00060401 0.00060506 0.06668955 0.2408366  0.05051808 0.12101923\n",
      "  0.51013345 0.00770898 0.0010761  0.00080896]\n",
      " [0.3083408  0.05731087 0.06653971 0.02679066 0.03644173 0.01638562\n",
      "  0.03127458 0.01068021 0.35586894 0.09036694]\n",
      " [0.00048193 0.00013557 0.01533876 0.17738846 0.00640341 0.7640596\n",
      "  0.00343699 0.03213754 0.00021999 0.00039778]\n",
      " [0.00082286 0.09341033 0.00072807 0.01268123 0.00051249 0.00285745\n",
      "  0.00652934 0.05017154 0.00029112 0.8319956 ]\n",
      " [0.0001627  0.00033748 0.01189815 0.01336877 0.2159467  0.0073657\n",
      "  0.7418972  0.00894884 0.00002555 0.00004888]\n",
      " [0.02253126 0.1298815  0.00268926 0.00147588 0.00566377 0.00252232\n",
      "  0.0003516  0.07711773 0.00032798 0.7574387 ]\n",
      " [0.12045552 0.06202431 0.13860999 0.1552236  0.07475845 0.0601077\n",
      "  0.03162294 0.06145752 0.10442478 0.1913151 ]\n",
      " [0.00116742 0.00026919 0.00688102 0.17558928 0.00391179 0.7898116\n",
      "  0.00551457 0.01563726 0.00069897 0.00051887]\n",
      " [0.04674385 0.00289278 0.12381241 0.00674136 0.33353022 0.00357567\n",
      "  0.00212262 0.4801215  0.00016659 0.0002929 ]\n",
      " [0.00868623 0.51265806 0.00159032 0.01453329 0.00065826 0.00659325\n",
      "  0.01305368 0.0021568  0.04620171 0.39386842]\n",
      " [0.04172238 0.4290047  0.00404245 0.00283124 0.00337434 0.00095221\n",
      "  0.00086008 0.00458132 0.01350565 0.49912557]\n",
      " [0.02997428 0.1315254  0.01753485 0.01171813 0.00535985 0.01129168\n",
      "  0.00160237 0.03148042 0.01168152 0.7478315 ]\n",
      " [0.00078391 0.00348306 0.00392091 0.08801466 0.00996011 0.05176338\n",
      "  0.81657887 0.0089062  0.00029111 0.01629771]\n",
      " [0.5100983  0.10010896 0.06301031 0.02040234 0.11367245 0.01294671\n",
      "  0.04456497 0.01791468 0.06353974 0.05374156]\n",
      " [0.02451496 0.00646773 0.10405183 0.3447229  0.05026511 0.24887754\n",
      "  0.05984767 0.08970458 0.02896339 0.0425843 ]\n",
      " [0.92115283 0.00030024 0.04483185 0.00331317 0.01957127 0.00226885\n",
      "  0.00026716 0.00670579 0.00126352 0.00032532]\n",
      " [0.02412283 0.00484285 0.19894023 0.19463241 0.14147128 0.22955175\n",
      "  0.14107361 0.03612896 0.02283295 0.00640314]\n",
      " [0.06091933 0.13776083 0.00495657 0.01338822 0.00326781 0.00318073\n",
      "  0.00417031 0.00301708 0.18561454 0.5837246 ]\n",
      " [0.00286243 0.03305448 0.02323513 0.0282755  0.00830308 0.02074916\n",
      "  0.857473   0.00797938 0.00028501 0.01778274]\n",
      " [0.01083431 0.00412787 0.19028634 0.22914015 0.10531049 0.14641476\n",
      "  0.10913288 0.19300419 0.00206943 0.00967962]\n",
      " [0.00516659 0.00092411 0.04609636 0.48983967 0.08633851 0.17082806\n",
      "  0.02242259 0.17571102 0.00163547 0.00103769]\n",
      " [0.00769831 0.0165701  0.09928426 0.3216961  0.08032891 0.20748645\n",
      "  0.15737666 0.08509013 0.00604418 0.01842487]\n",
      " [0.9546715  0.00115004 0.00817509 0.00040856 0.00621635 0.00005656\n",
      "  0.00043406 0.00003487 0.02801143 0.00084163]\n",
      " [0.01365985 0.01194678 0.1343388  0.19429657 0.11287424 0.21559969\n",
      "  0.20705822 0.08312953 0.01364259 0.01345372]\n",
      " [0.00122598 0.00407251 0.01971297 0.02029436 0.20092414 0.03504455\n",
      "  0.5757043  0.14044558 0.00007046 0.00250505]\n",
      " [0.07016411 0.02454065 0.1406764  0.12963471 0.13149828 0.11709622\n",
      "  0.02065383 0.28879118 0.02061573 0.05632892]\n",
      " [0.05019775 0.07020839 0.0469681  0.0748152  0.05012754 0.08062616\n",
      "  0.01958142 0.26871064 0.0196863  0.31907845]\n",
      " [0.2514785  0.26679885 0.03738059 0.01995614 0.02287058 0.0186376\n",
      "  0.01358369 0.04892265 0.03667321 0.2836981 ]\n",
      " [0.9658324  0.00131466 0.01630202 0.00077566 0.00428598 0.00033533\n",
      "  0.00078622 0.00006235 0.00971844 0.00058702]\n",
      " [0.03293704 0.01111288 0.14302017 0.25492823 0.15049826 0.17049176\n",
      "  0.0673748  0.11082431 0.02482583 0.03398678]\n",
      " [0.24311575 0.01509665 0.28194872 0.10445302 0.11191512 0.05670661\n",
      "  0.05200112 0.02267624 0.09056303 0.02152365]\n",
      " [0.00094255 0.01819917 0.00464824 0.01735061 0.00440715 0.00617806\n",
      "  0.92647564 0.0012324  0.00020041 0.02036559]\n",
      " [0.56649655 0.00403592 0.01296762 0.00404237 0.00578955 0.00130837\n",
      "  0.00049308 0.00023544 0.40254906 0.00208207]\n",
      " [0.03311533 0.02210148 0.11671889 0.31701583 0.05258369 0.21820207\n",
      "  0.08131242 0.08739618 0.03921077 0.03234336]\n",
      " [0.04054314 0.01233432 0.01907593 0.02857505 0.04755409 0.03215818\n",
      "  0.02348042 0.6065618  0.00263122 0.1870859 ]\n",
      " [0.25221154 0.00573287 0.317831   0.10933933 0.08618293 0.04920959\n",
      "  0.03879679 0.01872388 0.11281623 0.00915567]\n",
      " [0.00316963 0.00366029 0.02181212 0.03261456 0.01012981 0.00627059\n",
      "  0.9107528  0.00223482 0.00360582 0.00574959]\n",
      " [0.02962573 0.01238704 0.26493675 0.24573787 0.1362861  0.19080067\n",
      "  0.02682587 0.08507457 0.00299176 0.00533364]\n",
      " [0.20386612 0.4189384  0.00550736 0.01127816 0.00709188 0.00222821\n",
      "  0.00468459 0.00234778 0.15731294 0.18674454]\n",
      " [0.00246968 0.00130399 0.02967643 0.18093836 0.18988293 0.08269458\n",
      "  0.3211829  0.18703794 0.00100574 0.00380748]\n",
      " [0.0092714  0.00152395 0.12319629 0.07947432 0.04254834 0.16681485\n",
      "  0.00508965 0.5640726  0.00409602 0.00391255]\n",
      " [0.02837607 0.00011521 0.24947728 0.04468704 0.35657588 0.26501533\n",
      "  0.01059014 0.04472964 0.00026918 0.00016417]\n",
      " [0.03225499 0.01389801 0.10398506 0.14054628 0.06672861 0.13901101\n",
      "  0.01181061 0.4335283  0.00298752 0.05524953]\n",
      " [0.87783283 0.00467861 0.05572421 0.00719289 0.00805277 0.00295177\n",
      "  0.00214643 0.00049758 0.03904085 0.00188208]\n",
      " [0.01866989 0.01226236 0.06139665 0.12352262 0.07684456 0.31905258\n",
      "  0.01806062 0.34187084 0.00308213 0.02523779]\n",
      " [0.31877562 0.01416541 0.00669523 0.00183411 0.00231898 0.0003996\n",
      "  0.00051563 0.00018053 0.643991   0.01112393]\n",
      " [0.00094633 0.00094141 0.01078494 0.01870088 0.02460911 0.02338312\n",
      "  0.00597377 0.9117922  0.00013885 0.00272942]\n",
      " [0.01925684 0.00709051 0.11014944 0.30044818 0.13253762 0.19664173\n",
      "  0.09998392 0.09684145 0.00539687 0.03165349]] (35.505 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.3271173, step = 501 (35.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.95831\n",
      "INFO:tensorflow:probabilities = [[0.23753615 0.22442338 0.23499556 0.02927588 0.04338806 0.03479349\n",
      "  0.04430881 0.04994701 0.05433894 0.04699275]\n",
      " [0.00428133 0.03017059 0.17409691 0.1876525  0.06606871 0.06869231\n",
      "  0.43709695 0.02117559 0.00618529 0.0045798 ]\n",
      " [0.00152657 0.00033335 0.08024876 0.0767571  0.6424876  0.04148414\n",
      "  0.09836079 0.05826834 0.0002945  0.0002388 ]\n",
      " [0.20645359 0.0077243  0.04381411 0.01622509 0.01543351 0.00707705\n",
      "  0.00692661 0.00145607 0.6888422  0.00604749]\n",
      " [0.0408046  0.00961763 0.20089217 0.3407327  0.05324432 0.17152049\n",
      "  0.10025794 0.02977553 0.04140709 0.01174751]\n",
      " [0.04085867 0.00789413 0.00801393 0.0053508  0.00511652 0.01026084\n",
      "  0.00048266 0.23514448 0.00150267 0.68537533]\n",
      " [0.00055518 0.00011523 0.05788083 0.6141794  0.15318234 0.07154179\n",
      "  0.09421741 0.00821055 0.00005568 0.0000616 ]\n",
      " [0.00012482 0.00008321 0.00526453 0.01605712 0.10838921 0.01341917\n",
      "  0.00040854 0.8562139  0.00000998 0.00002951]\n",
      " [0.00598377 0.35089263 0.00405485 0.09481507 0.00121082 0.04885368\n",
      "  0.03427318 0.00235924 0.0296611  0.42789572]\n",
      " [0.00455312 0.8139589  0.00296666 0.00588852 0.0026914  0.00213281\n",
      "  0.00665608 0.00071958 0.01591769 0.14451529]\n",
      " [0.20976757 0.00729927 0.24546088 0.03257455 0.07704785 0.01873961\n",
      "  0.0056778  0.07225781 0.20758168 0.12359312]\n",
      " [0.00251344 0.00015761 0.01641493 0.27905858 0.01341688 0.60541433\n",
      "  0.00083573 0.08170783 0.00029323 0.00018743]\n",
      " [0.04545026 0.01142737 0.099251   0.264173   0.04609617 0.27764168\n",
      "  0.04980358 0.14724931 0.0192727  0.03963492]\n",
      " [0.3344017  0.00524555 0.2955969  0.04410123 0.07061071 0.02988683\n",
      "  0.01924254 0.03195846 0.15326019 0.01569579]\n",
      " [0.00172676 0.00003414 0.07748127 0.12581527 0.0282751  0.7450857\n",
      "  0.00550725 0.01545471 0.00058602 0.00003378]\n",
      " [0.09723432 0.09846098 0.00295835 0.00295993 0.00433313 0.00159816\n",
      "  0.00101804 0.00489942 0.20925781 0.5772798 ]\n",
      " [0.03838889 0.06117132 0.09703359 0.25120056 0.10729323 0.1231515\n",
      "  0.16655666 0.08656909 0.02397035 0.04466478]\n",
      " [0.03287375 0.04268356 0.06099978 0.45342195 0.01756821 0.20752986\n",
      "  0.06211257 0.04566383 0.03080086 0.04634568]\n",
      " [0.46009335 0.00028964 0.36209306 0.05429503 0.04458839 0.0341883\n",
      "  0.00247139 0.02992165 0.01024959 0.00180969]\n",
      " [0.00071023 0.868905   0.00006352 0.00010481 0.00005426 0.00022791\n",
      "  0.00006243 0.00009008 0.00036149 0.12942018]\n",
      " [0.469155   0.00245857 0.04555225 0.00637061 0.00308972 0.00341156\n",
      "  0.00280213 0.00031256 0.46160558 0.00524201]\n",
      " [0.00004028 0.00008652 0.00028813 0.01063939 0.00099063 0.00339113\n",
      "  0.98441297 0.0000174  0.00006012 0.00007359]\n",
      " [0.25350547 0.21543044 0.00698478 0.00412814 0.00676908 0.00339535\n",
      "  0.00612724 0.00925774 0.14012143 0.35428026]\n",
      " [0.5018411  0.01530518 0.17232107 0.02580605 0.14182374 0.02607307\n",
      "  0.00631159 0.06835989 0.01635208 0.02580625]\n",
      " [0.00727774 0.00017491 0.20417336 0.11316158 0.42910334 0.11958222\n",
      "  0.06136595 0.06138346 0.00330991 0.00046763]\n",
      " [0.02828438 0.00661724 0.13150886 0.17699057 0.10430164 0.08260053\n",
      "  0.37722126 0.01863719 0.06712808 0.00671022]\n",
      " [0.00525706 0.00279175 0.09282125 0.2859156  0.09724658 0.41625875\n",
      "  0.01120494 0.08586399 0.00132193 0.00131816]\n",
      " [0.03632681 0.00786009 0.11235312 0.0734085  0.49417484 0.09529413\n",
      "  0.06308963 0.07953776 0.03104936 0.00690575]\n",
      " [0.03166612 0.12516579 0.04354457 0.2663836  0.02271168 0.09696398\n",
      "  0.01660513 0.07454317 0.00471434 0.3177016 ]\n",
      " [0.00198306 0.00198373 0.04133684 0.08957849 0.03596654 0.04841394\n",
      "  0.7674388  0.00860254 0.00086355 0.00383249]\n",
      " [0.01294418 0.04271023 0.04323189 0.2540432  0.11447307 0.13351811\n",
      "  0.1783615  0.18087125 0.00937298 0.0304735 ]\n",
      " [0.6078583  0.01588714 0.13121742 0.00679788 0.06681243 0.00317092\n",
      "  0.00739202 0.00631673 0.13686578 0.01768122]\n",
      " [0.03086044 0.00401055 0.01659679 0.08622009 0.07428334 0.04557493\n",
      "  0.00886117 0.71306103 0.00128283 0.01924879]\n",
      " [0.00007428 0.00000569 0.01697341 0.0080129  0.34772325 0.0229334\n",
      "  0.6026218  0.00164674 0.00000521 0.00000336]\n",
      " [0.43426636 0.17560367 0.02144861 0.00717527 0.0125539  0.00255654\n",
      "  0.0016709  0.00421346 0.15862063 0.18189068]\n",
      " [0.11486682 0.19447011 0.02975375 0.02284312 0.04302913 0.00923875\n",
      "  0.01063452 0.02490731 0.12280545 0.427451  ]\n",
      " [0.007258   0.00276946 0.01947424 0.01961342 0.35627136 0.01884611\n",
      "  0.01234119 0.55967414 0.0020815  0.00167062]\n",
      " [0.01340103 0.00776254 0.16577657 0.10443322 0.17543355 0.20118718\n",
      "  0.04553876 0.27084112 0.0033039  0.01232211]\n",
      " [0.0076866  0.8336644  0.00100858 0.00033314 0.00022599 0.00022769\n",
      "  0.00017452 0.0001735  0.00478026 0.15172528]\n",
      " [0.01465944 0.00257374 0.14147723 0.30098668 0.05625283 0.29512927\n",
      "  0.0286118  0.14189626 0.00974785 0.00866499]\n",
      " [0.06839146 0.6730141  0.00244453 0.00221241 0.0026933  0.00171241\n",
      "  0.00127335 0.00155003 0.0239944  0.22271405]\n",
      " [0.00171422 0.00037132 0.0210348  0.34123236 0.05908461 0.3357846\n",
      "  0.00778676 0.22974248 0.00036792 0.00288088]\n",
      " [0.04316991 0.6037107  0.0014856  0.0014701  0.00448672 0.00087779\n",
      "  0.0069157  0.0002305  0.290638   0.04701501]\n",
      " [0.00810917 0.00110206 0.04431498 0.01515019 0.22464006 0.02005012\n",
      "  0.00089954 0.6805974  0.00124262 0.00389387]\n",
      " [0.01655187 0.005615   0.8175298  0.0375041  0.0142536  0.04313502\n",
      "  0.03662957 0.02212187 0.00176911 0.00488997]\n",
      " [0.01256274 0.13843384 0.00050947 0.00008946 0.00064439 0.00033791\n",
      "  0.00003302 0.00812559 0.00039712 0.8388664 ]\n",
      " [0.00001506 0.00000114 0.0020036  0.00122346 0.02004247 0.00429968\n",
      "  0.00149503 0.9709151  0.00000021 0.00000425]\n",
      " [0.0531504  0.52934843 0.02845355 0.05085194 0.04024153 0.01265732\n",
      "  0.05116348 0.01039793 0.07193002 0.15180539]\n",
      " [0.00634438 0.00679973 0.09141815 0.34398696 0.10487621 0.20211923\n",
      "  0.1562104  0.07562628 0.00465199 0.00796657]\n",
      " [0.00375833 0.00004921 0.97215974 0.00508794 0.00713381 0.00646087\n",
      "  0.0036649  0.00058598 0.0010211  0.00007812]\n",
      " [0.03490905 0.6288549  0.01617796 0.02730518 0.01426504 0.03065253\n",
      "  0.00716477 0.02162492 0.00513298 0.21391279]\n",
      " [0.00006001 0.0000104  0.02515439 0.01905929 0.9042608  0.01359624\n",
      "  0.01537976 0.02244618 0.00002347 0.00000933]\n",
      " [0.00073406 0.00003741 0.13272367 0.01384133 0.38708964 0.01992727\n",
      "  0.4409208  0.00466136 0.00005396 0.00001066]\n",
      " [0.00782343 0.02479607 0.00023973 0.00013539 0.00008877 0.00013232\n",
      "  0.00003811 0.00103046 0.00165216 0.9640635 ]\n",
      " [0.7362337  0.00084585 0.18243721 0.01126059 0.04095957 0.01255272\n",
      "  0.00249208 0.00441063 0.00815399 0.00065359]\n",
      " [0.066348   0.16353035 0.11133644 0.13776948 0.09183107 0.07595494\n",
      "  0.10222833 0.07353231 0.07216584 0.10530318]\n",
      " [0.00161507 0.00003316 0.1473116  0.07389381 0.57998943 0.10725606\n",
      "  0.01960672 0.07008436 0.00012677 0.00008305]\n",
      " [0.00171814 0.00393973 0.0020326  0.65885264 0.01313046 0.01530196\n",
      "  0.2851302  0.0135578  0.00138077 0.00495565]\n",
      " [0.00076105 0.00017569 0.11375875 0.65898395 0.01886156 0.15953086\n",
      "  0.01365708 0.03339234 0.00033185 0.00054699]\n",
      " [0.00142098 0.00036266 0.0244159  0.53065884 0.05838982 0.1743676\n",
      "  0.12791267 0.07785809 0.00167553 0.00293784]\n",
      " [0.00014438 0.00853657 0.00181519 0.7945501  0.00113665 0.04224077\n",
      "  0.07394056 0.01698379 0.00015942 0.06049252]\n",
      " [0.35854346 0.00027246 0.45431083 0.02789029 0.0960436  0.02014323\n",
      "  0.00521828 0.00589092 0.03098572 0.00070132]\n",
      " [0.10320232 0.04760441 0.08008427 0.24110541 0.08613413 0.16096684\n",
      "  0.04814086 0.09377866 0.08920124 0.04978181]\n",
      " [0.00702117 0.00486091 0.03408791 0.09395829 0.13172701 0.07550343\n",
      "  0.58649784 0.05753724 0.00204927 0.00675692]\n",
      " [0.06212797 0.02243674 0.09874097 0.2683352  0.05990566 0.25573096\n",
      "  0.0353421  0.047598   0.12027951 0.02950283]\n",
      " [0.03317725 0.00146783 0.2751989  0.19644792 0.16159366 0.21143399\n",
      "  0.03376058 0.06044875 0.02220431 0.0042667 ]\n",
      " [0.05379985 0.02210213 0.01684604 0.04734048 0.00698316 0.02632697\n",
      "  0.00705652 0.00776604 0.7891935  0.02258532]\n",
      " [0.0339935  0.01250868 0.11774854 0.41831884 0.03303276 0.1907832\n",
      "  0.02125421 0.05853485 0.10370174 0.0101236 ]\n",
      " [0.05519777 0.57433313 0.03083494 0.16756578 0.01495664 0.04298093\n",
      "  0.01061929 0.00827309 0.0072837  0.08795469]\n",
      " [0.05067417 0.0567768  0.09540424 0.34433383 0.05838001 0.15851204\n",
      "  0.09506494 0.02242089 0.09670444 0.02172856]\n",
      " [0.00927103 0.00183545 0.29811743 0.08979538 0.22997855 0.20596291\n",
      "  0.04846306 0.10532632 0.00748877 0.00376111]\n",
      " [0.01047686 0.00586945 0.00055944 0.00115332 0.00016317 0.00036162\n",
      "  0.00014217 0.0000722  0.97854394 0.00265796]\n",
      " [0.10331937 0.0132524  0.5379248  0.06608787 0.04533968 0.07921307\n",
      "  0.00562882 0.13064049 0.00683426 0.0117592 ]\n",
      " [0.001434   0.00005738 0.00593911 0.0171293  0.74881536 0.00731635\n",
      "  0.00339082 0.21573636 0.0000736  0.00010772]\n",
      " [0.00664509 0.00048577 0.0465484  0.10622514 0.14495604 0.11562676\n",
      "  0.00210091 0.575682   0.00062408 0.0011058 ]\n",
      " [0.46421632 0.01646258 0.12015991 0.12364873 0.0598588  0.07521109\n",
      "  0.03109247 0.0531473  0.03482642 0.02137629]\n",
      " [0.00130052 0.00005542 0.11705986 0.02431025 0.52576286 0.03404272\n",
      "  0.29004705 0.00720737 0.00017604 0.00003787]\n",
      " [0.00006401 0.00000048 0.00990806 0.27265188 0.00684461 0.70513564\n",
      "  0.00013616 0.00524742 0.00001061 0.00000112]\n",
      " [0.00241904 0.81759554 0.00086023 0.00188704 0.0003455  0.00108351\n",
      "  0.00048276 0.0003029  0.01205744 0.16296604]\n",
      " [0.00133112 0.00027966 0.02595807 0.1870707  0.47008806 0.14457566\n",
      "  0.0552466  0.11470794 0.00029424 0.00044798]\n",
      " [0.02971776 0.01872055 0.04057961 0.20681182 0.18085092 0.04137865\n",
      "  0.03222941 0.43531865 0.00653473 0.00785787]\n",
      " [0.00027201 0.00002716 0.00744859 0.0850205  0.48243767 0.03714325\n",
      "  0.36948222 0.01810112 0.00002778 0.00003959]\n",
      " [0.9575727  0.00012855 0.03126208 0.0007657  0.002676   0.00262594\n",
      "  0.00012516 0.00009548 0.00457252 0.00017576]\n",
      " [0.03038375 0.01589942 0.01241028 0.00517065 0.05769149 0.00387936\n",
      "  0.8651786  0.00408573 0.0009649  0.00433566]\n",
      " [0.01011785 0.00333335 0.06559888 0.09760541 0.19244662 0.07070291\n",
      "  0.5122342  0.03727255 0.00372355 0.00696466]\n",
      " [0.00315987 0.08172484 0.00019353 0.00039601 0.00006471 0.00022455\n",
      "  0.00061235 0.00033889 0.00082076 0.9124645 ]\n",
      " [0.00066855 0.00000066 0.86983883 0.0007226  0.11390287 0.00628268\n",
      "  0.00809342 0.00048185 0.00000803 0.00000051]\n",
      " [0.03018618 0.11176764 0.05139055 0.31166705 0.04774057 0.14846562\n",
      "  0.1786382  0.04938007 0.01746707 0.05329705]\n",
      " [0.01564513 0.00627997 0.02784576 0.05257081 0.08415364 0.06106494\n",
      "  0.00587441 0.71333045 0.00490339 0.0283314 ]\n",
      " [0.34006557 0.28371766 0.11818809 0.03240978 0.01395402 0.02373323\n",
      "  0.01856909 0.00568986 0.04001523 0.12365747]\n",
      " [0.00295381 0.0044661  0.05624711 0.22191629 0.23628406 0.13218679\n",
      "  0.083581   0.2591642  0.00092278 0.00227778]\n",
      " [0.02164762 0.76543003 0.00147055 0.00319268 0.00037384 0.00283409\n",
      "  0.00033258 0.01836678 0.00106182 0.18528986]\n",
      " [0.00164683 0.92885786 0.00022771 0.00042727 0.00013542 0.00008525\n",
      "  0.00008217 0.0000359  0.00842246 0.06007917]\n",
      " [0.26802105 0.12913348 0.06253054 0.02420066 0.05769582 0.00802746\n",
      "  0.01012287 0.0317249  0.08653317 0.32201004]\n",
      " [0.00317309 0.00048408 0.15472202 0.03671771 0.53073424 0.08977517\n",
      "  0.13519038 0.04787656 0.00101125 0.00031543]\n",
      " [0.01675968 0.00084485 0.12201906 0.55140316 0.0543675  0.14437549\n",
      "  0.01655563 0.09173328 0.00097609 0.00096528]\n",
      " [0.90538865 0.00453522 0.0422666  0.00388499 0.01629438 0.00186451\n",
      "  0.00382281 0.00132116 0.01543428 0.00518737]\n",
      " [0.00948716 0.5856714  0.00763922 0.01971707 0.00467153 0.00552012\n",
      "  0.01038042 0.00289216 0.01214998 0.3418709 ]\n",
      " [0.00089826 0.0098793  0.01169783 0.7817495  0.00135392 0.07869048\n",
      "  0.02991981 0.01320772 0.00071041 0.07189278]\n",
      " [0.0177949  0.00077468 0.2614132  0.28966916 0.0709878  0.24119131\n",
      "  0.06824779 0.0402469  0.00668051 0.00299385]] (33.804 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.2981021, step = 601 (33.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.92714\n",
      "INFO:tensorflow:probabilities = [[0.95149046 0.00995944 0.00068075 0.00001488 0.00032318 0.00000271\n",
      "  0.0000519  0.00000464 0.01882065 0.01865139]\n",
      " [0.48996046 0.08842228 0.01465509 0.00085807 0.00209241 0.00034084\n",
      "  0.00024749 0.00587793 0.1939503  0.20359509]\n",
      " [0.00158019 0.00155653 0.01937619 0.15150213 0.00751447 0.378131\n",
      "  0.06065214 0.18153094 0.00036102 0.19779538]\n",
      " [0.01373238 0.00110062 0.08903375 0.15510917 0.07700665 0.4109391\n",
      "  0.00214369 0.24922071 0.00069582 0.00101815]\n",
      " [0.0364345  0.01743395 0.07003046 0.14864601 0.1263529  0.05090428\n",
      "  0.47310466 0.03546422 0.01048723 0.03114193]\n",
      " [0.21677855 0.20635925 0.00617041 0.00309239 0.00267637 0.000674\n",
      "  0.00289108 0.00123769 0.50631446 0.05380577]\n",
      " [0.09883008 0.002134   0.09970246 0.10553446 0.36309066 0.07232215\n",
      "  0.00841287 0.20811222 0.00519178 0.03666922]\n",
      " [0.02010472 0.00391935 0.28249246 0.01808975 0.43898603 0.04436233\n",
      "  0.04629381 0.1408876  0.00173315 0.00313084]\n",
      " [0.01646003 0.7601557  0.0005057  0.00040081 0.00018732 0.00006877\n",
      "  0.00021082 0.00008139 0.13294323 0.08898634]\n",
      " [0.11756825 0.19515716 0.02275979 0.03235969 0.01359013 0.01451295\n",
      "  0.00507959 0.01521858 0.4236448  0.16010906]\n",
      " [0.00768344 0.00169545 0.10321902 0.18973759 0.25568625 0.23844074\n",
      "  0.0691122  0.12910879 0.00258133 0.00273515]\n",
      " [0.08570661 0.37848297 0.10887461 0.0476524  0.06010979 0.04206545\n",
      "  0.10557035 0.06733236 0.01997358 0.08423194]\n",
      " [0.06096656 0.01358933 0.2895479  0.13203178 0.09440596 0.14920397\n",
      "  0.01004795 0.20511907 0.01073216 0.03435518]\n",
      " [0.00929306 0.00229599 0.05813214 0.06437433 0.4992438  0.05292862\n",
      "  0.07491815 0.23137116 0.00135693 0.00608579]\n",
      " [0.17636113 0.00833896 0.00640439 0.00145261 0.0053235  0.00038915\n",
      "  0.00063065 0.00048226 0.77680975 0.0238076 ]\n",
      " [0.00019541 0.9159159  0.00000398 0.00002417 0.0000163  0.00000679\n",
      "  0.00018913 0.00000364 0.00023038 0.08341446]\n",
      " [0.37707582 0.02837473 0.16873375 0.03863428 0.09841137 0.01493305\n",
      "  0.18095025 0.01074052 0.03129704 0.05084922]\n",
      " [0.00244354 0.0071596  0.02072692 0.12451176 0.02991841 0.01988582\n",
      "  0.78336424 0.00177813 0.00325441 0.00695709]\n",
      " [0.12259204 0.00448293 0.35457042 0.06987482 0.233343   0.09280905\n",
      "  0.04788558 0.02892151 0.04078789 0.00473277]\n",
      " [0.00096676 0.19948462 0.00002869 0.00012448 0.00000446 0.00002358\n",
      "  0.00002454 0.00003837 0.00077606 0.79852843]\n",
      " [0.46478862 0.10947528 0.01651779 0.00467824 0.01126954 0.00200723\n",
      "  0.00213343 0.00265436 0.3530114  0.03346407]\n",
      " [0.01212198 0.00645579 0.07592551 0.04402353 0.07790972 0.3720313\n",
      "  0.01672981 0.3895819  0.00123663 0.00398381]\n",
      " [0.03985459 0.00196177 0.4440274  0.0851007  0.06004964 0.03031678\n",
      "  0.2706167  0.00130729 0.06170057 0.00506457]\n",
      " [0.0065733  0.01213099 0.07250136 0.20827346 0.03890992 0.22708051\n",
      "  0.33505762 0.05627541 0.01761589 0.02558175]\n",
      " [0.6169217  0.00039155 0.25931102 0.02578078 0.03411344 0.00715706\n",
      "  0.00264749 0.0004065  0.05163387 0.00163661]\n",
      " [0.01899297 0.01856492 0.06271346 0.04741111 0.01468602 0.31698108\n",
      "  0.00186282 0.5012401  0.00778099 0.00976657]\n",
      " [0.03973565 0.03171678 0.0943296  0.06985407 0.13246508 0.02009646\n",
      "  0.5141843  0.04993897 0.0066504  0.04102879]\n",
      " [0.10234922 0.00555824 0.00045972 0.00005314 0.00009428 0.00000224\n",
      "  0.00001479 0.00001043 0.889273   0.00218498]\n",
      " [0.7369405  0.00020866 0.00912877 0.00084466 0.00118902 0.00062898\n",
      "  0.00015175 0.00006901 0.25051627 0.00032236]\n",
      " [0.01822154 0.00148897 0.0118659  0.00343259 0.04807736 0.02625221\n",
      "  0.00178379 0.818103   0.00024058 0.070534  ]\n",
      " [0.00105148 0.00055609 0.1411047  0.05584573 0.3447061  0.04600011\n",
      "  0.38923123 0.01915798 0.00111405 0.0012326 ]\n",
      " [0.00235458 0.510249   0.00033046 0.00084749 0.00011513 0.00206752\n",
      "  0.00048459 0.00151342 0.00028522 0.48175249]\n",
      " [0.24470933 0.08008436 0.0355626  0.03741443 0.01494944 0.00417339\n",
      "  0.02620111 0.00318479 0.43734077 0.11637976]\n",
      " [0.00905738 0.00001259 0.96372205 0.00284106 0.01203455 0.00102706\n",
      "  0.00225536 0.00007976 0.00887855 0.00009163]\n",
      " [0.01200766 0.00299771 0.22082733 0.22771531 0.13045952 0.13640344\n",
      "  0.24581511 0.01786383 0.00347076 0.00243939]\n",
      " [0.6333844  0.03757468 0.08063878 0.00602801 0.15764126 0.00389416\n",
      "  0.00529557 0.01456408 0.03977933 0.02119967]\n",
      " [0.04782347 0.01964054 0.00298145 0.00227419 0.0014105  0.00165361\n",
      "  0.00009962 0.01178405 0.00958376 0.90274876]\n",
      " [0.01326007 0.00254877 0.14667027 0.45322093 0.1491988  0.08925098\n",
      "  0.1058163  0.01694427 0.01504455 0.008045  ]\n",
      " [0.00648479 0.00194635 0.04674828 0.02618391 0.2102753  0.08584602\n",
      "  0.00453609 0.61554503 0.00101416 0.00142013]\n",
      " [0.02852727 0.63197803 0.00130798 0.0016125  0.00015037 0.00376518\n",
      "  0.00017519 0.01357194 0.00958743 0.30932415]\n",
      " [0.0121126  0.7373063  0.00388138 0.01488841 0.01089861 0.0027829\n",
      "  0.00258295 0.00132114 0.19416131 0.02006441]\n",
      " [0.65975815 0.00232482 0.14422324 0.01697393 0.13712953 0.00935961\n",
      "  0.00206809 0.00808141 0.01743908 0.00264226]\n",
      " [0.4404906  0.18366665 0.04787798 0.0093288  0.04884982 0.00684438\n",
      "  0.02413891 0.04976974 0.08648853 0.10254466]\n",
      " [0.00921905 0.00152785 0.14151677 0.24310938 0.20490134 0.3606971\n",
      "  0.01003214 0.02205694 0.0060368  0.00090263]\n",
      " [0.02479448 0.01646225 0.12806644 0.16095848 0.20858191 0.07553414\n",
      "  0.29602903 0.05105254 0.02014099 0.01837979]\n",
      " [0.01538135 0.0000373  0.0000013  0.00000011 0.00000032 0.\n",
      "  0.00000001 0.00000002 0.98456025 0.00001932]\n",
      " [0.00189841 0.00073884 0.00906908 0.04946637 0.11698388 0.17094252\n",
      "  0.00132918 0.6479325  0.00111123 0.000528  ]\n",
      " [0.02476897 0.80536216 0.00131468 0.00047745 0.00023326 0.00136846\n",
      "  0.00056967 0.00074137 0.00071299 0.16445099]\n",
      " [0.00331022 0.01148299 0.01074577 0.0035045  0.0040481  0.01298856\n",
      "  0.00147146 0.94531465 0.00045349 0.00668031]\n",
      " [0.18475387 0.0360233  0.12190821 0.06011987 0.0404754  0.02497828\n",
      "  0.01019404 0.02497324 0.43450862 0.06206517]\n",
      " [0.00140352 0.00248637 0.11262152 0.15666696 0.0862739  0.15951934\n",
      "  0.46410117 0.00480906 0.00971457 0.00240364]\n",
      " [0.00622079 0.0022741  0.12703663 0.15751055 0.23423488 0.14094672\n",
      "  0.27139896 0.05263958 0.00191495 0.00582287]\n",
      " [0.04577371 0.3793689  0.05317923 0.02727879 0.01490741 0.01307306\n",
      "  0.04145367 0.00893527 0.04298113 0.3730488 ]\n",
      " [0.0931236  0.01399251 0.30407277 0.06338158 0.18448757 0.07425396\n",
      "  0.04731406 0.04757665 0.14171843 0.03007885]\n",
      " [0.01673332 0.11964853 0.00922798 0.0481357  0.00616167 0.00546638\n",
      "  0.04834001 0.00635508 0.0142363  0.72569495]\n",
      " [0.10862679 0.04013394 0.15824303 0.13841528 0.10195509 0.03429445\n",
      "  0.31011808 0.00746796 0.05749844 0.04324694]\n",
      " [0.01401872 0.00456052 0.19802746 0.03576688 0.3064452  0.02643227\n",
      "  0.40016913 0.01072195 0.00294686 0.00091109]\n",
      " [0.0531088  0.10330402 0.05931442 0.17577375 0.08195441 0.09042469\n",
      "  0.3197428  0.04442658 0.01165199 0.06029858]\n",
      " [0.13869402 0.03771677 0.08857721 0.06357866 0.09474694 0.01084611\n",
      "  0.25483492 0.01554071 0.1608055  0.13465916]\n",
      " [0.00309987 0.00020259 0.26196542 0.02893087 0.20868856 0.0094904\n",
      "  0.47787842 0.00825943 0.00125524 0.00022926]\n",
      " [0.28898218 0.00230946 0.00773484 0.00064907 0.00659916 0.00020751\n",
      "  0.00048763 0.00039118 0.68919086 0.00344811]\n",
      " [0.3451033  0.17436148 0.09466682 0.01866162 0.07812809 0.01671831\n",
      "  0.05204623 0.01879948 0.1243138  0.07720094]\n",
      " [0.01567287 0.00077588 0.45730764 0.07883281 0.16756012 0.02334102\n",
      "  0.22597139 0.00739177 0.02216363 0.00098293]\n",
      " [0.02717777 0.05916682 0.13362776 0.32123464 0.06373248 0.18093032\n",
      "  0.10176405 0.04608973 0.02444654 0.04182994]\n",
      " [0.00814216 0.0745493  0.0269826  0.05919195 0.00628715 0.09411687\n",
      "  0.05110186 0.01549096 0.00292413 0.661213  ]\n",
      " [0.08502923 0.02176537 0.15638822 0.09522127 0.13439964 0.06467092\n",
      "  0.21267316 0.17555626 0.01415779 0.04013807]\n",
      " [0.14423358 0.03003399 0.00002362 0.00000314 0.00000889 0.00000007\n",
      "  0.00000022 0.00000013 0.8247692  0.0009272 ]\n",
      " [0.00655331 0.00082378 0.39033487 0.04750101 0.36808705 0.06552384\n",
      "  0.02565301 0.08704653 0.00777413 0.00070243]\n",
      " [0.05213451 0.0032332  0.19209112 0.03812211 0.3953808  0.01376333\n",
      "  0.24780937 0.04194025 0.00541091 0.01011449]\n",
      " [0.03184139 0.42425942 0.0111413  0.00451574 0.0031196  0.00897617\n",
      "  0.00119615 0.00661633 0.01144846 0.4968854 ]\n",
      " [0.02099443 0.08218962 0.0267844  0.05558756 0.01697912 0.0336263\n",
      "  0.0376023  0.08333898 0.00712665 0.6357706 ]\n",
      " [0.05903035 0.01425737 0.13650347 0.12203328 0.24351372 0.02283127\n",
      "  0.34491768 0.02797504 0.01320502 0.01573285]\n",
      " [0.0128501  0.02031217 0.22862843 0.06016076 0.04110143 0.09558958\n",
      "  0.09814771 0.40522826 0.01355479 0.02442668]\n",
      " [0.2393129  0.02112913 0.1942041  0.03835874 0.268093   0.04158776\n",
      "  0.0114309  0.07992145 0.09384791 0.01211407]\n",
      " [0.00398682 0.03460069 0.02568513 0.16926953 0.01531027 0.06483424\n",
      "  0.6126278  0.00542076 0.0024293  0.0658354 ]\n",
      " [0.03272318 0.14462753 0.26524812 0.08635962 0.03105455 0.12505114\n",
      "  0.01444124 0.07028463 0.00787848 0.22233143]\n",
      " [0.05671648 0.0024674  0.23740731 0.14372598 0.2790244  0.19241272\n",
      "  0.01661677 0.02015246 0.04831401 0.00316244]\n",
      " [0.03791399 0.00951457 0.0991997  0.09499055 0.5377566  0.05642666\n",
      "  0.06107195 0.07443227 0.02052051 0.00817316]\n",
      " [0.11624038 0.09335424 0.05975051 0.03404398 0.05060076 0.01153867\n",
      "  0.03322609 0.05539542 0.03291919 0.51293075]\n",
      " [0.00071655 0.00004895 0.07804488 0.0087381  0.8094156  0.02316238\n",
      "  0.01565383 0.06400236 0.00016056 0.00005673]\n",
      " [0.16039632 0.07663697 0.12459078 0.08042333 0.03741106 0.08951949\n",
      "  0.02511104 0.10114681 0.02136182 0.28340238]\n",
      " [0.01553529 0.89981806 0.00024379 0.00013302 0.00008911 0.000048\n",
      "  0.00003934 0.00004927 0.03078875 0.05325522]\n",
      " [0.00069973 0.81307083 0.00019131 0.00065434 0.00008487 0.0007984\n",
      "  0.00029861 0.00040463 0.00028167 0.18351549]\n",
      " [0.35767758 0.15819794 0.00207953 0.0016264  0.00132306 0.00017468\n",
      "  0.00061875 0.00020188 0.09037289 0.38772732]\n",
      " [0.07393627 0.01783068 0.05347764 0.37356037 0.04744091 0.14043668\n",
      "  0.23046482 0.01083731 0.03014216 0.02187317]\n",
      " [0.04517461 0.01365695 0.4214139  0.05931607 0.15220882 0.05945976\n",
      "  0.15241453 0.05018675 0.01238298 0.03378566]\n",
      " [0.00863346 0.00443535 0.02079162 0.04429195 0.10101333 0.02219859\n",
      "  0.05374439 0.68417245 0.00100318 0.05971574]\n",
      " [0.01850127 0.7164556  0.00505867 0.00836271 0.00373458 0.00305528\n",
      "  0.00778732 0.00164469 0.03005659 0.20534325]\n",
      " [0.00610663 0.07605997 0.0439598  0.17205581 0.01110873 0.02401866\n",
      "  0.5809534  0.00553585 0.01310285 0.0670983 ]\n",
      " [0.00112913 0.00016824 0.02229255 0.37086943 0.0532412  0.5269231\n",
      "  0.00199435 0.02200633 0.00125492 0.00012078]\n",
      " [0.11274087 0.00639369 0.10158024 0.05150302 0.43922293 0.05233091\n",
      "  0.01232956 0.19385126 0.02315748 0.0068901 ]\n",
      " [0.12350878 0.12408366 0.0353753  0.03971654 0.01083061 0.00802778\n",
      "  0.00803214 0.00910471 0.26306155 0.37825888]\n",
      " [0.33977988 0.11019607 0.01502526 0.00405653 0.01525334 0.0010969\n",
      "  0.00101288 0.00139998 0.47047606 0.041703  ]\n",
      " [0.6690328  0.03051689 0.06579696 0.00514232 0.03306715 0.00293842\n",
      "  0.01118231 0.00358134 0.14094096 0.03780087]\n",
      " [0.26056498 0.00090767 0.3498915  0.03075126 0.25880572 0.01986451\n",
      "  0.00838482 0.00518491 0.06459808 0.00104645]\n",
      " [0.00277916 0.00095142 0.00967766 0.5472924  0.1819477  0.22379074\n",
      "  0.00639286 0.02316919 0.00353533 0.00046356]\n",
      " [0.46763068 0.05398504 0.10844015 0.06193992 0.07169038 0.01738206\n",
      "  0.00870455 0.03526855 0.15779191 0.01716678]\n",
      " [0.04284961 0.00179159 0.17117809 0.21395174 0.26220828 0.14317146\n",
      "  0.01677233 0.13832942 0.00695724 0.00279032]\n",
      " [0.00093615 0.00176531 0.00084707 0.00241562 0.00007479 0.00345958\n",
      "  0.00002149 0.01467401 0.00008273 0.97572327]\n",
      " [0.02640509 0.8667829  0.00187948 0.00037641 0.00026957 0.00024447\n",
      "  0.00026399 0.00054197 0.01828863 0.08494742]] (34.163 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.15191, step = 701 (34.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00025\n",
      "INFO:tensorflow:probabilities = [[0.00047812 0.00135333 0.00766637 0.02870877 0.15640596 0.05720035\n",
      "  0.02158392 0.72590727 0.00011933 0.00057671]\n",
      " [0.11457142 0.11660373 0.00359276 0.00050397 0.00210058 0.00020452\n",
      "  0.00008793 0.00266074 0.0118795  0.74779487]\n",
      " [0.05987592 0.5405407  0.00518917 0.00444001 0.00383301 0.00089946\n",
      "  0.00245639 0.001411   0.29246798 0.08888642]\n",
      " [0.16425213 0.08296993 0.06439167 0.03796941 0.0956929  0.02679539\n",
      "  0.01733488 0.0476521  0.34771246 0.11522915]\n",
      " [0.02803881 0.03726096 0.03931392 0.05331808 0.02253996 0.05378502\n",
      "  0.01196165 0.19631766 0.02480794 0.532656  ]\n",
      " [0.00000394 0.9871301  0.00000193 0.00002389 0.00000064 0.00000559\n",
      "  0.00001364 0.00000048 0.00011986 0.01270005]\n",
      " [0.00175743 0.06978231 0.01706607 0.04126738 0.03441074 0.02247746\n",
      "  0.80449045 0.00363998 0.00302307 0.00208513]\n",
      " [0.00160041 0.00044874 0.01612376 0.46924555 0.00994661 0.4537076\n",
      "  0.00988623 0.01140186 0.02672122 0.00091804]\n",
      " [0.01516661 0.00025907 0.73898464 0.03766545 0.06247579 0.10138459\n",
      "  0.01577684 0.02382653 0.00272498 0.00173543]\n",
      " [0.49064323 0.00082058 0.03861968 0.00812488 0.06954385 0.0024488\n",
      "  0.0006019  0.00094975 0.387066   0.00118127]\n",
      " [0.33603343 0.00465337 0.10578395 0.06118757 0.35276815 0.03972362\n",
      "  0.00965767 0.06361125 0.01247646 0.01410451]\n",
      " [0.29409426 0.31581128 0.0042478  0.00047935 0.00126187 0.00020587\n",
      "  0.00002657 0.00063467 0.33563828 0.0476    ]\n",
      " [0.20293601 0.06089842 0.12337373 0.01448812 0.06955042 0.01387735\n",
      "  0.00668088 0.04999751 0.2489324  0.20926514]\n",
      " [0.3339503  0.06273722 0.02086137 0.00763817 0.0170071  0.0028188\n",
      "  0.00137729 0.01784398 0.49110052 0.04466514]\n",
      " [0.01375153 0.18864538 0.01595602 0.14531688 0.01403825 0.03689988\n",
      "  0.5132734  0.00421634 0.02689488 0.04100737]\n",
      " [0.00029082 0.9822965  0.00016178 0.00022537 0.00017047 0.00007603\n",
      "  0.00003306 0.00002165 0.0052846  0.01143968]\n",
      " [0.0626381  0.04886452 0.11533049 0.08441469 0.07871636 0.02667219\n",
      "  0.06405028 0.00969749 0.49703154 0.01258438]\n",
      " [0.06097373 0.00170217 0.22180209 0.08239357 0.01852338 0.21420713\n",
      "  0.00097185 0.38410717 0.00668432 0.00863464]\n",
      " [0.00411874 0.00633859 0.02212864 0.12045693 0.05569484 0.03026455\n",
      "  0.71610224 0.01409386 0.01150721 0.01929447]\n",
      " [0.00027233 0.99601483 0.00013394 0.00023813 0.00002565 0.00002794\n",
      "  0.00001684 0.00004159 0.00173232 0.00149636]\n",
      " [0.03157308 0.00977936 0.00816116 0.00456908 0.00574331 0.00208539\n",
      "  0.00089872 0.00061689 0.9327666  0.00380638]\n",
      " [0.0001394  0.00000654 0.00023185 0.24884841 0.00014894 0.7492742\n",
      "  0.00001753 0.00099326 0.00033716 0.00000265]\n",
      " [0.10754202 0.08356465 0.0275447  0.00712413 0.03004125 0.01333127\n",
      "  0.00370069 0.05011903 0.02605908 0.65097314]\n",
      " [0.95339143 0.00039432 0.00828194 0.00212275 0.0203308  0.00036126\n",
      "  0.00003145 0.00041804 0.01450644 0.00016147]\n",
      " [0.4266642  0.04329011 0.00640564 0.00764159 0.02460396 0.00287651\n",
      "  0.00395767 0.00449461 0.45383897 0.02622673]\n",
      " [0.03617042 0.00099733 0.3816218  0.03581161 0.37828043 0.04196585\n",
      "  0.02747121 0.09161415 0.00217563 0.00389144]\n",
      " [0.03331687 0.00074125 0.38978702 0.0397133  0.22632375 0.06762496\n",
      "  0.00984151 0.226281   0.00450084 0.0018695 ]\n",
      " [0.1457035  0.00196472 0.0005656  0.00000823 0.00051362 0.00000177\n",
      "  0.00000246 0.00000668 0.8496707  0.00156272]\n",
      " [0.02993475 0.00100265 0.16330124 0.01510909 0.24286707 0.01629124\n",
      "  0.00219402 0.51996136 0.00478593 0.00455253]\n",
      " [0.3379465  0.19227201 0.0340914  0.00489573 0.01464744 0.00508626\n",
      "  0.02925173 0.01584091 0.1033181  0.26264995]\n",
      " [0.48666385 0.00081805 0.08140536 0.00385239 0.02188784 0.00092894\n",
      "  0.00385195 0.00034302 0.39802337 0.00222526]\n",
      " [0.01358989 0.00342425 0.13241746 0.19079606 0.14718811 0.27983004\n",
      "  0.07852467 0.14051208 0.00884211 0.00487532]\n",
      " [0.00107357 0.00036418 0.2775765  0.0144542  0.30243504 0.01725027\n",
      "  0.36083472 0.02569941 0.00019659 0.00011551]\n",
      " [0.5390942  0.01013    0.10990962 0.04413444 0.02129698 0.03263883\n",
      "  0.00425953 0.0440195  0.17904747 0.01546937]\n",
      " [0.00011081 0.00000144 0.00337137 0.0726077  0.00003281 0.9209371\n",
      "  0.0000029  0.00104284 0.00188888 0.0000043 ]\n",
      " [0.00138457 0.00004568 0.00000449 0.00000121 0.00000268 0.00000003\n",
      "  0.00000006 0.00000003 0.99847    0.00009114]\n",
      " [0.01313933 0.01230306 0.08457483 0.44467774 0.07074013 0.15687592\n",
      "  0.13332826 0.02726427 0.03773373 0.01936278]\n",
      " [0.0362883  0.00539868 0.14266172 0.15958728 0.07660245 0.13870923\n",
      "  0.07188702 0.02490961 0.31693572 0.02702005]\n",
      " [0.00653016 0.00002332 0.6571968  0.00325928 0.30267537 0.00239198\n",
      "  0.02627699 0.00139964 0.00022554 0.000021  ]\n",
      " [0.00408124 0.00285847 0.1168866  0.10628448 0.28048298 0.08417688\n",
      "  0.37811556 0.02267868 0.00294638 0.00148875]\n",
      " [0.60518324 0.03987532 0.04758215 0.00779858 0.03853264 0.00207658\n",
      "  0.00053141 0.04826214 0.17074873 0.03940937]\n",
      " [0.04359797 0.00982652 0.2004853  0.09723496 0.08534147 0.21097058\n",
      "  0.00417874 0.3112047  0.02139336 0.01576637]\n",
      " [0.01402372 0.00069505 0.27832347 0.20996341 0.01000241 0.43250352\n",
      "  0.0069705  0.03833416 0.008445   0.00073884]\n",
      " [0.00055474 0.00012194 0.01176218 0.2995128  0.0128344  0.63452715\n",
      "  0.01850581 0.01709735 0.00433259 0.00075101]\n",
      " [0.4316394  0.19021066 0.04061577 0.00239608 0.02956194 0.00026137\n",
      "  0.23831268 0.00019467 0.04811797 0.01868956]\n",
      " [0.00295747 0.0000608  0.35644144 0.3868139  0.1031304  0.08448786\n",
      "  0.05767572 0.00525611 0.0030896  0.00008662]\n",
      " [0.07063441 0.01428124 0.29153973 0.09192913 0.25787073 0.02266832\n",
      "  0.17620562 0.04925396 0.01921383 0.00640295]\n",
      " [0.00434754 0.00102377 0.12019492 0.02855417 0.3969367  0.01982891\n",
      "  0.4127284  0.01532072 0.00081892 0.00024599]\n",
      " [0.00210408 0.00006233 0.4837617  0.08843274 0.24889775 0.06068041\n",
      "  0.07903563 0.03629109 0.00057238 0.00016187]\n",
      " [0.34806222 0.06901162 0.02797733 0.02074142 0.11107576 0.01373913\n",
      "  0.00740234 0.18265328 0.09171792 0.12761894]\n",
      " [0.00372047 0.04835374 0.00134724 0.00210634 0.00010637 0.00309766\n",
      "  0.00083663 0.00083031 0.00233183 0.9372694 ]\n",
      " [0.16395313 0.03705622 0.23560892 0.13169147 0.12418614 0.06667171\n",
      "  0.0392849  0.11701658 0.05946853 0.02506237]\n",
      " [0.09951006 0.1406264  0.03249824 0.01139253 0.01639763 0.02402058\n",
      "  0.00672094 0.18989392 0.00995378 0.468986  ]\n",
      " [0.30615345 0.01117817 0.00141838 0.00020077 0.00183673 0.00003004\n",
      "  0.00039741 0.0001485  0.53080785 0.14782871]\n",
      " [0.7414693  0.03728472 0.00077621 0.00008346 0.00201133 0.00004049\n",
      "  0.00012513 0.00058411 0.0423959  0.17522936]\n",
      " [0.02365491 0.12659442 0.02377783 0.0093722  0.03096352 0.01740056\n",
      "  0.00736122 0.29920876 0.01246358 0.44920304]\n",
      " [0.07787737 0.6192865  0.04527126 0.01454983 0.04976044 0.00660499\n",
      "  0.00179856 0.09511202 0.07291792 0.01682117]\n",
      " [0.06306475 0.00840352 0.04831088 0.11639817 0.3900787  0.04286004\n",
      "  0.07704563 0.19792493 0.01660631 0.0393071 ]\n",
      " [0.2793104  0.00000181 0.6861982  0.00130673 0.03144476 0.00064949\n",
      "  0.00034454 0.00058444 0.00014797 0.00001161]\n",
      " [0.00120545 0.00024454 0.00805203 0.00269764 0.0100152  0.0027476\n",
      "  0.00066289 0.9740234  0.00002798 0.00032325]\n",
      " [0.00013098 0.00000647 0.01241884 0.09059484 0.00011412 0.8936151\n",
      "  0.00005378 0.00297335 0.00008309 0.00000933]\n",
      " [0.01174416 0.3186728  0.00022031 0.00086746 0.00038083 0.0002758\n",
      "  0.00292403 0.00006226 0.36573964 0.2991127 ]\n",
      " [0.00790815 0.08599178 0.00109989 0.00474473 0.00156535 0.00188652\n",
      "  0.00146528 0.00509754 0.02852932 0.8617115 ]\n",
      " [0.23885109 0.01392951 0.10073885 0.03173701 0.21399209 0.01591914\n",
      "  0.00694194 0.02861545 0.32134545 0.02792944]\n",
      " [0.33204418 0.03351924 0.02792286 0.02211755 0.04599324 0.00870689\n",
      "  0.00426022 0.01072708 0.45997497 0.05473369]\n",
      " [0.03099166 0.04798676 0.01201406 0.02281098 0.0130045  0.0083016\n",
      "  0.00514729 0.03758221 0.05761959 0.7645413 ]\n",
      " [0.05717485 0.2646144  0.0179441  0.02570283 0.04015027 0.02445218\n",
      "  0.01035006 0.13170536 0.01357425 0.4143317 ]\n",
      " [0.01142994 0.00270613 0.02922558 0.01193546 0.6788662  0.01172312\n",
      "  0.00188515 0.24730967 0.00400055 0.00091823]\n",
      " [0.0042722  0.0004832  0.12559578 0.44401202 0.02454735 0.28850767\n",
      "  0.00508912 0.10522582 0.00114132 0.0011255 ]\n",
      " [0.9730047  0.00026084 0.01431964 0.00006899 0.00738857 0.00000965\n",
      "  0.0000082  0.00019464 0.00308521 0.00165947]\n",
      " [0.0125983  0.01347564 0.03149204 0.1748301  0.06032718 0.18225117\n",
      "  0.45710042 0.03694743 0.00709573 0.0238819 ]\n",
      " [0.00471084 0.0124888  0.05151764 0.08951648 0.08482067 0.05162355\n",
      "  0.6641095  0.02081237 0.00573366 0.0146664 ]\n",
      " [0.18141803 0.0042193  0.23580717 0.0800733  0.11258949 0.0147078\n",
      "  0.35712653 0.00675771 0.00465752 0.00264315]\n",
      " [0.02968851 0.00068275 0.34305567 0.08050792 0.30743194 0.0963688\n",
      "  0.1060503  0.01815322 0.01682329 0.00123756]\n",
      " [0.00508366 0.00125591 0.26102626 0.06234938 0.21124597 0.02132446\n",
      "  0.42032796 0.01480848 0.00176281 0.00081512]\n",
      " [0.08961861 0.02106022 0.08992571 0.08947015 0.09627335 0.07674741\n",
      "  0.30767363 0.10528278 0.02453262 0.09941554]\n",
      " [0.01516471 0.00059064 0.07158924 0.01595164 0.01141336 0.14045589\n",
      "  0.00020747 0.71423566 0.01496518 0.01542622]\n",
      " [0.09847739 0.09377462 0.02699039 0.02208535 0.00972908 0.00853361\n",
      "  0.00220468 0.00850032 0.55010056 0.179604  ]\n",
      " [0.00301343 0.00456626 0.12430412 0.16306174 0.19656695 0.20439252\n",
      "  0.20883292 0.08734796 0.00308112 0.00483301]\n",
      " [0.00551273 0.00879861 0.08116258 0.22426341 0.14123335 0.19312571\n",
      "  0.21836211 0.09211791 0.01831837 0.01710525]\n",
      " [0.00133626 0.00007954 0.027912   0.7901616  0.01897652 0.07601491\n",
      "  0.08141763 0.00366672 0.00033803 0.00009677]\n",
      " [0.00005512 0.9398234  0.00001852 0.00002155 0.00002281 0.0000251\n",
      "  0.00000519 0.00004089 0.0003162  0.05967136]\n",
      " [0.02689826 0.02271115 0.10353444 0.08507963 0.14399932 0.03544112\n",
      "  0.52085763 0.02577124 0.01539018 0.02031706]\n",
      " [0.05626805 0.04582023 0.00501135 0.03937548 0.00401741 0.01719506\n",
      "  0.00381172 0.00852854 0.75278777 0.06718428]\n",
      " [0.07737065 0.0092266  0.20739599 0.05950595 0.3757903  0.03690679\n",
      "  0.02851021 0.09650838 0.07878461 0.0300005 ]\n",
      " [0.00130122 0.00228875 0.04472165 0.13283986 0.09314603 0.05761076\n",
      "  0.6417883  0.02339339 0.00205622 0.00085382]\n",
      " [0.00098429 0.00020954 0.08954411 0.01258579 0.7354497  0.01014585\n",
      "  0.1430603  0.00772158 0.00021434 0.00008454]\n",
      " [0.10388175 0.02084163 0.00052894 0.00018044 0.00373954 0.00006163\n",
      "  0.00004855 0.01285722 0.00693963 0.85092074]\n",
      " [0.60937214 0.00010477 0.2715431  0.00801882 0.05901976 0.0012858\n",
      "  0.02038886 0.00014635 0.02998211 0.00013835]\n",
      " [0.0514789  0.00150146 0.5752653  0.05005745 0.10812665 0.06840341\n",
      "  0.00434201 0.13729522 0.00247166 0.00105794]\n",
      " [0.07606819 0.24878277 0.01106019 0.07139084 0.01596979 0.00874202\n",
      "  0.09448478 0.00493343 0.3345113  0.13405664]\n",
      " [0.00075366 0.00019972 0.06809852 0.18734995 0.13724287 0.10481911\n",
      "  0.48833752 0.01296286 0.00012473 0.00011114]\n",
      " [0.11901542 0.00726726 0.10451906 0.15275231 0.12869152 0.15922368\n",
      "  0.00756066 0.26841852 0.02894707 0.02360453]\n",
      " [0.29578388 0.02043929 0.04837015 0.00537784 0.05089397 0.00196799\n",
      "  0.00177885 0.00964464 0.4597727  0.10597067]\n",
      " [0.11845754 0.00998339 0.2349611  0.0541387  0.38342643 0.02473312\n",
      "  0.03621493 0.12242468 0.01014495 0.00551524]\n",
      " [0.00375396 0.00223178 0.17513356 0.05014297 0.1874428  0.06529228\n",
      "  0.48170403 0.03026897 0.00246432 0.00156534]\n",
      " [0.00472744 0.01101412 0.05315487 0.31695634 0.022663   0.34719172\n",
      "  0.01979607 0.21030368 0.0072419  0.00695075]\n",
      " [0.00086522 0.01720411 0.02026262 0.35615915 0.00450376 0.5590072\n",
      "  0.01470571 0.00942885 0.01367274 0.00419057]\n",
      " [0.05125397 0.00076732 0.41694415 0.02643239 0.43133712 0.02136279\n",
      "  0.03509416 0.00669563 0.00967746 0.00043499]\n",
      " [0.26528987 0.16028136 0.06109377 0.07645185 0.03226456 0.0377141\n",
      "  0.04910486 0.02977718 0.18187    0.1061525 ]] (33.340 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.3463069, step = 801 (33.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.93122\n",
      "INFO:tensorflow:probabilities = [[0.00027681 0.00085087 0.0018259  0.12841175 0.00107889 0.00848454\n",
      "  0.8563589  0.00057355 0.0001289  0.00200985]\n",
      " [0.0058952  0.00167511 0.08880534 0.15459384 0.5016604  0.12657702\n",
      "  0.06891671 0.04793305 0.00294498 0.00099831]\n",
      " [0.02053212 0.01514952 0.25023466 0.03428015 0.2400011  0.01124485\n",
      "  0.40913516 0.00822673 0.00725043 0.00394535]\n",
      " [0.00152134 0.00206151 0.01474931 0.11235082 0.06329829 0.21865954\n",
      "  0.01746855 0.56779814 0.0002847  0.0018078 ]\n",
      " [0.01014267 0.00077821 0.14259581 0.31619453 0.04058644 0.4290592\n",
      "  0.00517573 0.05080106 0.00378143 0.00088485]\n",
      " [0.01335754 0.89926004 0.00243076 0.00326771 0.00081031 0.00116981\n",
      "  0.00110951 0.00219013 0.00446936 0.07193488]\n",
      " [0.00553141 0.67089784 0.00037503 0.00027482 0.00020681 0.00006149\n",
      "  0.00002523 0.00006378 0.24533823 0.07722537]\n",
      " [0.02353093 0.00010634 0.0006933  0.00011553 0.00073143 0.00000552\n",
      "  0.00006255 0.00000377 0.97431254 0.0004381 ]\n",
      " [0.00875675 0.00466865 0.08498996 0.18608366 0.08727016 0.21392679\n",
      "  0.1315468  0.22785401 0.00954603 0.04535719]\n",
      " [0.00276976 0.00147964 0.13651556 0.03182515 0.17179726 0.08377402\n",
      "  0.5212957  0.04884225 0.00105514 0.00064548]\n",
      " [0.00028676 0.00056835 0.02707147 0.56697387 0.00061754 0.3907742\n",
      "  0.0064287  0.00529688 0.00011892 0.0018633 ]\n",
      " [0.0000669  0.00002021 0.01130034 0.00894881 0.0396364  0.00278908\n",
      "  0.93704945 0.00017365 0.0000125  0.00000265]\n",
      " [0.64748234 0.00250291 0.0071804  0.00026429 0.00062232 0.00000941\n",
      "  0.0000592  0.00000297 0.34119904 0.00067708]\n",
      " [0.00114913 0.0030645  0.02472458 0.12689322 0.0252675  0.04864477\n",
      "  0.7608503  0.00452207 0.00100006 0.00388393]\n",
      " [0.00246942 0.0011498  0.1243327  0.02282392 0.6672395  0.06643983\n",
      "  0.03553147 0.07911973 0.00050672 0.00038688]\n",
      " [0.00031543 0.00004793 0.00192923 0.0002945  0.01115889 0.00144384\n",
      "  0.00003103 0.98460686 0.00000231 0.00016996]\n",
      " [0.17269942 0.02772478 0.01444606 0.03496189 0.0116993  0.0082302\n",
      "  0.00028093 0.00501918 0.7189845  0.00595372]\n",
      " [0.01239509 0.0009729  0.02068561 0.32947916 0.35514352 0.20338129\n",
      "  0.01522824 0.05539452 0.0066322  0.00068754]\n",
      " [0.00064434 0.00080191 0.02616902 0.05037603 0.13421881 0.0301468\n",
      "  0.73170435 0.02531518 0.00034008 0.0002835 ]\n",
      " [0.00125321 0.00167481 0.03914724 0.41942215 0.01678093 0.33385527\n",
      "  0.1637913  0.01958214 0.00122922 0.00326385]\n",
      " [0.02219651 0.00106245 0.24567401 0.04472698 0.55397636 0.05081666\n",
      "  0.02592446 0.05132974 0.00328751 0.00100528]\n",
      " [0.03178025 0.01217013 0.08327641 0.01424172 0.34609857 0.04601298\n",
      "  0.0490222  0.4138242  0.00062011 0.00295341]\n",
      " [0.00013742 0.00008774 0.00507758 0.7835619  0.01497138 0.03234702\n",
      "  0.16298838 0.0007638  0.00003453 0.0000302 ]\n",
      " [0.00949747 0.00205868 0.09527104 0.26471266 0.26961663 0.16332091\n",
      "  0.07889406 0.10032004 0.01223691 0.00407152]\n",
      " [0.02282998 0.31033456 0.02907713 0.0323205  0.01790098 0.00784526\n",
      "  0.08595244 0.0026546  0.46640664 0.0246778 ]\n",
      " [0.00350077 0.00813692 0.02468857 0.05002043 0.01442786 0.01441709\n",
      "  0.87395155 0.0026152  0.00162177 0.00661979]\n",
      " [0.00069803 0.00006431 0.12135728 0.20416255 0.05907931 0.51280606\n",
      "  0.00659985 0.09503989 0.00008808 0.00010462]\n",
      " [0.00177236 0.00032352 0.09907816 0.031554   0.16591707 0.03174172\n",
      "  0.6461872  0.02278782 0.00034354 0.00029462]\n",
      " [0.0038742  0.06368244 0.00036462 0.00078091 0.00007374 0.00014611\n",
      "  0.00009372 0.00014945 0.00040525 0.9304296 ]\n",
      " [0.00018067 0.00052011 0.01022064 0.00531779 0.01845441 0.00549122\n",
      "  0.9547014  0.00332505 0.00003619 0.00175254]\n",
      " [0.00831252 0.02364847 0.05578586 0.15899113 0.01872737 0.12455945\n",
      "  0.03624582 0.27669758 0.00527626 0.2917555 ]\n",
      " [0.07404666 0.10658392 0.13803014 0.12927413 0.09476837 0.13845529\n",
      "  0.04712119 0.13475999 0.0367174  0.10024294]\n",
      " [0.00035398 0.9604718  0.00007207 0.00001935 0.00000285 0.00001268\n",
      "  0.00005948 0.00000452 0.00026891 0.03873431]\n",
      " [0.00164318 0.00156075 0.08631252 0.2170382  0.10479436 0.30392802\n",
      "  0.17035782 0.11095513 0.00207245 0.00133775]\n",
      " [0.0246416  0.80538523 0.00270094 0.00874145 0.00074347 0.00170758\n",
      "  0.00050873 0.00080725 0.01750963 0.13725407]\n",
      " [0.9842083  0.00003273 0.00217281 0.00002325 0.00002429 0.00000071\n",
      "  0.00000191 0.00000027 0.01352631 0.00000957]\n",
      " [0.12255991 0.00058496 0.29404825 0.02303734 0.39670095 0.02791514\n",
      "  0.01162004 0.11828144 0.00214875 0.00310324]\n",
      " [0.29484057 0.00104812 0.29175046 0.14021985 0.06899774 0.07463545\n",
      "  0.09097333 0.02072975 0.00884693 0.00795783]\n",
      " [0.00145917 0.7349453  0.00020323 0.00006758 0.00001591 0.00005657\n",
      "  0.00001491 0.00009291 0.00034567 0.26279885]\n",
      " [0.00247254 0.00181886 0.03605303 0.01959543 0.05654482 0.01894592\n",
      "  0.85334504 0.00676225 0.00278583 0.00167621]\n",
      " [0.02698085 0.00961438 0.10462213 0.13522004 0.50982475 0.08307625\n",
      "  0.09805766 0.02202453 0.00804459 0.00253486]\n",
      " [0.2994543  0.00601988 0.4163307  0.07748954 0.04184918 0.08176562\n",
      "  0.02318302 0.03726415 0.00704593 0.00959768]\n",
      " [0.12198497 0.07306662 0.200739   0.24099594 0.07760057 0.11687638\n",
      "  0.03985182 0.0480563  0.05289258 0.02793578]\n",
      " [0.02264558 0.10368191 0.02832354 0.07894518 0.0353398  0.0498609\n",
      "  0.36030608 0.0937705  0.00386019 0.22326635]\n",
      " [0.01125774 0.11591246 0.00380139 0.00653993 0.0022554  0.00309538\n",
      "  0.00802128 0.00017938 0.79910815 0.04982894]\n",
      " [0.24160254 0.01109953 0.01518664 0.00484837 0.00370829 0.00076386\n",
      "  0.0011092  0.0038687  0.22028176 0.49753115]\n",
      " [0.01436356 0.02095716 0.03683126 0.14844832 0.07812525 0.20732981\n",
      "  0.09214793 0.29985207 0.00622485 0.09571975]\n",
      " [0.02084224 0.02313908 0.1192199  0.28459248 0.02526075 0.29584152\n",
      "  0.03055369 0.10670915 0.00982204 0.08401917]\n",
      " [0.01458964 0.04607323 0.00097697 0.00103391 0.00071183 0.00019884\n",
      "  0.00039044 0.00004635 0.9058896  0.03008931]\n",
      " [0.00111911 0.54042655 0.00027041 0.00053003 0.00001899 0.00011164\n",
      "  0.00057402 0.00009419 0.00206165 0.45479345]\n",
      " [0.2249297  0.00170242 0.46093097 0.08749884 0.13417988 0.06100959\n",
      "  0.00222046 0.01627315 0.01056368 0.00069137]\n",
      " [0.8823235  0.00011244 0.03473249 0.00091314 0.0795185  0.0002913\n",
      "  0.00132717 0.00009693 0.00066351 0.00002082]\n",
      " [0.08554932 0.00231549 0.0049371  0.00143343 0.005165   0.00038119\n",
      "  0.00074041 0.00015642 0.89475536 0.00456625]\n",
      " [0.21988842 0.00897751 0.03996937 0.02983598 0.18527411 0.03596483\n",
      "  0.00614484 0.3585456  0.00135835 0.11404095]\n",
      " [0.00204473 0.5219949  0.00038931 0.00025172 0.00007162 0.00023377\n",
      "  0.00159981 0.00033253 0.00192771 0.471154  ]\n",
      " [0.00324338 0.00019392 0.03965564 0.0043933  0.41483492 0.01544781\n",
      "  0.00038194 0.5217332  0.00004424 0.00007167]\n",
      " [0.05923669 0.0156778  0.22283785 0.22974184 0.09823148 0.15953483\n",
      "  0.16121897 0.01732169 0.0080324  0.02816651]\n",
      " [0.03398442 0.00808747 0.13041939 0.275405   0.03944958 0.34727547\n",
      "  0.01830516 0.07700007 0.04503312 0.0250404 ]\n",
      " [0.00071111 0.00022155 0.07756397 0.01300483 0.2092982  0.00527052\n",
      "  0.689638   0.00420553 0.00004571 0.00004051]\n",
      " [0.00392075 0.00256832 0.08172452 0.32895124 0.05067629 0.09488051\n",
      "  0.30254123 0.07164375 0.00440754 0.05868588]\n",
      " [0.0025539  0.00075402 0.05622118 0.19858572 0.2000468  0.29955444\n",
      "  0.06213235 0.17716789 0.0015677  0.001416  ]\n",
      " [0.0425771  0.00743771 0.0498658  0.04040597 0.01756044 0.01351244\n",
      "  0.0143811  0.00511078 0.7895529  0.01959571]\n",
      " [0.9830604  0.00236145 0.00243238 0.0005459  0.0036124  0.00006171\n",
      "  0.00015306 0.00003237 0.00046111 0.00727909]\n",
      " [0.00023265 0.00000591 0.00162803 0.10011688 0.00045553 0.8840897\n",
      "  0.0000299  0.01339595 0.00002161 0.00002382]\n",
      " [0.01248062 0.02913632 0.09891629 0.2676605  0.03163466 0.20364627\n",
      "  0.13313636 0.05452184 0.01816472 0.1507024 ]\n",
      " [0.00523114 0.00257825 0.11278769 0.10583348 0.14150324 0.05546452\n",
      "  0.489801   0.08156934 0.0009769  0.0042545 ]\n",
      " [0.01049614 0.00041849 0.43071568 0.13844413 0.10768838 0.10910265\n",
      "  0.11094721 0.01401187 0.07735633 0.00081921]\n",
      " [0.01055256 0.00584821 0.01882183 0.2702291  0.16967386 0.11424963\n",
      "  0.39732513 0.01018222 0.00178259 0.00133479]\n",
      " [0.0270836  0.0001965  0.00197787 0.00066479 0.00051152 0.00004294\n",
      "  0.00008873 0.00001758 0.96885353 0.00056298]\n",
      " [0.0094544  0.0000647  0.00000049 0.00000006 0.00000007 0.\n",
      "  0.00000002 0.         0.990458   0.00002221]\n",
      " [0.1713279  0.0622168  0.1840267  0.12621725 0.08981567 0.06639444\n",
      "  0.16449754 0.03702521 0.05446136 0.04401712]\n",
      " [0.13398317 0.00475132 0.31425473 0.00273953 0.5087882  0.00193849\n",
      "  0.01537057 0.01633665 0.00110826 0.00072907]\n",
      " [0.0866778  0.62756234 0.08448844 0.05182926 0.0196361  0.00929317\n",
      "  0.0047523  0.00380846 0.09794503 0.01400704]\n",
      " [0.0016975  0.00168939 0.07419145 0.1092157  0.01534319 0.7279168\n",
      "  0.00636341 0.0593181  0.00247271 0.00179184]\n",
      " [0.0031237  0.00107742 0.3426888  0.15657967 0.1849906  0.16313215\n",
      "  0.11361489 0.03028629 0.00341058 0.00109586]\n",
      " [0.00156407 0.5554238  0.00001185 0.00000474 0.00010811 0.00000464\n",
      "  0.00001061 0.00004557 0.00068251 0.44214413]\n",
      " [0.00071401 0.0000748  0.01136757 0.5085239  0.01568864 0.44049123\n",
      "  0.01585577 0.00697203 0.00024829 0.00006365]\n",
      " [0.05115515 0.00914841 0.04199279 0.06572969 0.14508943 0.06578168\n",
      "  0.00992438 0.41321942 0.03684643 0.1611126 ]\n",
      " [0.00299703 0.00059509 0.08916834 0.17139415 0.22393048 0.33692947\n",
      "  0.05345375 0.12000515 0.00086023 0.00066624]\n",
      " [0.6395688  0.03814427 0.02270193 0.00382643 0.02310139 0.00177723\n",
      "  0.00154213 0.01171887 0.09293779 0.16468105]\n",
      " [0.00139271 0.00738941 0.01051907 0.17056744 0.00379309 0.16692974\n",
      "  0.00171979 0.54267436 0.00017538 0.094839  ]\n",
      " [0.00001297 0.00000968 0.00044755 0.00024436 0.00598874 0.00476051\n",
      "  0.00003852 0.9884189  0.00000073 0.00007808]\n",
      " [0.00312733 0.00440334 0.01923957 0.3167984  0.01009441 0.5888058\n",
      "  0.00894347 0.01725585 0.02467498 0.00665694]\n",
      " [0.02595796 0.09776852 0.06494381 0.08166669 0.12483271 0.06504662\n",
      "  0.32731384 0.12143    0.00685019 0.08418965]\n",
      " [0.02418849 0.00190491 0.13285606 0.27354848 0.13421236 0.13155052\n",
      "  0.24620326 0.03917783 0.0105     0.00585814]\n",
      " [0.0842754  0.00027273 0.06016906 0.4436099  0.02031325 0.35995233\n",
      "  0.01061267 0.01808718 0.00157688 0.00113064]\n",
      " [0.00040874 0.00204581 0.03416926 0.12302031 0.03924498 0.03788244\n",
      "  0.7441588  0.0164103  0.00049173 0.00216765]\n",
      " [0.00093849 0.00011866 0.07108397 0.00792803 0.76684195 0.00715081\n",
      "  0.13138586 0.01438871 0.00006072 0.00010284]\n",
      " [0.02415884 0.01616753 0.12691374 0.2349564  0.03110336 0.27424818\n",
      "  0.21068685 0.05414659 0.00623747 0.02138105]\n",
      " [0.00381811 0.00130317 0.05260946 0.5432685  0.01700187 0.32229736\n",
      "  0.0369501  0.01878605 0.00149132 0.00247404]\n",
      " [0.02121528 0.0239603  0.07787871 0.30113485 0.06882385 0.2601055\n",
      "  0.12637746 0.08616899 0.00708826 0.02724669]\n",
      " [0.00978335 0.0001075  0.5364973  0.0266656  0.18921354 0.12139946\n",
      "  0.01240989 0.1032628  0.00037558 0.00028505]\n",
      " [0.00057066 0.00135178 0.02424152 0.11532078 0.02448742 0.7191037\n",
      "  0.01151333 0.1018299  0.00008706 0.00149387]\n",
      " [0.00000664 0.00000546 0.00011054 0.00013159 0.00203259 0.00321135\n",
      "  0.00017778 0.99432194 0.00000001 0.00000217]\n",
      " [0.01381844 0.05625478 0.06152868 0.5715594  0.00177427 0.20870449\n",
      "  0.02395828 0.00681383 0.01991062 0.03567714]\n",
      " [0.12221766 0.08799507 0.08153471 0.12656601 0.17918174 0.05208058\n",
      "  0.10720657 0.03887734 0.11661588 0.08772452]\n",
      " [0.00184148 0.00034372 0.00583065 0.06919958 0.00834638 0.30205622\n",
      "  0.00085625 0.60652995 0.00016418 0.00483148]\n",
      " [0.00310377 0.00017326 0.06326591 0.09162258 0.02589558 0.64319015\n",
      "  0.00028832 0.17204283 0.00024277 0.00017487]\n",
      " [0.00451362 0.00208656 0.04935579 0.50797343 0.07615771 0.1375157\n",
      "  0.16514704 0.05291586 0.00221253 0.00212167]\n",
      " [0.00703874 0.01362903 0.02758644 0.4246106  0.10735562 0.08793333\n",
      "  0.29088908 0.02281209 0.00234873 0.01579629]] (34.105 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.1281607, step = 901 (34.106 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/cifar10_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.024688.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-08-16:07:50\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/cifar10_convnet_model\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-08-16:07:57\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.6246, global_step = 1000, loss = 1.0567349\n",
      "{'accuracy': 0.6246, 'loss': 1.0567349, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "def run_cifar10():\n",
    "    \n",
    "    # Load training and eval data\n",
    "    t_data, train_labels, tr_labels = cifar10_data.load_training_data()    \n",
    "    e_data, eval_labels, ev_labels = cifar10_data.load_test_data()  \n",
    "  \n",
    "    # Convert to float32\n",
    "    train_data = np.float32(t_data)\n",
    "    eval_data = np.float32(e_data)\n",
    "  \n",
    "    # Create the Estimator\n",
    "    cifar10_classifier = tf.estimator.Estimator(\n",
    "      model_fn=cnn_model_fn, model_dir=\"/tmp/cifar10_convnet_model\")\n",
    "\n",
    "    # Set up logging for predictions\n",
    "    # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=100)\n",
    "\n",
    "    # Train the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": train_data},\n",
    "      y=train_labels,\n",
    "      batch_size=100,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "    train_results = cifar10_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=1000,\n",
    "      hooks=[logging_hook])\n",
    "\n",
    "    # Evaluate the model and print results\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": eval_data},\n",
    "      y=eval_labels,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "    eval_results = cifar10_classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print(eval_results)\n",
    "    \n",
    "run_cifar10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify;\">Como se pode constatar, o modelo obteve uma precisão de teste de 0.6246 e custo de aproximadamente 1.06. É importante referir que, idealmente, o modelo deveria ter mais passos de treino, mas para efeitos de demonstração definiram-se apenas 1000 passos. Para melhorar os resultados seria benéfico experimentar outros valores de batch size, número de épocas e passos de treino, learning rate, entre outros. Experimentar outras arquiteturas de redes neuronais de convolução também poderia ser interessante.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\"><b>TensorBoard</b></p>\n",
    "\n",
    "<p style=\"text-align:justify;\">Abaixo apresenta-se o grafo de computação bem como os gráficos de custo de treino e teste e precisão de teste. Aquando do uso de estimators, não é necessário adicionar código de escrita para o TensorBoard, já que a API dos estimators já trata disso.</p>\n",
    "\n",
    "![alt text](cifar10_tensorboard_graph.png \"Grafo de computação\")\n",
    "<p style=\"text-align:center;\">Grafo de computação</p>\n",
    "![alt text](cifar10_tensorboard_loss.png \"Custo - Treino e Teste\")\n",
    "<p style=\"text-align:center;\">Gráficos de custo - Treino (laranja) e Teste (azul)</p>\n",
    "![alt text](cifar10_tensorboard_accuracy.png \"Precisão - Teste\")\n",
    "<p style=\"text-align:center;\">Gráfico de precisão - Teste</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Referências</h2>\n",
    "\n",
    "<ul>\n",
    "    <li style=\"text-align:justify;\">https://www.tensorflow.org/</li>\n",
    "    <li style=\"text-align:justify;\">https://www.geeksforgeeks.org/softmax-regression-using-tensorflow/</li>\n",
    "    <li style=\"text-align:justify;\">https://www.tensorflow.org/tutorials/estimators/cnn</li>\n",
    "    <li style=\"text-align:justify;\">https://www.tensorflow.org/tutorials/images/deep_cnn</li>\n",
    "    <li style=\"text-align:justify;\">http://adne.ssdi.di.fct.unl.pt/teoricas.html</li>\n",
    "    <li style=\"text-align:justify;\">https://en.wikipedia.org/wiki/MNIST_database</li>\n",
    "    <li style=\"text-align:justify;\">https://en.wikipedia.org/wiki/CIFAR-10</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
